wandb: Starting wandb agent 🕵️
2022-09-02 15:32:06,493 - wandb.wandb_agent - INFO - Running runs: []
2022-09-02 15:32:06,724 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:32:06,724 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0437848241978869
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:32:06,742 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0437848241978869 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:32:11,755 - wandb.wandb_agent - INFO - Running runs: ['u2ayojpo']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153209-u2ayojpo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-10
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u2ayojpo
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.182393170427446 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.22742566149598 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.93484393835964 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2577765533964427 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.782290265603152 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
2022-09-02 15:33:44,744 - wandb.wandb_agent - INFO - Cleaning up finished run: u2ayojpo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▇▇▇▇▇▆▆▆▆▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▇▇▆▇▇▇▇▇▇████▇▇▇▇▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▃▁▁▁▁▅▄▁▁▁█▁█▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced ethereal-sweep-10: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u2ayojpo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153209-u2ayojpo/logs
2022-09-02 15:33:51,161 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:33:51,164 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0015827824007898642
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:33:51,176 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0015827824007898642 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:33:56,187 - wandb.wandb_agent - INFO - Running runs: ['2yudglms']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153355-2yudglms
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-35
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2yudglms
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.291292901190814 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2943297452466287 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.060262349816982 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0001500880347347 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.562587100165126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.360608384970104 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ████▇▇▆▇▇▇▇▇▇▇▇████▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▇█▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▁▁▁▁▁█▄▁▁█▁█▅█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.978
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.022
wandb:  reward 1.0
wandb: 
wandb: Synced crisp-sweep-35: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2yudglms
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153355-2yudglms/logs
2022-09-02 15:35:29,064 - wandb.wandb_agent - INFO - Cleaning up finished run: 2yudglms
2022-09-02 15:35:29,307 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:35:29,307 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00542035223109153
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:35:29,326 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00542035223109153 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:35:34,337 - wandb.wandb_agent - INFO - Running runs: ['on68mlfl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153533-on68mlfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-51
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/on68mlfl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1835118514383134 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.898084733527892 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4280387262055423 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.374663557545128 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0623957814615412 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.817848065240087 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▇▆▆▆▆▇▇▇▇▇▆▆▇▇▇▇▇▇██▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆█▇▆▆▇▇█▇▇████▇▇▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇▇▇▇▇▇██████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁██▇▁▁▆██▁█▅█▁█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced devout-sweep-51: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/on68mlfl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153533-on68mlfl/logs
2022-09-02 15:37:07,031 - wandb.wandb_agent - INFO - Cleaning up finished run: on68mlfl
2022-09-02 15:37:07,276 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:37:07,276 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00019848431849863607
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:37:07,295 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00019848431849863607 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:37:12,306 - wandb.wandb_agent - INFO - Running runs: ['uevyk575']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153711-uevyk575
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-66
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uevyk575
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4526139933640434 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.030463401505763 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.410487999791074 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4275308175624963 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.391011516698911 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇▇▇▇▇█▇█▆▆▆▆▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁█▁▁▇▁▁▁▁█▁▁▁▅▁▇▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced lyric-sweep-66: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uevyk575
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153711-uevyk575/logs
2022-09-02 15:38:45,080 - wandb.wandb_agent - INFO - Cleaning up finished run: uevyk575
2022-09-02 15:38:45,300 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:38:45,300 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.008545266558752788
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:38:45,333 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.008545266558752788 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:38:50,343 - wandb.wandb_agent - INFO - Running runs: ['c51zhocq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153850-c51zhocq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-81
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c51zhocq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.349785065112897 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1880828378539943 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.308024289063759 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇████▇▇▇▇▆▇▇▇▇█▇██▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▇▆▇▇▇██▇▇▇▇██▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁█▁▁▁█▁▁▆▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced apricot-sweep-81: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c51zhocq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153850-c51zhocq/logs
2022-09-02 15:40:23,134 - wandb.wandb_agent - INFO - Cleaning up finished run: c51zhocq
2022-09-02 15:40:23,409 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:40:23,409 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.009185716294035955
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:40:23,436 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.009185716294035955 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:40:28,446 - wandb.wandb_agent - INFO - Running runs: ['erhv9ims']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154028-erhv9ims
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-96
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/erhv9ims
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1755771650489057 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.579596117703872 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇█▇██▇▇▇█▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆█▇▇▇▇▆▆▇▆▇▆▇▇▇▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁▁▁▁▆▇▁▁▁█▁▇▁▃▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced breezy-sweep-96: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/erhv9ims
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154028-erhv9ims/logs
2022-09-02 15:41:56,037 - wandb.wandb_agent - INFO - Cleaning up finished run: erhv9ims
2022-09-02 15:41:56,279 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:41:56,279 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001316818951425662
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:41:56,313 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001316818951425662 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:42:01,323 - wandb.wandb_agent - INFO - Running runs: ['t6xs60ll']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154201-t6xs60ll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-111
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t6xs60ll
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3254531347780807 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1842826295231585 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3815402915140744 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇██▇▇▆▆▆▆▆▆▆▆▆▆▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▅▆▆▇▇████▇██▇██▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇█▇██▇█▇▇▇▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁▁█▇▁▁▁▅▁▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced winter-sweep-111: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t6xs60ll
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154201-t6xs60ll/logs
2022-09-02 15:43:39,171 - wandb.wandb_agent - INFO - Cleaning up finished run: t6xs60ll
2022-09-02 15:43:39,430 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:43:39,430 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0002316496584488267
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:43:39,471 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0002316496584488267 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:43:44,481 - wandb.wandb_agent - INFO - Running runs: ['crg1w7sc']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154344-crg1w7sc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-126
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/crg1w7sc
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.027797471656262 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.734052945889257 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2095918783427058 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▆▆▆▆▇▇▇▇▇▇▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▇▇▇▇▇█▇█▇▇████▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▁▁█▁▁▁▄█▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced wise-sweep-126: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/crg1w7sc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154344-crg1w7sc/logs
2022-09-02 15:45:22,395 - wandb.wandb_agent - INFO - Cleaning up finished run: crg1w7sc
2022-09-02 15:45:22,637 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:45:22,637 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01378080054176195
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:45:22,666 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01378080054176195 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:45:27,675 - wandb.wandb_agent - INFO - Running runs: ['zvvt8bvg']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154528-zvvt8bvg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-141
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zvvt8bvg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4723287477883695 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.259978244802958 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.646846582111315 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▅▅▇▇▇▇▇▇▇▆▇▆▆▆▆▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ███▇▇▆▆▆▆▆▇██▇▆▆▆▅▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁█▃▁▁▁▁▁▁█▁▇▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sandy-sweep-141: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zvvt8bvg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154528-zvvt8bvg/logs
2022-09-02 15:47:05,674 - wandb.wandb_agent - INFO - Cleaning up finished run: zvvt8bvg
2022-09-02 15:47:05,963 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:47:05,963 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0005560853040492823
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:47:05,971 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0005560853040492823 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:47:10,981 - wandb.wandb_agent - INFO - Running runs: ['2a5xhsr0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154711-2a5xhsr0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-156
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2a5xhsr0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3237061391787783 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.480155789268893 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8088351548993815 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇██▇█▇▇▇▇██▇▆▆▅▆▆▆▆▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇█▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇▇▇███▇▇█████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃█▄▁▁▁▁▁▁█▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.986
wandb:  prop_3 0.0
wandb: prop_NA 0.014
wandb:  reward 0.83716
wandb: 
wandb: Synced dark-sweep-156: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2a5xhsr0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154711-2a5xhsr0/logs
2022-09-02 15:48:38,655 - wandb.wandb_agent - INFO - Cleaning up finished run: 2a5xhsr0
2022-09-02 15:48:38,931 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:48:38,931 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002694354974632371
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:48:38,955 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002694354974632371 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:48:43,966 - wandb.wandb_agent - INFO - Running runs: ['topyrhrn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154844-topyrhrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-171
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/topyrhrn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0952696770517294 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.253343494421625 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2094795535914917 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7094312120563275 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▇▇▇▇▇▇▇▇▇▇▇▆▇▆▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇▇▇▇█▇▇▇▇▆▇▇██▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▃▁▁▁▁▁█▁▁▁▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced worldly-sweep-171: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/topyrhrn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154844-topyrhrn/logs
2022-09-02 15:50:27,367 - wandb.wandb_agent - INFO - Cleaning up finished run: topyrhrn
2022-09-02 15:50:27,609 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:50:27,609 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03922989910934763
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:50:27,612 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03922989910934763 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:50:32,622 - wandb.wandb_agent - INFO - Running runs: ['34bg17zb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155032-34bg17zb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-187
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/34bg17zb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3651803007486123 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.665408191387175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2193881349858433 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.279516035692767 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.493257481632493 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇███████▇▇▇▇█▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ██▇▇▇▆▇▇▇▇▇▇████▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▁▁▃▁▁██▁▁▁▁▇▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced unique-sweep-187: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/34bg17zb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155032-34bg17zb/logs
2022-09-02 15:52:10,637 - wandb.wandb_agent - INFO - Cleaning up finished run: 34bg17zb
2022-09-02 15:52:10,882 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:52:10,882 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0034889564519391806
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:52:10,908 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0034889564519391806 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:52:15,918 - wandb.wandb_agent - INFO - Running runs: ['rswr7ufl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155215-rswr7ufl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-207
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rswr7ufl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2700657891493554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7221245026790655 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4308194180952087 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.302551463706244 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4903606478858045 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4775534371452 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.049750305122264 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▆▆▇▆▆▆▆▆▆▆▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▇██▇▇▇▇▇▇▇▇▇▇█████▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁█▁▄▃▁▆▁▁▁▁▁▁▁█▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.987
wandb:  prop_3 0.0
wandb: prop_NA 0.013
wandb:  reward 0.83716
wandb: 
wandb: Synced neat-sweep-207: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rswr7ufl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155215-rswr7ufl/logs
2022-09-02 15:53:46,453 - wandb.wandb_agent - INFO - Cleaning up finished run: rswr7ufl
2022-09-02 15:53:46,770 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:53:46,770 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.041156916070005226
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:53:46,783 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.041156916070005226 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:53:51,793 - wandb.wandb_agent - INFO - Running runs: ['wrb1c2pq']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155351-wrb1c2pq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-224
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wrb1c2pq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0703796137736328 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.460570751996601 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1706438471350737 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.364535616788197 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.190441281181558 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.685144521291153 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1302863979379647 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.338379579675352 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▇▆▆▆▆▇▇▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ██▇███▇▇▇▇▆▇▇▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▃▅▁▁▁▁▁▁▅▇▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced splendid-sweep-224: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wrb1c2pq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155351-wrb1c2pq/logs
2022-09-02 15:55:35,112 - wandb.wandb_agent - INFO - Cleaning up finished run: wrb1c2pq
2022-09-02 15:55:35,362 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:55:35,362 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004219351927482177
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:55:35,366 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004219351927482177 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:55:40,376 - wandb.wandb_agent - INFO - Running runs: ['69x6fyu1']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155539-69x6fyu1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-242
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/69x6fyu1
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2597972255089616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.803299756780904 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3860864736285294 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.513650093416267 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4914846892490665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.43883176646246 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▅▅▆▇▇████▇████▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▆▆▆▆▆▆▆▇▇███▇▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▇█▁▁█▁▁▁██▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced brisk-sweep-242: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/69x6fyu1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155539-69x6fyu1/logs
2022-09-02 15:57:13,091 - wandb.wandb_agent - INFO - Cleaning up finished run: 69x6fyu1
2022-09-02 15:57:13,340 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:57:13,340 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011607363177763124
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:57:13,361 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011607363177763124 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:57:18,371 - wandb.wandb_agent - INFO - Running runs: ['a4hfmmkf']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155718-a4hfmmkf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-257
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a4hfmmkf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3765654085068992 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.447354120122207 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2681022454028126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.002729659489067 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇███▇▇▇▇▇▇█████▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▇▇▇▇▇█▇▇▇▆▇▇▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▄▁▁▁▁█▂▄█▁▁▁▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced glad-sweep-257: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a4hfmmkf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155718-a4hfmmkf/logs
2022-09-02 15:58:53,570 - wandb.wandb_agent - INFO - Cleaning up finished run: a4hfmmkf
2022-09-02 15:58:53,818 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:58:53,818 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002096992016998373
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:58:53,824 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002096992016998373 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:58:58,834 - wandb.wandb_agent - INFO - Running runs: ['zsxvsn11']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155859-zsxvsn11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-272
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zsxvsn11
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2365655759242453 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3225252597758943 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 █▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▇█▇▇█▇█▇▇▇▇▇████▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▁▇▇▁▁▁▅▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.991
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.009
wandb:  reward 1.0
wandb: 
wandb: Synced fiery-sweep-272: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zsxvsn11
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155859-zsxvsn11/logs
2022-09-02 16:00:42,575 - wandb.wandb_agent - INFO - Cleaning up finished run: zsxvsn11
2022-09-02 16:00:42,801 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:00:42,801 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0016512566700268396
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:00:42,807 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0016512566700268396 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:00:47,818 - wandb.wandb_agent - INFO - Running runs: ['cf4fl7w6']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160047-cf4fl7w6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-288
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cf4fl7w6
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.228074732565724 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▂▂▂▂▂▁▁▁▁▁▂▁▂▂▂▂▂▄▆▇████████████████
wandb:  prop_2 ▅▇▇▇██▇▇▇▇████▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇████████████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁▁▁▁█▇▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.973
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.027
wandb:  reward 1.0
wandb: 
wandb: Synced lyric-sweep-288: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cf4fl7w6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160047-cf4fl7w6/logs
2022-09-02 16:02:22,093 - wandb.wandb_agent - INFO - Cleaning up finished run: cf4fl7w6
2022-09-02 16:02:22,678 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:02:22,678 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00699492721612746
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:02:22,683 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00699492721612746 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:02:27,693 - wandb.wandb_agent - INFO - Running runs: ['t8qr6elm']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160227-t8qr6elm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-303
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t8qr6elm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3060085524560097 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.325204019532701 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.094045237803372 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▅▆▇█▇▇▇▆▇▇███▇▇▇▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▇▇▇▇▇▇█▇██▇█▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇████▇▇▇▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▅▁▇▁▁█▁▁▄▁▁▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced eager-sweep-303: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t8qr6elm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160227-t8qr6elm/logs
2022-09-02 16:04:00,616 - wandb.wandb_agent - INFO - Cleaning up finished run: t8qr6elm
2022-09-02 16:04:00,858 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:04:00,858 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0007084992490017897
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:04:00,861 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0007084992490017897 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:04:05,871 - wandb.wandb_agent - INFO - Running runs: ['f4m5ma72']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160406-f4m5ma72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-318
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f4m5ma72
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4865108733401335 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.018567448592439 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.07852852158145 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▇▇▇▇▇▇▆▇▇██▇█▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆█▇▆▆▆▆▇▇▇▇▇▆▆▆▆▆▅▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇████▇▇▇▇▇▇▇▇██████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▂▁▁▁█▁▇▁██▅▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced zesty-sweep-318: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f4m5ma72
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160406-f4m5ma72/logs
2022-09-02 16:05:38,614 - wandb.wandb_agent - INFO - Cleaning up finished run: f4m5ma72
2022-09-02 16:05:38,854 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:05:38,854 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.011677000247757788
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:05:38,859 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.011677000247757788 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:05:43,869 - wandb.wandb_agent - INFO - Running runs: ['v708299z']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160543-v708299z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-333
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v708299z
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3695799202369083 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.552132567895407 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1120634309368973 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.261739897158222 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▆▆▅▅▅▅▅▆▆▆▆▆▅▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇███████████████▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▄▅▁█▁▇▁█▁▁▁▅▁▁▁▇█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced dandy-sweep-333: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v708299z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160543-v708299z/logs
2022-09-02 16:07:11,593 - wandb.wandb_agent - INFO - Cleaning up finished run: v708299z
2022-09-02 16:07:11,829 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:07:11,830 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.04338212022243885
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:07:11,869 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.04338212022243885 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:07:16,880 - wandb.wandb_agent - INFO - Running runs: ['344hlrso']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160716-344hlrso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-347
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/344hlrso
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.360469076607039 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.447576101378012 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.125602304375711 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇███▇▇▇▆▆▆▆▇▇▇█████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆███▇▇▆▆▆▆▇▆▆▇▆▇█▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇▇█████████▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▁█▇▁▁▁▁▇▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.964
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.036
wandb:  reward 1.0
wandb: 
wandb: Synced feasible-sweep-347: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/344hlrso
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160716-344hlrso/logs
2022-09-02 16:08:54,754 - wandb.wandb_agent - INFO - Cleaning up finished run: 344hlrso
2022-09-02 16:08:54,991 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:08:54,991 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00030186326663475527
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:08:54,998 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00030186326663475527 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:09:00,010 - wandb.wandb_agent - INFO - Running runs: ['5v5cdks7']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160900-5v5cdks7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-362
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5v5cdks7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2388558851540283 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.230088171408553 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.304884498778159 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.186539302428102 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇██▇█▇▇██████████▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▇▇▇▇████▇██▇██▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▃▅▁▁▁▁▁▁▁▇▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced divine-sweep-362: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5v5cdks7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160900-5v5cdks7/logs
2022-09-02 16:10:38,093 - wandb.wandb_agent - INFO - Cleaning up finished run: 5v5cdks7
2022-09-02 16:10:50,090 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:10:50,104 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0034204224850004805
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:10:50,163 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0034204224850004805 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:10:55,192 - wandb.wandb_agent - INFO - Running runs: ['7itd8d6l']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161055-7itd8d6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-380
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7itd8d6l
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.204751705682128 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.423532457277256 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4878370621615598 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.995221748842829 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.255949421865608 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▅▆▅▆▆▆▆▆▆▆▅▅▅▅▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇████▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:  reward ▁▁▁▁▁▁▁▁▁▁█▂▄▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.943
wandb: prop_NA 0.057
wandb:  reward 0.92352
wandb: 
wandb: Synced curious-sweep-380: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7itd8d6l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161055-7itd8d6l/logs
2022-09-02 16:12:22,760 - wandb.wandb_agent - INFO - Cleaning up finished run: 7itd8d6l
2022-09-02 16:12:23,014 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:12:23,020 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0004330191765913764
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:12:23,027 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0004330191765913764 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:12:28,039 - wandb.wandb_agent - INFO - Running runs: ['nds09c8x']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161228-nds09c8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-393
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nds09c8x
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.13626402456332 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.055407169919717 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.242939326460929 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4941622570126913 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.938344247878493 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.200612246926311 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.916791208675217 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▃▅▆▇████
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████▇▇▆▅▄▃▃▃▃
wandb:  prop_3 ▆▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▁██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.577
wandb:  prop_2 0.391
wandb:  prop_3 0.0
wandb: prop_NA 0.032
wandb:  reward 1.0
wandb: 
wandb: Synced lively-sweep-393: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nds09c8x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161228-nds09c8x/logs
2022-09-02 16:13:55,578 - wandb.wandb_agent - INFO - Cleaning up finished run: nds09c8x
2022-09-02 16:13:55,828 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:13:55,835 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001364878439037531
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:13:55,862 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001364878439037531 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:14:00,873 - wandb.wandb_agent - INFO - Running runs: ['3yoyxebk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161401-3yoyxebk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-408
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3yoyxebk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.033049123076265 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.342629512745238 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.393325670551191 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.408752882692413 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.468675120463141 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.701330694261091 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆▇█
wandb:  prop_2 █▇▆▆▇▇▇█▇▆▇▆▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇██████████▇▆▄▃▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂
wandb:  reward ██▁█▅▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.839
wandb:  prop_2 0.0
wandb:  prop_3 0.09
wandb: prop_NA 0.071
wandb:  reward 1.0
wandb: 
wandb: Synced grateful-sweep-408: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3yoyxebk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161401-3yoyxebk/logs
2022-09-02 16:15:39,284 - wandb.wandb_agent - INFO - Cleaning up finished run: 3yoyxebk
2022-09-02 16:15:39,522 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:15:39,522 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00012169144680957508
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:15:39,533 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00012169144680957508 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:15:44,543 - wandb.wandb_agent - INFO - Running runs: ['bsohqtm5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161544-bsohqtm5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-428
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bsohqtm5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1804704097163947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.122701012660841 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.633879884354596 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.431239415950423 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.502723463617779 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0818608553624736 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▆▇▇███▇▇▇███▇▆▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▄▁▁▁▁▁▇▁▁█▁▁▁▇██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced divine-sweep-428: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bsohqtm5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161544-bsohqtm5/logs
2022-09-02 16:17:27,601 - wandb.wandb_agent - INFO - Cleaning up finished run: bsohqtm5
2022-09-02 16:17:27,852 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:17:27,852 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.000267633076343381
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:17:27,859 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.000267633076343381 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:17:32,869 - wandb.wandb_agent - INFO - Running runs: ['k0bbwujy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161732-k0bbwujy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-449
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/k0bbwujy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.417477485578283 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.738017634201988 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3048041905173653 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.402272333027813 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2728630586262213 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▆▆▆▆▇█▇▇▇▆▆▇███▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇█▇▇▇▇▇▇▆▆▆▇▇▇█▇▇▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇█████████████▇██
wandb: prop_NA ████████████████▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂
wandb:  reward ▁▄▁▁▇▁▁▁▁▁▇▁▁▆▅▁▇▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.94
wandb: prop_NA 0.06
wandb:  reward 0.92352
wandb: 
wandb: Synced upbeat-sweep-449: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/k0bbwujy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161732-k0bbwujy/logs
2022-09-02 16:19:00,530 - wandb.wandb_agent - INFO - Cleaning up finished run: k0bbwujy
2022-09-02 16:19:00,785 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:19:00,785 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0011654733129217482
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:19:00,796 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0011654733129217482 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:19:05,806 - wandb.wandb_agent - INFO - Running runs: ['pn65ijne']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161906-pn65ijne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-463
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pn65ijne
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.192578537926767 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1465749247869064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3293746865656075 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2753389955106855 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.790510691958015 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▅▆▆▇▇██▇▇▇▇▇█▇█▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄█▁▁▁█▁▄▁▅▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.999
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 1.0
wandb: 
wandb: Synced summer-sweep-463: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pn65ijne
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161906-pn65ijne/logs
2022-09-02 16:20:43,702 - wandb.wandb_agent - INFO - Cleaning up finished run: pn65ijne
2022-09-02 16:20:43,945 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:20:43,948 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0009026572219086672
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:20:44,013 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0009026572219086672 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:20:49,023 - wandb.wandb_agent - INFO - Running runs: ['qf2jxhvv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162048-qf2jxhvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-479
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qf2jxhvv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.191240690546908 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8617776605235825 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3286416326629173 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇██████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆██▇▅▄▃▄▄▄▄▄▄▄▅▄▅▅
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▄▅▇██▇▇▇▇▇▇▇▇▆▆
wandb: prop_NA ▇▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▃▁▂█▃▁▁▁▁▄▁▁▁▁▆▁▁▂████████████████▁▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.514
wandb:  prop_3 0.482
wandb: prop_NA 0.004
wandb:  reward 0.92352
wandb: 
wandb: Synced restful-sweep-479: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qf2jxhvv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162048-qf2jxhvv/logs
2022-09-02 16:22:17,226 - wandb.wandb_agent - INFO - Cleaning up finished run: qf2jxhvv
2022-09-02 16:22:17,476 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:22:17,476 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0003454981794793878
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:22:17,498 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0003454981794793878 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:22:22,509 - wandb.wandb_agent - INFO - Running runs: ['6aptad1x']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162222-6aptad1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-493
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6aptad1x
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3686407404183942 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.327692902864652 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1917921402100227 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.591296507871604 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▄▄▄▄▃▂▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▅█
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▄▆███████▇▇▇▇▆
wandb: prop_NA ████████████▇█▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▂▇▁▁▁█▂▁▁█▁▁▁▁▁█▃▅▅▆▅██████▇▆██▃▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.262
wandb:  prop_3 0.705
wandb: prop_NA 0.033
wandb:  reward 0.0
wandb: 
wandb: Synced jumping-sweep-493: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6aptad1x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162222-6aptad1x/logs
2022-09-02 16:23:50,259 - wandb.wandb_agent - INFO - Cleaning up finished run: 6aptad1x
2022-09-02 16:23:50,538 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:23:50,538 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011688532693008265
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:23:50,550 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011688532693008265 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:23:55,560 - wandb.wandb_agent - INFO - Running runs: ['wl2he47q']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162356-wl2he47q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-507
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wl2he47q
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2507636883078757 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3053380761261537 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.616077804668725 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.349279904533529 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.965966503449664 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▆▅▅▅▆▆▇▇▇▆▆▆▆▆▆▆▆▆▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆██▇█▇▇█▇██▇▇▇██▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁▁▅▁▁▁▁▁██▅▁██▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced revived-sweep-507: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wl2he47q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162356-wl2he47q/logs
2022-09-02 16:25:28,558 - wandb.wandb_agent - INFO - Cleaning up finished run: wl2he47q
2022-09-02 16:25:28,787 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:25:28,788 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00023716395364572075
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:25:28,806 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00023716395364572075 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:25:33,816 - wandb.wandb_agent - INFO - Running runs: ['tecbvxwy']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162534-tecbvxwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-523
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tecbvxwy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.13326922212464 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5638158675393905 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.011600149814768 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.639316308377479 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.171040919009371 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█████████▇▇▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▆▆▆▆▇▇▇█▇▇█▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced polished-sweep-523: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tecbvxwy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162534-tecbvxwy/logs
2022-09-02 16:27:22,478 - wandb.wandb_agent - INFO - Cleaning up finished run: tecbvxwy
2022-09-02 16:27:22,707 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:27:22,707 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.030285909142693294
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:27:22,742 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.030285909142693294 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:27:27,752 - wandb.wandb_agent - INFO - Running runs: ['uq8rmio0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162728-uq8rmio0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-538
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uq8rmio0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.268471222441373 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3293772461963296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.744039759944502 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▆▆▆▇▇▇▆▆▇▇▇▇▇████▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▄▁▁██▇▁▁▁▅▁▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glorious-sweep-538: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uq8rmio0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162728-uq8rmio0/logs
2022-09-02 16:29:10,826 - wandb.wandb_agent - INFO - Cleaning up finished run: uq8rmio0
2022-09-02 16:29:11,171 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:29:11,172 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01580247271696243
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:29:11,189 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01580247271696243 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:29:16,199 - wandb.wandb_agent - INFO - Running runs: ['j6zfi85d']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162916-j6zfi85d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-554
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j6zfi85d
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.368784027489443 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2335803053623247 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.311860210767909 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▆▆▇▆▆▆▆▆▇███▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆█▇██▇█▇▇▇▇▇▇▇▆▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ███████████▇▇▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▁▁▁▁▁▁▁███▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced worthy-sweep-554: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j6zfi85d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162916-j6zfi85d/logs
2022-09-02 16:30:54,047 - wandb.wandb_agent - INFO - Cleaning up finished run: j6zfi85d
2022-09-02 16:30:54,450 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:30:54,450 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004523746554714681
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:30:54,461 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004523746554714681 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:30:59,471 - wandb.wandb_agent - INFO - Running runs: ['4aoj0bsf']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163058-4aoj0bsf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-570
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4aoj0bsf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.031637992928334 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.278919750504022 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.090083191502856 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.693308673796726 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▆▇▇▇▆▆▆▆▇▇▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▁▁▁▁█▁▇▁▁▁▁▁▁▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.964
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.036
wandb:  reward 1.0
wandb: 
wandb: Synced curious-sweep-570: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4aoj0bsf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163058-4aoj0bsf/logs
2022-09-02 16:32:40,537 - wandb.wandb_agent - INFO - Cleaning up finished run: 4aoj0bsf
2022-09-02 16:32:40,774 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:32:40,774 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00080729245933875
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:32:40,795 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00080729245933875 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:32:45,805 - wandb.wandb_agent - INFO - Running runs: ['su1g3wgz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163246-su1g3wgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-586
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/su1g3wgz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2571348880809765 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.640523409091082 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.155030547608002 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▆▆▆▆▇▇██▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▃▆▆▇▇▇███▇▇▇▇▇██▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁█▁▁▁▁█▁▁▄█▁▃█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.998
wandb: prop_NA 0.002
wandb:  reward 0.92352
wandb: 
wandb: Synced pleasant-sweep-586: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/su1g3wgz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163246-su1g3wgz/logs
2022-09-02 16:34:18,482 - wandb.wandb_agent - INFO - Cleaning up finished run: su1g3wgz
2022-09-02 16:34:18,714 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:34:18,715 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0011010077874541366
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:34:18,726 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0011010077874541366 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:34:23,740 - wandb.wandb_agent - INFO - Running runs: ['15rex5rn']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163423-15rex5rn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-601
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/15rex5rn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.170868717540785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.073118682327518 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.790134582951539 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3308262476813986 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇████▇▇▇▇▇▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆█▇███▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁▇▁▁▁▁▁▇▁▁███▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced leafy-sweep-601: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/15rex5rn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163423-15rex5rn/logs
2022-09-02 16:35:51,551 - wandb.wandb_agent - INFO - Cleaning up finished run: 15rex5rn
2022-09-02 16:35:52,000 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:35:52,000 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0016655218147012163
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:35:52,021 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0016655218147012163 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:35:57,031 - wandb.wandb_agent - INFO - Running runs: ['z8m0u2io']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163557-z8m0u2io
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-616
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z8m0u2io
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0755942599328248 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.640973111049331 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇█████▇██▇██▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁██▂▁▁▁▅▁▇█▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.979
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.021
wandb:  reward 1.0
wandb: 
wandb: Synced graceful-sweep-616: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z8m0u2io
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163557-z8m0u2io/logs
2022-09-02 16:37:40,465 - wandb.wandb_agent - INFO - Cleaning up finished run: z8m0u2io
2022-09-02 16:37:40,716 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:37:40,717 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.011624690050990096
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:37:40,737 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.011624690050990096 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:37:45,748 - wandb.wandb_agent - INFO - Running runs: ['qvoqiw5j']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163746-qvoqiw5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-636
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qvoqiw5j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.138510514598654 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.31683832594853 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.075909614399199 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.057601320047259 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4915369156179206 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.212419530747427 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▅▆▆▆▇▇▇██▇▇▆▆▇▇██▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▆▅▅▅▅▅▅▆▆▅▅▅▆▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁▁▁▁▄▁█▁█▆▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced true-sweep-636: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qvoqiw5j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163746-qvoqiw5j/logs
2022-09-02 16:39:19,748 - wandb.wandb_agent - INFO - Cleaning up finished run: qvoqiw5j
2022-09-02 16:39:20,051 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:39:20,051 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0009696805926804888
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:39:20,089 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0009696805926804888 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:39:25,098 - wandb.wandb_agent - INFO - Running runs: ['8tq9k32w']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163926-8tq9k32w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-650
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8tq9k32w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2465567873147947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3863232236014666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.010221610700273 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4547331140190796 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.661054162906233 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇████▇████▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▇▇█▇▇▇████▇██▇████▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ███▇▇▇██████▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁▁▁▁▁▁▆█▁▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.993
wandb: prop_NA 0.007
wandb:  reward 0.92352
wandb: 
wandb: Synced denim-sweep-650: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8tq9k32w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163926-8tq9k32w/logs
2022-09-02 16:41:08,639 - wandb.wandb_agent - INFO - Cleaning up finished run: 8tq9k32w
2022-09-02 16:41:08,921 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:41:08,925 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03798240496002841
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:41:08,939 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03798240496002841 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:41:13,950 - wandb.wandb_agent - INFO - Running runs: ['u7m0uuz9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164115-u7m0uuz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-668
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u7m0uuz9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.039938714014868 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.22022128379472 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1650553109703496 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.397488704844166 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1860620151205836 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆▆▅▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▆█▇▇█▇▆▇▆▆▇▆▆▆▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇▇█████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄▁▁█▁█▂▁██▁▇▇▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced brisk-sweep-668: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u7m0uuz9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164115-u7m0uuz9/logs
2022-09-02 16:42:57,091 - wandb.wandb_agent - INFO - Cleaning up finished run: u7m0uuz9
2022-09-02 16:42:57,342 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:42:57,342 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0009198988890258276
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:42:57,368 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0009198988890258276 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:43:02,378 - wandb.wandb_agent - INFO - Running runs: ['a6cyvh3s']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164303-a6cyvh3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-686
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a6cyvh3s
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1828976736268415 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3252250119777393 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3952882378897944 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.465419338104499 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇███▇▇▇▇▇▇▇▇███▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆███████▇▆▅▅▅▅▅▄▄
wandb:  prop_3 ▂▂▂▂▂▂▂▃▃▂▂▂▂▂▃▃▃▃▃▃▄▄▃▂▁▁▂▂▂▂▂▄▅▆▇▇▇▇██
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂
wandb:  reward ▆▁█▁▁▁▁▃█▄█▁▄▁▁▁▁▁▁▁▅███▇█▂▆▄▆████▁██▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.493
wandb:  prop_3 0.417
wandb: prop_NA 0.09
wandb:  reward 0.83716
wandb: 
wandb: Synced trim-sweep-686: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a6cyvh3s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164303-a6cyvh3s/logs
2022-09-02 16:44:35,398 - wandb.wandb_agent - INFO - Cleaning up finished run: a6cyvh3s
2022-09-02 16:44:35,655 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:44:35,655 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00043027514142836943
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:44:35,702 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00043027514142836943 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:44:40,712 - wandb.wandb_agent - INFO - Running runs: ['9i3rqjyi']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164442-9i3rqjyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-700
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9i3rqjyi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4872962810464267 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇████▇▆▇▇▇▇▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ████▇▇▇▇▇▇▇▇██▇▇▇▆▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▃▄▄▅
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇███████████████▇
wandb: prop_NA ███▇████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁█▇▁▁▄▁▁▁█▁▁▁▇▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.067
wandb:  prop_3 0.929
wandb: prop_NA 0.004
wandb:  reward 0.92352
wandb: 
wandb: Synced efficient-sweep-700: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9i3rqjyi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164442-9i3rqjyi/logs
2022-09-02 16:46:23,806 - wandb.wandb_agent - INFO - Cleaning up finished run: 9i3rqjyi
2022-09-02 16:46:24,080 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:46:24,089 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00018121027171736495
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:46:24,107 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00018121027171736495 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:46:29,117 - wandb.wandb_agent - INFO - Running runs: ['islq0kle']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164630-islq0kle
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-718
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/islq0kle
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2410103703521704 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1200543706104424 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.043550657129861 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▆▆▇▇▇▇▇▇▇▇▇█████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▁▁██▅▁▁█▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced unique-sweep-718: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/islq0kle
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164630-islq0kle/logs
2022-09-02 16:48:12,320 - wandb.wandb_agent - INFO - Cleaning up finished run: islq0kle
2022-09-02 16:48:12,615 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:48:12,616 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001712830552849125
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:48:12,629 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001712830552849125 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:48:17,639 - wandb.wandb_agent - INFO - Running runs: ['bkv86icq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164819-bkv86icq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-733
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bkv86icq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2509521722756545 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6013518759916785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0095338906428712 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0552519778728873 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▇▇██████▇▇▇▇▇██▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▆▇▇▆▇▆▆▇▇▇▆▆▇▇▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇██▇▇▇▇█▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▇▁▁▆▁▁▅▁▅▄▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced worthy-sweep-733: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bkv86icq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164819-bkv86icq/logs
2022-09-02 16:50:00,855 - wandb.wandb_agent - INFO - Cleaning up finished run: bkv86icq
2022-09-02 16:50:01,114 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:50:01,114 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00358511781915285
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:50:01,118 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00358511781915285 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:50:06,128 - wandb.wandb_agent - INFO - Running runs: ['yw1jwf50']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165007-yw1jwf50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-749
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yw1jwf50
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.004198146331628 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.134464042081591 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.603226736393391 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3618955074736694 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆████▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▇▇▆▇▆▇▇▇█▇▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▅▁▁▅▁▁▁▁█▁▁▁▇▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced visionary-sweep-749: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yw1jwf50
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165007-yw1jwf50/logs
2022-09-02 16:51:49,255 - wandb.wandb_agent - INFO - Cleaning up finished run: yw1jwf50
2022-09-02 16:51:49,505 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:51:49,506 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00010523208048285549
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:51:49,524 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00010523208048285549 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:51:54,545 - wandb.wandb_agent - INFO - Running runs: ['c5nsp161']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165155-c5nsp161
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-768
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c5nsp161
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.294483052992189 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.461577901518153 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.286233121319721 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3288462049116747 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇█████████▇▇▇▇▇▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▆▆▆▆▇▇▆▆▆▇▆▇▇▆▇▇█▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁▅▆██▁▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced pleasant-sweep-768: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c5nsp161
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165155-c5nsp161/logs
2022-09-02 16:53:32,487 - wandb.wandb_agent - INFO - Cleaning up finished run: c5nsp161
2022-09-02 16:53:32,730 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:53:32,730 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00042759383812977704
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:53:32,749 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00042759383812977704 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:53:37,759 - wandb.wandb_agent - INFO - Running runs: ['f9wczswx']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165337-f9wczswx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-785
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f9wczswx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4345767249378256 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.266963921924926 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.809089936143018 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0595955282777405 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6469129709595745 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▇▇▇▇▇▇▇▇▆▇▆▆▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▇▇▆▇▆▆▇▇▇▇▇▇▇▇▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁██▁▁▁▁██▁▁▅▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced good-sweep-785: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f9wczswx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165337-f9wczswx/logs
2022-09-02 16:55:20,934 - wandb.wandb_agent - INFO - Cleaning up finished run: f9wczswx
2022-09-02 16:55:21,174 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:55:21,175 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00036834551867629154
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:55:21,190 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00036834551867629154 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:55:26,200 - wandb.wandb_agent - INFO - Running runs: ['3xmaxan0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165526-3xmaxan0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-802
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3xmaxan0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.369584676076965 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3631475405044333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.042955111557955 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0164709141385107 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▂▄▅▇████▇▆▅▄▄▄▄▄▄▄▄▄
wandb:  prop_2 ██▇▇▇▆▆▅▅▆▆▆▇▇▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▃▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▂▂▂▁▁▁▁▂▃▅▆▇███████▇
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▁▁▁▁▁█▁▁▁▅▁▁▃▁█▃▅▅▆▂▇█████▇▆█▁▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.477
wandb:  prop_2 0.0
wandb:  prop_3 0.518
wandb: prop_NA 0.005
wandb:  reward 1.0
wandb: 
wandb: Synced rural-sweep-802: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3xmaxan0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165526-3xmaxan0/logs
2022-09-02 16:56:53,929 - wandb.wandb_agent - INFO - Cleaning up finished run: 3xmaxan0
2022-09-02 16:56:54,188 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:56:54,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0031172406957226933
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:56:54,207 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0031172406957226933 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:56:59,217 - wandb.wandb_agent - INFO - Running runs: ['hbgtungx']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165700-hbgtungx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-817
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hbgtungx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1773345803096884 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.859836486038947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.026245386498558 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.227887842168494 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇█▇▇▇█▇████▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇▇▇███▇█▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▇▁█▄▁▁▁▁▅▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced true-sweep-817: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hbgtungx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165700-hbgtungx/logs
2022-09-02 16:58:42,302 - wandb.wandb_agent - INFO - Cleaning up finished run: hbgtungx
2022-09-02 16:58:42,566 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:58:42,566 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.000701552937629051
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:58:42,583 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.000701552937629051 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:58:47,593 - wandb.wandb_agent - INFO - Running runs: ['lthvh2or']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165848-lthvh2or
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-833
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lthvh2or
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.478991656093742 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.001463836505108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0420307435151157 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▇██▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██████████████
wandb:  prop_3 ▇▆▇▇▇███████▇▇█▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▄█▃██▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.027
wandb:  prop_2 0.966
wandb:  prop_3 0.0
wandb: prop_NA 0.007
wandb:  reward 0.83716
wandb: 
wandb: Synced legendary-sweep-833: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lthvh2or
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165848-lthvh2or/logs
2022-09-02 17:00:25,464 - wandb.wandb_agent - INFO - Cleaning up finished run: lthvh2or
2022-09-02 17:00:25,752 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:00:25,769 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00014148347551173445
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:00:25,772 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00014148347551173445 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:00:30,781 - wandb.wandb_agent - INFO - Running runs: ['2yg7lvon']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170031-2yg7lvon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-849
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2yg7lvon
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2496440036047693 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.878335873138704 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2140135755269488 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3856584975439064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0235069940230384 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██████▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ███▇▇▇▇███▇▇▇████▇▇▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁▃▁▁▁▁▅▁▁▁█▆▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.978
wandb: prop_NA 0.022
wandb:  reward 0.92352
wandb: 
wandb: Synced stellar-sweep-849: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2yg7lvon
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170031-2yg7lvon/logs
2022-09-02 17:02:08,821 - wandb.wandb_agent - INFO - Cleaning up finished run: 2yg7lvon
2022-09-02 17:02:09,098 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:02:09,098 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008572685112251817
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:02:09,102 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008572685112251817 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:02:14,114 - wandb.wandb_agent - INFO - Running runs: ['tcjdxxdi']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170213-tcjdxxdi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-865
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tcjdxxdi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0178758894847357 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.388661204986328 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.033748942588948 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.088259315098945 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▆▆▆▆▆▇▇▇▆▆▅▅▆▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▇▇▇▇▇▇▇▇▇█▇▇██████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁█▁▁▁▁▁▇▁▁▁▁▁▁▇█▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced peachy-sweep-865: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tcjdxxdi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170213-tcjdxxdi/logs
2022-09-02 17:03:41,690 - wandb.wandb_agent - INFO - Cleaning up finished run: tcjdxxdi
2022-09-02 17:03:41,959 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:03:41,960 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0044364555652424385
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:03:41,978 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0044364555652424385 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:03:46,988 - wandb.wandb_agent - INFO - Running runs: ['g1kgefve']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170347-g1kgefve
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-879
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g1kgefve
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.244982131314132 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.335573357077123 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2229049271072823 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.635330471336597 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆███████▇▇▇▇█▇▇▇▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇█▇▇▇▇▇████████▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁█▁▁▁▄▁▁█▁▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced fresh-sweep-879: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g1kgefve
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170347-g1kgefve/logs
2022-09-02 17:05:25,383 - wandb.wandb_agent - INFO - Cleaning up finished run: g1kgefve
2022-09-02 17:05:25,684 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:05:25,684 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0011707403662900749
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:05:25,703 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0011707403662900749 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:05:30,716 - wandb.wandb_agent - INFO - Running runs: ['2hmul6xk']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170530-2hmul6xk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-895
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2hmul6xk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.064783387700232 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.07595034385701 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.301095135748257 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆██▇▇▇██████▇▇▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▆▇▁▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced zesty-sweep-895: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2hmul6xk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170530-2hmul6xk/logs
2022-09-02 17:06:58,263 - wandb.wandb_agent - INFO - Cleaning up finished run: 2hmul6xk
2022-09-02 17:06:58,560 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:06:58,561 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.002092622071304962
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:06:58,570 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.002092622071304962 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:07:03,581 - wandb.wandb_agent - INFO - Running runs: ['sx875vca']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170703-sx875vca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-910
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sx875vca
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4309054119608176 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4850887782586826 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.577889848334347 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.226203838463071 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▆▇▇▇█▇▇███▇▇▇▇█▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▇███▇▇▇▇▇▇▇▆▆▇▇▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁█▁▁▁▇▁▁▁▁▅▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced charmed-sweep-910: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sx875vca
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170703-sx875vca/logs
2022-09-02 17:08:41,540 - wandb.wandb_agent - INFO - Cleaning up finished run: sx875vca
2022-09-02 17:08:41,812 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:08:41,812 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001550711358384829
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:08:41,816 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001550711358384829 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:08:46,826 - wandb.wandb_agent - INFO - Running runs: ['8loy1i0z']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170847-8loy1i0z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-926
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8loy1i0z
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3990526119902884 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4265491565164865 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0017658165525902 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4383581931224025 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇▇▇▆▆▆▆▆▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁█▁▁▁▇▁▆█▁▁█▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced wise-sweep-926: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8loy1i0z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170847-8loy1i0z/logs
2022-09-02 17:10:22,453 - wandb.wandb_agent - INFO - Cleaning up finished run: 8loy1i0z
2022-09-02 17:10:22,740 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:10:22,741 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0491968783924216
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:10:22,749 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0491968783924216 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:10:27,759 - wandb.wandb_agent - INFO - Running runs: ['1w6yefjd']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171027-1w6yefjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-942
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1w6yefjd
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.491654833878035 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.626334378124439 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.48739024747248 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.755600590754247 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3953724718919784 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.993798801819102 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▇▆▆▇▆▆▆▆▆▆▆▆▆▅▆▆▆▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▇▇▇▇▇▆▆▇▇███▇▇▇██▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▄▄▃▁▆▁▇█▆▁▁▁█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced legendary-sweep-942: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1w6yefjd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171027-1w6yefjd/logs
2022-09-02 17:12:00,702 - wandb.wandb_agent - INFO - Cleaning up finished run: 1w6yefjd
2022-09-02 17:12:00,983 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:12:00,983 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0001331576097039726
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:12:00,986 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0001331576097039726 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:12:05,997 - wandb.wandb_agent - INFO - Running runs: ['bzz7dtpb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171206-bzz7dtpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-957
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bzz7dtpb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4440921173825947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.177408780111877 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.309910824480366 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3467025200592704 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▇██▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██████████████
wandb:  prop_3 ▅▆█▇▇▇▆▇▇▇▇▇▇▇█▇▇▇▆█▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅▄▁▁▄▁▁▄▁▆▁▁████▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced brisk-sweep-957: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bzz7dtpb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171206-bzz7dtpb/logs
2022-09-02 17:13:34,561 - wandb.wandb_agent - INFO - Cleaning up finished run: bzz7dtpb
2022-09-02 17:13:34,887 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:13:34,887 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001344054851790061
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:13:34,915 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001344054851790061 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:13:39,926 - wandb.wandb_agent - INFO - Running runs: ['65adtyp4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171341-65adtyp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-970
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/65adtyp4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.194617545145386 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3886402143447256 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.835007055325118 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.120096974424904 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.388158795251129 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇█▇▇▇▇█▇██▇████▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇████▇▇▇▇▇▇▇▇▇██▇▇▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▁▇█▁▁▁▁▁▁▁▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.945
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.055
wandb:  reward 1.0
wandb: 
wandb: Synced silver-sweep-970: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/65adtyp4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171341-65adtyp4/logs
2022-09-02 17:15:23,485 - wandb.wandb_agent - INFO - Cleaning up finished run: 65adtyp4
2022-09-02 17:15:23,964 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:15:23,964 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00010390876835601502
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:15:23,974 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00010390876835601502 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:15:28,984 - wandb.wandb_agent - INFO - Running runs: ['a1cc97ee']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171529-a1cc97ee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-993
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a1cc97ee
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3957557725804257 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.922799664451057 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0251469795915398 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.830748975752045 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2303401053037364 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇█▇▇▇▆▇▇▇█▇▇▆▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▇▇▇▇▇▇▇███▇▆▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▄▁▁▁▄▁▁▁▁▁▁▁▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced desert-sweep-993: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a1cc97ee
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171529-a1cc97ee/logs
2022-09-02 17:17:05,776 - wandb.wandb_agent - INFO - Cleaning up finished run: a1cc97ee
2022-09-02 17:17:06,072 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:17:06,073 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0003352054378952134
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:17:06,083 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0003352054378952134 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:17:11,095 - wandb.wandb_agent - INFO - Running runs: ['h9z64kef']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171710-h9z64kef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-1009
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h9z64kef
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.384619779282974 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0378551006137853 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.606523956100752 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3713591067398454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3976889384673234 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▇▆▆▆▆▆▆▇▆▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ███▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▃▁▄▇▁█▁▁█▁█▁▁▁▁▇▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced crimson-sweep-1009: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h9z64kef
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171710-h9z64kef/logs
2022-09-02 17:18:49,093 - wandb.wandb_agent - INFO - Cleaning up finished run: h9z64kef
2022-09-02 17:18:50,687 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:18:50,687 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0009130766506583088
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:18:50,695 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0009130766506583088 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:18:55,725 - wandb.wandb_agent - INFO - Running runs: ['em9s3vet']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171855-em9s3vet
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-1024
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/em9s3vet
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.408692209088043 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4018303821041336 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0824955919583794 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.87908164311448 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▅▇████████████████
wandb:  prop_2 ███▇▇▇▇▇▇▇█▇▇▆▆▆▆▇▇▆█▆▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇██▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▃▁▁▁▁▁▁█▁▁▁▁▁▁▁███▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.99
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.01
wandb:  reward 1.0
wandb: 
wandb: Synced woven-sweep-1024: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/em9s3vet
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171855-em9s3vet/logs
2022-09-02 17:20:23,300 - wandb.wandb_agent - INFO - Cleaning up finished run: em9s3vet
2022-09-02 17:20:23,579 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:20:23,579 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008996273787779159
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:20:23,585 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008996273787779159 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:20:28,595 - wandb.wandb_agent - INFO - Running runs: ['3nphl17y']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172028-3nphl17y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-1039
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3nphl17y
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.399535401182545 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.451968950401973 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.44950304669945 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▆▆▆▆▆▇▇▇▆▆▆▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ████▇▇▇▆▆▆▆▆▆▇▇▇▆▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▂▁█▁▅▁▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced denim-sweep-1039: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3nphl17y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172028-3nphl17y/logs
2022-09-02 17:21:50,968 - wandb.wandb_agent - INFO - Cleaning up finished run: 3nphl17y
2022-09-02 17:21:51,263 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:21:51,263 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00012502465682213103
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:21:51,268 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00012502465682213103 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:21:56,278 - wandb.wandb_agent - INFO - Running runs: ['bfvaet8f']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172157-bfvaet8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-1052
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bfvaet8f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4800915899840295 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4714064649403893 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.17476473687949 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1300413255448785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.965795801796222 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▆▇███▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇█▇▇▇▆▇▇▇▇▇▆▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ███████▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▁▁▁▁█▁▁▁▁▄▁▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced golden-sweep-1052: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bfvaet8f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172157-bfvaet8f/logs
2022-09-02 17:23:29,008 - wandb.wandb_agent - INFO - Cleaning up finished run: bfvaet8f
2022-09-02 17:23:29,283 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:23:29,284 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01721909989231752
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:23:29,293 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01721909989231752 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:23:34,307 - wandb.wandb_agent - INFO - Running runs: ['loptpv9q']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172336-loptpv9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-1066
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/loptpv9q
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1608379875032933 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.125264132367553 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.156348815889007 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.130891390699802 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇████▇▇▇▇▇▇██▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▆▇▇▇█████▇▇▇▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▂▂▂▁▁▁▁▂▂▂▂▂▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁██▁▁█▆▁█▄▁▁█▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced zany-sweep-1066: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/loptpv9q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172336-loptpv9q/logs
2022-09-02 17:25:07,067 - wandb.wandb_agent - INFO - Cleaning up finished run: loptpv9q
2022-09-02 17:25:07,343 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:25:07,343 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00048254188198893936
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:25:07,352 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00048254188198893936 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:25:12,363 - wandb.wandb_agent - INFO - Running runs: ['u2ylbj85']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172513-u2ylbj85
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-1082
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u2ylbj85
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2672660469231767 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2602366525057445 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.61597994153515 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇████▇▇▆▇▇██▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▄▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁▁▁▁▁█▆█▁▁▁█▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced clear-sweep-1082: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u2ylbj85
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172513-u2ylbj85/logs
2022-09-02 17:26:50,332 - wandb.wandb_agent - INFO - Cleaning up finished run: u2ylbj85
2022-09-02 17:26:50,610 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:26:50,610 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0016758805306558826
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:26:50,634 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0016758805306558826 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:26:55,645 - wandb.wandb_agent - INFO - Running runs: ['dgkjlae5']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172656-dgkjlae5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-1098
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dgkjlae5
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.372532553343455 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.351051135807966 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.692388153202943 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▅▆▇▇█▇▇▆▆▆▇▇████▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▁▃▁▁▁▁▁▁▁█▇▇▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced decent-sweep-1098: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dgkjlae5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172656-dgkjlae5/logs
2022-09-02 17:28:34,124 - wandb.wandb_agent - INFO - Cleaning up finished run: dgkjlae5
2022-09-02 17:28:34,427 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:28:34,427 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.014632447980680544
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:28:34,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.014632447980680544 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:28:39,447 - wandb.wandb_agent - INFO - Running runs: ['xyqe51is']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172841-xyqe51is
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-1114
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xyqe51is
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.191691088555923 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1159603841507773 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.520420033365495 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.263205824165304 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇██▇▇▆▆▇▇▇▇▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▆▆▆▆▇▇▇█▇▇▆▆▇▇▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██████▇▇▇▇▇█▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▄▁▁▁▁█▁█▁▁▁▇▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced tough-sweep-1114: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xyqe51is
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172841-xyqe51is/logs
2022-09-02 17:30:12,276 - wandb.wandb_agent - INFO - Cleaning up finished run: xyqe51is
2022-09-02 17:30:12,638 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:30:12,640 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03026075793543994
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:30:12,643 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03026075793543994 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:30:17,653 - wandb.wandb_agent - INFO - Running runs: ['s6ak1o67']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173016-s6ak1o67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-1132
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/s6ak1o67
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.297936228704515 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.801065231870332 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1124048347887516 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.180930366615267 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.469009113835739 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▆▆▆▅▅▅▆▆▆▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▅▇▇▇██▇▇▆▆▇▇█▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁████▁▁▁▁▁▇▁▁▁▁▁▁▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced wild-sweep-1132: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/s6ak1o67
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173016-s6ak1o67/logs
2022-09-02 17:31:45,270 - wandb.wandb_agent - INFO - Cleaning up finished run: s6ak1o67
2022-09-02 17:31:45,571 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:31:45,571 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0007709736607330965
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:31:45,578 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0007709736607330965 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:31:50,588 - wandb.wandb_agent - INFO - Running runs: ['3tohzyel']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173149-3tohzyel
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-1146
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3tohzyel
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.284668956328095 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.146785478484094 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3065310490653914 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.377716181090895 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1228279899333216 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.319521649200227 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▄▆▇█████████
wandb:  prop_2 █▇▆▆▆▆▇▇▇▇▇▇▆▆▆▅▅▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███▇▆▅▄▃▄▄▄▄▄▄▄▄
wandb: prop_NA ███▇▇█▇██▇█▇▇███████▇▅▄▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:  reward ▁██▁▇▁▁▁▁▁▁▇▄▆▅▅▇▆▇▁▅▄▄▆█▅████▁█▇▆██▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.52
wandb:  prop_2 0.0
wandb:  prop_3 0.474
wandb: prop_NA 0.006
wandb:  reward 1.0
wandb: 
wandb: Synced clear-sweep-1146: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3tohzyel
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173149-3tohzyel/logs
2022-09-02 17:33:07,820 - wandb.wandb_agent - INFO - Cleaning up finished run: 3tohzyel
2022-09-02 17:33:08,140 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:33:08,140 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.006955234367595507
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:33:08,146 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.006955234367595507 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:33:13,157 - wandb.wandb_agent - INFO - Running runs: ['iw66bfs8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173313-iw66bfs8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-1160
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iw66bfs8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.028764666148536 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.769926782593195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2185330539043138 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.118899513959687 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇████▇▆▆▆▇▇▇▇▆▇▇█▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▆▆▇▇▇▇▆▆▆▇███▇▇▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▂▁▁█▅▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced stellar-sweep-1160: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iw66bfs8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173313-iw66bfs8/logs
2022-09-02 17:34:35,593 - wandb.wandb_agent - INFO - Cleaning up finished run: iw66bfs8
2022-09-02 17:34:36,103 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:34:36,108 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03414790241777318
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:34:36,118 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03414790241777318 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:34:41,128 - wandb.wandb_agent - INFO - Running runs: ['ijp42gln']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173442-ijp42gln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-1172
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ijp42gln
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.319748269243937 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.272619192930031 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▇▆▇▇▇▇█▇██▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▇▆▇▇██▇▇▇██▇▇▇▇█▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁██▁▆▁▁▁▁▁█▇▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced usual-sweep-1172: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ijp42gln
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173442-ijp42gln/logs
2022-09-02 17:36:08,685 - wandb.wandb_agent - INFO - Cleaning up finished run: ijp42gln
2022-09-02 17:36:08,997 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:36:08,997 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00025663054456237955
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:36:09,003 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00025663054456237955 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:36:14,013 - wandb.wandb_agent - INFO - Running runs: ['ivyd1xhb']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173613-ivyd1xhb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-1190
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ivyd1xhb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.057284002187591 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.754187035565782 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2092656650900193 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.99653369547218 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▇▇▇▇▇██▇█▇▇▇▇▇▇█▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▆▇▇██▇▇▆▇▇▇▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁██▅▁▁▁▁▁▁▁▁▆███▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced crisp-sweep-1190: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ivyd1xhb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173613-ivyd1xhb/logs
2022-09-02 17:37:41,510 - wandb.wandb_agent - INFO - Cleaning up finished run: ivyd1xhb
2022-09-02 17:37:41,937 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:37:41,937 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011995321414024512
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:37:41,942 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011995321414024512 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:37:46,951 - wandb.wandb_agent - INFO - Running runs: ['qee9hqww']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173747-qee9hqww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-1205
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qee9hqww
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.035343935381291 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0648431304811075 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0087895607863415 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.482022851784179 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.229410060316905 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▆▆▆▆▇▇▆▆▆▆▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▃▁▁▇▁▁▁█▁▁▁█▁▇▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fancy-sweep-1205: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qee9hqww
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173747-qee9hqww/logs
2022-09-02 17:39:09,332 - wandb.wandb_agent - INFO - Cleaning up finished run: qee9hqww
2022-09-02 17:39:09,659 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:39:09,659 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.001995772464986691
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:39:09,670 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.001995772464986691 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:39:14,679 - wandb.wandb_agent - INFO - Running runs: ['6o957oft']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173915-6o957oft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-1218
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6o957oft
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4736003146904326 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.862722280398454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1309319743740183 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1848274761968565 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.133044791733763 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.92775053445296 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇████████▇▇▇▇▇▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇██▇▇▇█▇█▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████▇██████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▁▁▄▁▁▁██▁▁▁▅▁▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.983
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.017
wandb:  reward 1.0
wandb: 
wandb: Synced deft-sweep-1218: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6o957oft
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173915-6o957oft/logs
2022-09-02 17:40:37,214 - wandb.wandb_agent - INFO - Cleaning up finished run: 6o957oft
2022-09-02 17:40:37,546 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:40:37,546 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00908850286051668
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:40:37,551 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00908850286051668 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:40:42,564 - wandb.wandb_agent - INFO - Running runs: ['rilbky26']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174043-rilbky26
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-1230
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rilbky26
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.323011009230996 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3215120016330735 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3981067385664905 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.148235925688454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.150870451579365 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.646266033227219 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▅▆▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▆▆▆▆▅▅▆▅▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▁▁▁▁▇▇▁▁▁▅▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced smooth-sweep-1230: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rilbky26
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174043-rilbky26/logs
2022-09-02 17:42:04,910 - wandb.wandb_agent - INFO - Cleaning up finished run: rilbky26
2022-09-02 17:42:06,579 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:42:06,586 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01966336361814896
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:42:06,625 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01966336361814896 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:42:11,642 - wandb.wandb_agent - INFO - Running runs: ['l3elrw8f']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174213-l3elrw8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-1242
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l3elrw8f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1602976655436117 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.696411069290848 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4610397500476187 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.688978985209274 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.149078462056848 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.200694454504772 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇█▇▇▇▇▇▇█▇▇▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▅▇▇▇▇▇▇▇▇█▇██▇▆▆▆▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇███████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▁▃▅▁▁▁▁█▁▁▁▆▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dauntless-sweep-1242: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l3elrw8f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174213-l3elrw8f/logs
2022-09-02 17:43:34,245 - wandb.wandb_agent - INFO - Cleaning up finished run: l3elrw8f
2022-09-02 17:43:34,536 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:43:34,536 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.005617297658653803
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:43:34,550 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.005617297658653803 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:43:39,563 - wandb.wandb_agent - INFO - Running runs: ['852xd5gm']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174341-852xd5gm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1257
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/852xd5gm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2059468412983945 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.409440518622205 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1320239208357608 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.82794294441616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.104458572250376 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▇▇▇▇▇▇██████▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▅▆▆▅▆▆▇▆▇▇▇███▇▇█▇▆▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████▇▇▇▇▇▇▇██▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁█▁▁▁▆█▇▁▁▁█▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced copper-sweep-1257: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/852xd5gm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174341-852xd5gm/logs
2022-09-02 17:45:07,170 - wandb.wandb_agent - INFO - Cleaning up finished run: 852xd5gm
2022-09-02 17:45:07,458 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:45:07,458 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001683315493313288
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:45:07,461 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001683315493313288 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:45:12,474 - wandb.wandb_agent - INFO - Running runs: ['7dn4l8su']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174512-7dn4l8su
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-1273
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7dn4l8su
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2827295749700243 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.921884939771563 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1990563313663936 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.763540433852141 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3130393521083095 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.189776884324165 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇█▇▇▆▆▆▆▇▇▇▇▇████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▆▇████████████████
wandb:  prop_3 ██▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁▅▄▁█▁█▁▁▁▆▃▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced elated-sweep-1273: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7dn4l8su
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174512-7dn4l8su/logs
2022-09-02 17:46:39,992 - wandb.wandb_agent - INFO - Cleaning up finished run: 7dn4l8su
2022-09-02 17:46:40,311 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:46:40,320 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00022067361069096384
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:46:40,344 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00022067361069096384 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:46:45,358 - wandb.wandb_agent - INFO - Running runs: ['huia103e']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174646-huia103e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-1287
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/huia103e
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.328668901349182 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3087332446765316 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.696503301050377 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0580460360844977 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.771810087294434 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2029675375137705 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.841710567086342 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▆▇▇▇█▇█▇▇▇▇█▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▆▅▅▅▆▇▇▇▇▇▇██▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇▇▇█████▇▇▇▇▇█▇▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▁▁▁▄▁▁█▁▁▁▁▁▁▇▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced feasible-sweep-1287: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/huia103e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174646-huia103e/logs
2022-09-02 17:48:12,864 - wandb.wandb_agent - INFO - Cleaning up finished run: huia103e
2022-09-02 17:48:13,161 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:48:13,162 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0017183948875252415
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:48:13,171 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0017183948875252415 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:48:18,185 - wandb.wandb_agent - INFO - Running runs: ['6pfh0l7d']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174819-6pfh0l7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-1300
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6pfh0l7d
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1682937904431885 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.575008499771969 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2971542360444634 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.473739193861015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.481803685384534 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▆▆▇▇▇▇▇▇███▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▄▁▁▁▁▁▂██▁▅▁▇▃▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced solar-sweep-1300: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6pfh0l7d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174819-6pfh0l7d/logs
2022-09-02 17:49:40,597 - wandb.wandb_agent - INFO - Cleaning up finished run: 6pfh0l7d
2022-09-02 17:49:40,884 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:49:40,884 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0027355049713394092
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:49:40,886 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0027355049713394092 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:49:45,899 - wandb.wandb_agent - INFO - Running runs: ['sqskoay9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174946-sqskoay9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-1314
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sqskoay9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441705401410503 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.561845291018786 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.002471637221279 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.588551143260448 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.372312113941481 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.340316163427933 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▆▇▇▇▇▆▆▇███▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▄▆▆▆▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▅███▁█▁▁█▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.971
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.029
wandb:  reward 1.0
wandb: 
wandb: Synced chocolate-sweep-1314: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sqskoay9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174946-sqskoay9/logs
2022-09-02 17:51:08,350 - wandb.wandb_agent - INFO - Cleaning up finished run: sqskoay9
2022-09-02 17:51:08,616 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:51:08,616 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00012898697946593058
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:51:08,625 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00012898697946593058 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:51:13,639 - wandb.wandb_agent - INFO - Running runs: ['43d5e629']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175115-43d5e629
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-1327
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/43d5e629
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0217489719274706 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4772409919845093 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.97778820830597 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.450950528457242 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.658518664436601 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0723989726178824 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.720353792328414 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇██████████████▇▇
wandb:  prop_2 ▇▆▆▆▆▆▆▆▇▆▆▆▆▆▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇███▇███▇▇▇▇███▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▂▃▄▆█
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▇▁▁▆██▁█▁▁▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.871
wandb:  prop_2 0.0
wandb:  prop_3 0.127
wandb: prop_NA 0.002
wandb:  reward 1.0
wandb: 
wandb: Synced ethereal-sweep-1327: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/43d5e629
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175115-43d5e629/logs
2022-09-02 17:52:36,843 - wandb.wandb_agent - INFO - Cleaning up finished run: 43d5e629
2022-09-02 17:52:37,128 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:52:37,128 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011450625231066802
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:52:37,161 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011450625231066802 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:52:42,179 - wandb.wandb_agent - INFO - Running runs: ['3hlav4wp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175243-3hlav4wp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-1341
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3hlav4wp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3789833048866944 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.194974981335101 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2511924859498733 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.486430787387609 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▆▆▇▇▆▆▆▆▇▇▇█▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁██▁▄▃▅▁▁▇▄▁█▁▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced cosmic-sweep-1341: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3hlav4wp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175243-3hlav4wp/logs
2022-09-02 17:54:09,826 - wandb.wandb_agent - INFO - Cleaning up finished run: 3hlav4wp
2022-09-02 17:54:10,120 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:54:10,121 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.001281899181605589
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:54:10,124 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.001281899181605589 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:54:15,136 - wandb.wandb_agent - INFO - Running runs: ['bot2ouhs']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175414-bot2ouhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-1359
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bot2ouhs
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.09355776429977 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1269109502103687 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.404735714484577 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1490095648848797 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.941220379875507 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.025452358984517 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.643445052547497 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇▇▇██▇█▇████▇███▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆█▇▇█▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇███████▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁██▁▁▆█▁▁█▁▁▇▁▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced effortless-sweep-1359: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bot2ouhs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175414-bot2ouhs/logs
2022-09-02 17:55:37,528 - wandb.wandb_agent - INFO - Cleaning up finished run: bot2ouhs
2022-09-02 17:55:37,798 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:55:37,799 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006919129793072372
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:55:37,807 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006919129793072372 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:55:42,821 - wandb.wandb_agent - INFO - Running runs: ['vcmbipa9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175542-vcmbipa9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-1372
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vcmbipa9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.06773170865098 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.21474628680063 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1937603404819788 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.298433617092692 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.232187939209855 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.251795024527615 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇▇▇▇▇▇████▇▇▆▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▆▆▆▆▇██▇▇▆▆▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb: prop_NA ███████████▇█████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄█▁▁▁█▁▁▁█▇▁▆█▁▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced golden-sweep-1372: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vcmbipa9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175542-vcmbipa9/logs
2022-09-02 17:57:01,311 - wandb.wandb_agent - INFO - Cleaning up finished run: vcmbipa9
2022-09-02 17:57:01,574 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:57:01,575 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00010362753948460062
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:57:01,583 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00010362753948460062 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:57:06,596 - wandb.wandb_agent - INFO - Running runs: ['0aansgog']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175707-0aansgog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-1385
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0aansgog
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4355017419577782 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1010064030026254 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.382256829024092 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.916069206410378 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇█▇▇▆▇▇▇█▇▇█▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▇▇▇▇▆▆▆▆▇▇▇▆▇████▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▄▄▁▅▁▁▁▄▁▁▁▇▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced electric-sweep-1385: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0aansgog
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175707-0aansgog/logs
2022-09-02 17:58:34,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 0aansgog
2022-09-02 17:58:34,686 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:58:34,686 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004630013769433322
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:58:34,700 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004630013769433322 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:58:39,713 - wandb.wandb_agent - INFO - Running runs: ['kzbk2m2m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175839-kzbk2m2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-1400
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kzbk2m2m
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2468535630170474 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.577095346432884 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4080840733365743 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.777230829342313 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▇▇▇▆▆▆▆▆▆▆▅▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▅▅▆▆▇▇▆▆▆▇████▇█▇▇█▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁▁█▁▅▁▁▁██▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced robust-sweep-1400: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kzbk2m2m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175839-kzbk2m2m/logs
2022-09-02 18:00:07,381 - wandb.wandb_agent - INFO - Cleaning up finished run: kzbk2m2m
2022-09-02 18:00:07,675 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:00:07,711 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0029488529366523196
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:00:07,715 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0029488529366523196 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:00:12,728 - wandb.wandb_agent - INFO - Running runs: ['rzy4rrty']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180013-rzy4rrty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-1417
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rzy4rrty
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3845751982233803 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1740266598792877 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.632982827582932 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0684075728111058 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.965380753114274 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.476532390431924 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.830521283367405 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▆▆▇▇▇█▇█▇▇▇█▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▆▆▆▆▆▇▆▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▇▁▁▃█▆▁▇▅▁█▁▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced radiant-sweep-1417: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rzy4rrty
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180013-rzy4rrty/logs
2022-09-02 18:01:40,211 - wandb.wandb_agent - INFO - Cleaning up finished run: rzy4rrty
2022-09-02 18:01:41,786 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:01:41,789 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.013092036914578636
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:01:41,796 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.013092036914578636 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:01:46,809 - wandb.wandb_agent - INFO - Running runs: ['o9l1u7mb']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180146-o9l1u7mb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-1433
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o9l1u7mb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.300179287074851 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0782019175253077 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.892062992932629 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3954250933663754 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4754874839736254 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇████▇█▇▇▇███▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▇▇▇▇▇▇████▇██▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁█▄▁▁█▁█▁▇▁▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dazzling-sweep-1433: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o9l1u7mb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180146-o9l1u7mb/logs
2022-09-02 18:03:09,661 - wandb.wandb_agent - INFO - Cleaning up finished run: o9l1u7mb
2022-09-02 18:03:09,949 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:03:09,989 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.010080201570433165
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:03:09,995 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.010080201570433165 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:03:15,008 - wandb.wandb_agent - INFO - Running runs: ['q6d3e490']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180314-q6d3e490
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-1445
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q6d3e490
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.465610428181496 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.41507120861674 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.168331376684724 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2767464477390527 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3066098475935224 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.041404343969833 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇█▇███▇▇▇▆▇▇█▇▆▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇███▇▅▄▃▃▃▂▂▂▂▂▃▃
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▅▆▇█▇█████▇▇
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▂▁▂▂▂▂▂▂▂▂
wandb:  reward ▁▁▁▁▁▁▁▅▁▁▁▁▅█▁█▁▁▁▁▂███▇█▁████▄▇▆██▃▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.335
wandb:  prop_3 0.594
wandb: prop_NA 0.071
wandb:  reward 0.92352
wandb: 
wandb: Synced flowing-sweep-1445: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q6d3e490
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180314-q6d3e490/logs
2022-09-02 18:04:37,508 - wandb.wandb_agent - INFO - Cleaning up finished run: q6d3e490
2022-09-02 18:04:37,819 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:04:37,822 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0014485091684003646
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:04:37,826 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0014485091684003646 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:04:42,839 - wandb.wandb_agent - INFO - Running runs: ['08hoj51f']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180442-08hoj51f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-1460
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/08hoj51f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.16264018297261 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0274297600497198 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.463970298997928 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4810023902315628 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.125267187494972 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.925863333634003 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▆▆▆▇▇█▇█▇█▇▇▇▇██▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▇▇▇█▇▇▇▇▇███▇▇▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▄█▁▁▁▁▇█▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.964
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.036
wandb:  reward 1.0
wandb: 
wandb: Synced denim-sweep-1460: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/08hoj51f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180442-08hoj51f/logs
2022-09-02 18:06:10,113 - wandb.wandb_agent - INFO - Cleaning up finished run: 08hoj51f
2022-09-02 18:06:11,973 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:06:11,979 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0028183401028345416
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:06:11,987 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0028183401028345416 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:06:17,001 - wandb.wandb_agent - INFO - Running runs: ['0kkuvj6v']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180616-0kkuvj6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-1478
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0kkuvj6v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2850494559970587 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.421229584698062 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4169177854286255 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3882285897619457 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1037378547558236 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.985067346173897 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇██▇▇▇████████▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▅▁▁▁▁▁██▁▇▇▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.992
wandb:  prop_3 0.0
wandb: prop_NA 0.008
wandb:  reward 0.83716
wandb: 
wandb: Synced brisk-sweep-1478: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0kkuvj6v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180616-0kkuvj6v/logs
2022-09-02 18:07:46,258 - wandb.wandb_agent - INFO - Cleaning up finished run: 0kkuvj6v
2022-09-02 18:07:46,537 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:07:46,538 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00031779815632305595
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:07:46,544 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00031779815632305595 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:07:51,557 - wandb.wandb_agent - INFO - Running runs: ['olmy98k9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180751-olmy98k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-1493
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/olmy98k9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3901852811274145 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0680255349241397 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.983767250631345 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.14666069075296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4054322570399833 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇████▇██████▇▇██▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ██▇▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁█▁▅██▁▁▁▁▁▁▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced different-sweep-1493: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/olmy98k9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180751-olmy98k9/logs
2022-09-02 18:09:08,949 - wandb.wandb_agent - INFO - Cleaning up finished run: olmy98k9
2022-09-02 18:09:09,297 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:09:09,297 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.004771637878379905
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:09:09,303 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.004771637878379905 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:09:14,317 - wandb.wandb_agent - INFO - Running runs: ['xnjl2t7q']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180913-xnjl2t7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-1506
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xnjl2t7q
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2970171688077676 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2964725879864645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3851960557654976 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.384094058145175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.390290014619279 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▆▇▇▇▆▆▆▆▆▆▆▆▆▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▇▇▇▇▇▇▇▆▆▇▇█▇█▇▇▇▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁▁▁▇▁▁▁▅▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced comfy-sweep-1506: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xnjl2t7q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180913-xnjl2t7q/logs
2022-09-02 18:10:33,367 - wandb.wandb_agent - INFO - Cleaning up finished run: xnjl2t7q
2022-09-02 18:10:33,712 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:10:33,712 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00025500929842832025
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:10:33,716 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00025500929842832025 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:10:38,729 - wandb.wandb_agent - INFO - Running runs: ['3on5rsjx']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181038-3on5rsjx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-1518
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3on5rsjx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.180526795984199 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.175732262391372 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4948016829932755 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3100792149240443 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.016944922631298 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇████▇▇▆▇▆▇▇▇▇▇▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇████▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███▇███████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▇█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced chocolate-sweep-1518: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3on5rsjx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181038-3on5rsjx/logs
2022-09-02 18:12:01,214 - wandb.wandb_agent - INFO - Cleaning up finished run: 3on5rsjx
2022-09-02 18:12:02,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:12:02,881 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00020867320323363208
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:12:02,888 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00020867320323363208 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:12:07,901 - wandb.wandb_agent - INFO - Running runs: ['vo0id5t3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181209-vo0id5t3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1529
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vo0id5t3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1781955887438267 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.976857584189316 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0023470206071594 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0305398616438852 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7066124382267125 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆██▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▃▅▇████████████
wandb:  prop_3 ▆▆▆▆▇▇▇█▇██▇▇▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▄█▁▁▁█▁▆▅█▁▁▁██▃▅▅▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.999
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 0.83716
wandb: 
wandb: Synced copper-sweep-1529: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vo0id5t3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181209-vo0id5t3/logs
2022-09-02 18:13:30,322 - wandb.wandb_agent - INFO - Cleaning up finished run: vo0id5t3
2022-09-02 18:13:30,602 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:13:30,602 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.03785586714169126
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:13:30,612 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.03785586714169126 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:13:35,628 - wandb.wandb_agent - INFO - Running runs: ['7j3adxi2']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181337-7j3adxi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-1544
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7j3adxi2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2687520124891924 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.015263317246205 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3100455899636474 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1433640890253662 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.073747142817244 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▆▆▆▆▇▆▇▇▇▇▇▇▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▆▇▆▆▆▆▇▇▇████▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████▇▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▅▁▁▁▁▁▁▁▁▁█▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glad-sweep-1544: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7j3adxi2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181337-7j3adxi2/logs
2022-09-02 18:14:58,178 - wandb.wandb_agent - INFO - Cleaning up finished run: 7j3adxi2
2022-09-02 18:14:58,454 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:14:58,454 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001803095258855311
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:14:58,470 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001803095258855311 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:15:03,484 - wandb.wandb_agent - INFO - Running runs: ['84ikesk1']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181505-84ikesk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-1558
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/84ikesk1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.081882916713223 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.214042407845892 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3203432801635855 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.572045315111328 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3017126001795947 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ██▇▇▇▇▇▆▆▆▇▇▇▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▇▃▁▁███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced daily-sweep-1558: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/84ikesk1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181505-84ikesk1/logs
2022-09-02 18:16:31,478 - wandb.wandb_agent - INFO - Cleaning up finished run: 84ikesk1
2022-09-02 18:16:31,764 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:16:31,764 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001434698638654034
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:16:31,766 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001434698638654034 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:16:36,779 - wandb.wandb_agent - INFO - Running runs: ['cum9i7r9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181636-cum9i7r9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-1574
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cum9i7r9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.141133342612197 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.794130187062337 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.249706690064392 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2621370678022306 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇█▇▇▇▇▇▇███▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▇▇█▇██▇▇███████▇▇▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▁▁▁█▁▁▁██▁▄▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced deft-sweep-1574: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cum9i7r9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181636-cum9i7r9/logs
2022-09-02 18:18:04,394 - wandb.wandb_agent - INFO - Cleaning up finished run: cum9i7r9
2022-09-02 18:18:04,672 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:18:04,672 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00024617831361474263
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:18:04,675 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00024617831361474263 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:18:09,688 - wandb.wandb_agent - INFO - Running runs: ['pebpqxe7']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181809-pebpqxe7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-1588
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pebpqxe7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3038025029637375 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.119644963101445 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.314344684605367 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3321546265648196 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▆▆▆▆▆▆▆▆▇▇▇▆▆▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▄█▁▁▁▁▁▁█▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced rosy-sweep-1588: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pebpqxe7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181809-pebpqxe7/logs
2022-09-02 18:19:38,275 - wandb.wandb_agent - INFO - Cleaning up finished run: pebpqxe7
2022-09-02 18:19:38,566 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:19:38,566 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.014695694691649686
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:19:38,569 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.014695694691649686 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:19:43,581 - wandb.wandb_agent - INFO - Running runs: ['0o9xnff5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181943-0o9xnff5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-1604
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0o9xnff5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.311068449728018 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1060357238895495 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2399534145755275 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0088337297930527 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.554816639860749 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1011019730012084 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.327166672239175 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▆▇▇▇█▇▇▇▆▆▆▆▇█▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇▇▇▇███▇▇▇▆▆▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇████▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▃▁█▁▅▁▁▁▂▁▁█▅▁█▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced charmed-sweep-1604: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0o9xnff5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181943-0o9xnff5/logs
2022-09-02 18:21:11,321 - wandb.wandb_agent - INFO - Cleaning up finished run: 0o9xnff5
2022-09-02 18:21:11,616 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:21:11,616 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03200694638826543
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:21:11,622 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03200694638826543 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:21:16,634 - wandb.wandb_agent - INFO - Running runs: ['lqlhoqze']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182115-lqlhoqze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-1620
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lqlhoqze
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.190451852699616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3251380343578996 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.427778462606385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3640597510217978 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▇▇▇▇▇▇▇▇██▇▇▆▇▇▇▇▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ██▇▇▆▆▆▅▅▆▅▆▆▆▆▆▆▆▅▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██▇▇██████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃█▄▁█▁▆▁▁█▁█▅▁▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced treasured-sweep-1620: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lqlhoqze
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182115-lqlhoqze/logs
2022-09-02 18:22:44,147 - wandb.wandb_agent - INFO - Cleaning up finished run: lqlhoqze
2022-09-02 18:22:44,435 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:22:44,438 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0037551404164655623
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:22:44,445 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0037551404164655623 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:22:49,459 - wandb.wandb_agent - INFO - Running runs: ['bqrmrq1c']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182250-bqrmrq1c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-1637
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bqrmrq1c
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4700485162000274 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.987343148467224 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.433491187876847 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.062314668710449 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1288824804484117 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▆▇▇██▇▇▇▇█▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▆▅▅▅▆▆▆▇▆▇▆▆▆▆▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████████▇▇▇▇▇██████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▂█▁▁▁▇█▁▁█▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced feasible-sweep-1637: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bqrmrq1c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182250-bqrmrq1c/logs
2022-09-02 18:24:17,175 - wandb.wandb_agent - INFO - Cleaning up finished run: bqrmrq1c
2022-09-02 18:25:18,582 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:25:18,584 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0002825914835532078
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:25:18,596 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0002825914835532078 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:25:23,609 - wandb.wandb_agent - INFO - Running runs: ['kup6vtpz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182525-kup6vtpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-1658
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kup6vtpz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.234478445543576 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.121575351174704 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0687450589266345 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▆▇███▇▇▇▆▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▆▆▆▅▆▆▆▆▅▅▅▆▆▅▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ███████▇▇█████▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▁▁▁▁▁▁▅▁█▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced ethereal-sweep-1658: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kup6vtpz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182525-kup6vtpz/logs
2022-09-02 18:26:51,177 - wandb.wandb_agent - INFO - Cleaning up finished run: kup6vtpz
2022-09-02 18:26:51,487 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:26:51,487 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0449007099739106
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:26:51,496 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0449007099739106 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:26:56,509 - wandb.wandb_agent - INFO - Running runs: ['5qlfph4p']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182658-5qlfph4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-1673
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5qlfph4p
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2695202223162667 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.457572022971643 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.509021288731985 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0854255768870447 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.071078630978865 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▇▇███▇▇▆▆▆▇▆▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▆▆▆▇▇▇▇▆▆▆▆▆▆▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇█▇▇███████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁█▂▁▃█▁▇▁▁▁▁▁███▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced exalted-sweep-1673: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5qlfph4p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182658-5qlfph4p/logs
2022-09-02 18:28:24,107 - wandb.wandb_agent - INFO - Cleaning up finished run: 5qlfph4p
2022-09-02 18:28:24,428 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:28:24,428 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001076431214370915
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:28:24,438 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001076431214370915 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:28:29,459 - wandb.wandb_agent - INFO - Running runs: ['o0f5hhes']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182830-o0f5hhes
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-1688
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o0f5hhes
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.393179181269925 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9962729838560795 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1720250071014173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9443776889087605 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.107377648177797 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ██▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▆▇▇▆▆▅▅▅▆▆▇▇▇▇▇▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅▁▁▂▄▁▅▁▁█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced exalted-sweep-1688: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o0f5hhes
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182830-o0f5hhes/logs
2022-09-02 18:29:57,245 - wandb.wandb_agent - INFO - Cleaning up finished run: o0f5hhes
2022-09-02 18:29:57,544 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:29:57,544 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.019260616553676776
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:29:57,579 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.019260616553676776 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:30:02,592 - wandb.wandb_agent - INFO - Running runs: ['y5z45uo6']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183004-y5z45uo6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-1702
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y5z45uo6
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.329877400317361 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.369823015138168 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1898273373530337 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.405595663772602 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0768930373084267 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██▇█▇▇█▇▇▇▇▇▇██▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▆▇▆▆▇▆▇▇▇▆▆▇▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁█▁▁▇█▁▁██▇▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dainty-sweep-1702: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y5z45uo6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183004-y5z45uo6/logs
2022-09-02 18:31:30,286 - wandb.wandb_agent - INFO - Cleaning up finished run: y5z45uo6
2022-09-02 18:31:30,577 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:31:30,577 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.02527222602235472
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:31:30,582 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.02527222602235472 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:31:35,596 - wandb.wandb_agent - INFO - Running runs: ['tgjxf98y']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183136-tgjxf98y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-1718
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tgjxf98y
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2366580628962285 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.429806099787891 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3752201307707566 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0654186943186557 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.826512419436262 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇████▇▇▇▇▇▇█▇▇▇▇█▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▆▆▆▇▇▇████▇▇▆▆▆▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁█▁▁▁▁▁▁▇▄▁▁▁█▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced swept-sweep-1718: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tgjxf98y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183136-tgjxf98y/logs
2022-09-02 18:32:58,038 - wandb.wandb_agent - INFO - Cleaning up finished run: tgjxf98y
2022-09-02 18:32:58,665 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:32:58,665 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.002061068699145305
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:32:58,669 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.002061068699145305 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:33:03,682 - wandb.wandb_agent - INFO - Running runs: ['3oecp6po']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183304-3oecp6po
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-1732
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3oecp6po
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.263381209103613 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.861361663699979 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.271915838642601 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7069606175125696 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.209401490980618 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.845298494268664 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇██▇▇▇▇▇███▇█▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA █▇▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁█▁▁▁▁█▁▁▁█▁▁▇▇▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced revived-sweep-1732: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3oecp6po
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183304-3oecp6po/logs
2022-09-02 18:34:26,324 - wandb.wandb_agent - INFO - Cleaning up finished run: 3oecp6po
2022-09-02 18:34:26,622 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:34:26,622 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00141556360837503
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:34:26,637 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00141556360837503 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:34:31,650 - wandb.wandb_agent - INFO - Running runs: ['v7w30lcb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183432-v7w30lcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-1745
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v7w30lcb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1072483289988733 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.042448797328964 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3151143961128993 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.921941145184618 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2595218511098163 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9643856553962316 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇█████████████▇▇▇
wandb:  prop_2 ███▇▇▆▆▆▆▆▆▅▆▇▆▇▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▆▆▇▇▇▇█▇▇█▇▇▇██▇█▇▇▅▄▂▁▁▁▂▂▂▂▁▂▂▂▃▃▄▄▅
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▅▁▁▁▁▆█▇▁▆█▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.892
wandb:  prop_2 0.0
wandb:  prop_3 0.075
wandb: prop_NA 0.033
wandb:  reward 1.0
wandb: 
wandb: Synced upbeat-sweep-1745: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v7w30lcb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183432-v7w30lcb/logs
2022-09-02 18:35:59,313 - wandb.wandb_agent - INFO - Cleaning up finished run: v7w30lcb
2022-09-02 18:35:59,622 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:35:59,622 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.030059324059053916
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:35:59,625 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.030059324059053916 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:36:04,638 - wandb.wandb_agent - INFO - Running runs: ['zut51x7j']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183604-zut51x7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-1763
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zut51x7j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1302767273711094 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1505770710089074 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.761077319348807 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.400312571389441 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.942635156646131 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▆▇▆▆▆▇▇██▇▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▄▆▆▆▇▇▇▇▇▆▇███▇▇▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁▁▁▁▄█▁▁▇█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced polar-sweep-1763: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zut51x7j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183604-zut51x7j/logs
2022-09-02 18:37:21,919 - wandb.wandb_agent - INFO - Cleaning up finished run: zut51x7j
2022-09-02 18:37:22,214 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:37:22,214 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.005133353728004825
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:37:22,217 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.005133353728004825 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:37:27,231 - wandb.wandb_agent - INFO - Running runs: ['09dk2ai1']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183727-09dk2ai1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-1775
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/09dk2ai1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3409477719351037 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.497121026753452 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.785258753288857 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇████████████████▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁▁▁▁▁▁▁▁▁▂▄▁█▁██▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sweepy-sweep-1775: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/09dk2ai1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183727-09dk2ai1/logs
2022-09-02 18:39:00,219 - wandb.wandb_agent - INFO - Cleaning up finished run: 09dk2ai1
2022-09-02 18:39:00,517 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:39:00,517 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005726374984158004
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:39:00,525 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005726374984158004 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:39:05,538 - wandb.wandb_agent - INFO - Running runs: ['cesqk65e']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183905-cesqk65e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-1794
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cesqk65e
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.40356374446934 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.063975808705229 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.305959955407296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.076256673782957 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.302497495619126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.21163025195765 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇█▇▇▇▆▇▆▆▇▇▆▇▇▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇██▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁▁▁▁▁▁▁█▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced drawn-sweep-1794: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cesqk65e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183905-cesqk65e/logs
2022-09-02 18:40:27,959 - wandb.wandb_agent - INFO - Cleaning up finished run: cesqk65e
2022-09-02 18:40:28,274 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:40:28,274 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00031986626924123866
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:40:28,280 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00031986626924123866 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:40:33,293 - wandb.wandb_agent - INFO - Running runs: ['bfz45tli']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184032-bfz45tli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-1807
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bfz45tli
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0659082235514226 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.240344331093288 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0658854134417015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.887407673178028 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.123617850844677 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.590482523684063 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇█▇████▇▇▇▇▇▇▆▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▇▇▇█▇▇▇▇▇▇███▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▇▁▁▅▁▁▁▁█▆▁▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced quiet-sweep-1807: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bfz45tli
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184032-bfz45tli/logs
2022-09-02 18:41:50,639 - wandb.wandb_agent - INFO - Cleaning up finished run: bfz45tli
2022-09-02 18:41:50,948 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:41:50,948 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0033303198826006987
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:41:50,959 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0033303198826006987 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:41:55,972 - wandb.wandb_agent - INFO - Running runs: ['x9qc3oub']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184156-x9qc3oub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-1817
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x9qc3oub
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.491948149394208 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.053431727803053 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.094769624656978 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9295551582927555 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2375059285447683 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.512258311390708 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆██████▇▇▇▇▇▆▆▇███▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▇▇▇████████▇██████▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇▇█▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▅▁▁▁▁▁▁▂▁▁█▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.968
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.032
wandb:  reward 1.0
wandb: 
wandb: Synced dutiful-sweep-1817: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x9qc3oub
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184156-x9qc3oub/logs
2022-09-02 18:43:18,376 - wandb.wandb_agent - INFO - Cleaning up finished run: x9qc3oub
2022-09-02 18:43:18,654 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:43:18,654 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.002736352699183238
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:43:18,659 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.002736352699183238 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:43:23,673 - wandb.wandb_agent - INFO - Running runs: ['dtfmxqo3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184325-dtfmxqo3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-1832
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dtfmxqo3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3591500639200147 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.903303774078012 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1051251716203576 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0248262228969027 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.625016338487427 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▆████▇▇▇▇▇▇▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▅▅▅▆▆▆▆▆▆▆▆▅▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅▄▁▁▁▄██▄▁▅▁▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced blooming-sweep-1832: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dtfmxqo3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184325-dtfmxqo3/logs
2022-09-02 18:44:51,293 - wandb.wandb_agent - INFO - Cleaning up finished run: dtfmxqo3
2022-09-02 18:44:51,617 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:44:51,617 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0029823938382145727
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:44:51,624 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0029823938382145727 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:44:56,637 - wandb.wandb_agent - INFO - Running runs: ['19vvmayq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184457-19vvmayq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-1847
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/19vvmayq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0621078865235285 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.279665220116968 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.741881932488478 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2902081187194168 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇█▇▇▇▆▇▇▇▇▇▇█▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▆▆▅▆▆▆▆▆▆▆▆▆▅▆▆▆▆▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁▁▁▁▄▁▁▁▁▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced quiet-sweep-1847: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/19vvmayq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184457-19vvmayq/logs
2022-09-02 18:46:24,229 - wandb.wandb_agent - INFO - Cleaning up finished run: 19vvmayq
2022-09-02 18:46:24,523 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:46:24,524 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001053383238153284
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:46:24,527 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001053383238153284 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:46:29,540 - wandb.wandb_agent - INFO - Running runs: ['khbg1ix3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184630-khbg1ix3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1862
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/khbg1ix3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0432388540420607 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.208104649884866 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.40662505907109 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3286387863365827 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.279160176792255 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▆▆▆▆▇▆▆▆▅▅▅▅▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▇▇▇██▇▇▇████▇██▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇████████████▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▁▁▁▁▁█▁▁▁▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced copper-sweep-1862: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/khbg1ix3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184630-khbg1ix3/logs
2022-09-02 18:47:57,096 - wandb.wandb_agent - INFO - Cleaning up finished run: khbg1ix3
2022-09-02 18:47:57,517 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:47:57,517 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.001788877073846832
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:47:57,520 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.001788877073846832 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:48:02,534 - wandb.wandb_agent - INFO - Running runs: ['anwq6j8u']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184802-anwq6j8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-1878
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/anwq6j8u
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2841283466333473 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4585296090984508 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.335933435059175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.464902070588517 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.341057646554985 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆█▇▇▇█▇▇▇▇▆▆▆▆▆▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁███▁▂▁▆▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced northern-sweep-1878: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/anwq6j8u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184802-anwq6j8u/logs
2022-09-02 18:49:25,050 - wandb.wandb_agent - INFO - Cleaning up finished run: anwq6j8u
2022-09-02 18:49:25,371 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:49:25,371 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0015119849849754396
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:49:25,386 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0015119849849754396 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:49:30,399 - wandb.wandb_agent - INFO - Running runs: ['idh8a7xr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184931-idh8a7xr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-1891
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/idh8a7xr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.390070005648104 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.331044359866898 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2226861584114426 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.448499103547799 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0963416520204277 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▆▇▇▇▇▆▆▇▇▇▆▆▇▇▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▆▇▇▇██▇▇▇▇▇▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced golden-sweep-1891: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/idh8a7xr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184931-idh8a7xr/logs
2022-09-02 18:50:58,161 - wandb.wandb_agent - INFO - Cleaning up finished run: idh8a7xr
2022-09-02 18:50:58,449 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:50:58,449 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0003105580757953533
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:50:58,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0003105580757953533 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:51:03,465 - wandb.wandb_agent - INFO - Running runs: ['6bfb9jgm']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185103-6bfb9jgm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-1905
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6bfb9jgm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1587886884528453 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.110511685329328 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1088874431513136 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6402811575778085 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1648232402896026 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇█████▇▇▇▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▇▇▇▇▇▇▇▇▇██▇█████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██████▇▇▇▇▇▇▇█▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▁▅▁▇██▁█▇▅▁▅▁▇▇█▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced snowy-sweep-1905: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6bfb9jgm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185103-6bfb9jgm/logs
2022-09-02 18:52:25,909 - wandb.wandb_agent - INFO - Cleaning up finished run: 6bfb9jgm
2022-09-02 18:52:26,222 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:52:26,223 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03726277445988401
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:52:26,226 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03726277445988401 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:52:31,242 - wandb.wandb_agent - INFO - Running runs: ['z8n0vvwl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185230-z8n0vvwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-1919
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z8n0vvwl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.258719237353807 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.263055454915092 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4591698949479093 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.890923232519262 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0144061773318898 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.937219356885029 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇▇▇████▇▇█████▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇██▇▇▇▆▆▆▆▆▇▇▇█▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇████████████▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▃▁▂▄█▁█▇▁▁▁▁▄▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced expert-sweep-1919: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z8n0vvwl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185230-z8n0vvwl/logs
2022-09-02 18:53:58,764 - wandb.wandb_agent - INFO - Cleaning up finished run: z8n0vvwl
2022-09-02 18:53:59,172 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:53:59,172 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0008222520998757355
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:53:59,176 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0008222520998757355 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:54:04,188 - wandb.wandb_agent - INFO - Running runs: ['n9da81ha']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185403-n9da81ha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-1934
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n9da81ha
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.123684880465977 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.493708340208556 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.229319166876372 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2983030247902736 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.962539193331771 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅██▇▇▇▇▇▇▆▆▇▇▇▆▆▇▆▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▇▇▇▇▇▇█▇████▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇███████▇██████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:  reward ▁▁▁▁▁█▁▁█▆▇▁▄▁▁▁▁▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.949
wandb: prop_NA 0.051
wandb:  reward 0.92352
wandb: 
wandb: Synced fancy-sweep-1934: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n9da81ha
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185403-n9da81ha/logs
2022-09-02 18:55:31,749 - wandb.wandb_agent - INFO - Cleaning up finished run: n9da81ha
2022-09-02 18:55:32,460 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:55:32,462 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.004534014451337213
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:55:32,465 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.004534014451337213 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:55:37,478 - wandb.wandb_agent - INFO - Running runs: ['kitw8793']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185536-kitw8793
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-1950
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kitw8793
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.210558527542568 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3543460280799042 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.096058225623256 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1324706221699388 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.148537783216696 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇██▇██▇█▇███▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▆▅▅▅▆▆▇▆▆▆▆▆▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇█████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁█▁▄▇▁▁▁█▇▁▁█▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced jolly-sweep-1950: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kitw8793
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185536-kitw8793/logs
2022-09-02 18:56:54,785 - wandb.wandb_agent - INFO - Cleaning up finished run: kitw8793
2022-09-02 18:56:55,115 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:56:55,115 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0008496479042073479
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:56:55,122 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0008496479042073479 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:57:00,135 - wandb.wandb_agent - INFO - Running runs: ['8zdeinud']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185700-8zdeinud
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-1962
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8zdeinud
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4857144579558317 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4230101215373483 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.834118177437318 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4182916830809402 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.118969974024876 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇██▇▇▇▇▇███▇▇▇▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇███▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▁▁▁█▆▁▇▁▁▁▁▇▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.995
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.005
wandb:  reward 1.0
wandb: 
wandb: Synced comfy-sweep-1962: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8zdeinud
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185700-8zdeinud/logs
2022-09-02 18:58:17,396 - wandb.wandb_agent - INFO - Cleaning up finished run: 8zdeinud
2022-09-02 18:58:17,708 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:58:17,709 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0035460734327161067
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:58:17,741 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0035460734327161067 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:58:22,754 - wandb.wandb_agent - INFO - Running runs: ['1cfa4nkm']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185824-1cfa4nkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-1974
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1cfa4nkm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.014262713397473 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1274448595189623 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.456502945708592 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆▇▇▇▇▇▇███▇▇▆▆▆▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▄▁▁▁▁█▇▅█▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▁█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.952
wandb:  prop_3 0.0
wandb: prop_NA 0.048
wandb:  reward 0.83716
wandb: 
wandb: Synced fresh-sweep-1974: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1cfa4nkm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185824-1cfa4nkm/logs
2022-09-02 18:59:45,151 - wandb.wandb_agent - INFO - Cleaning up finished run: 1cfa4nkm
2022-09-02 18:59:45,763 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:59:45,763 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0008151576465193536
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:59:45,769 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0008151576465193536 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:59:50,782 - wandb.wandb_agent - INFO - Running runs: ['i8um3euy']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185952-i8um3euy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-1989
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i8um3euy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
slurmstepd: error: *** JOB 2474887 ON arc-c147 CANCELLED AT 2022-09-02T19:00:03 ***
