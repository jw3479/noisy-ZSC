wandb: Starting wandb agent 🕵️
2022-09-02 15:32:10,116 - wandb.wandb_agent - INFO - Running runs: []
2022-09-02 15:32:10,485 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:32:10,485 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00315123978524208
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:32:10,491 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00315123978524208 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:32:15,513 - wandb.wandb_agent - INFO - Running runs: ['m4htpm8c']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153216-m4htpm8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-13
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m4htpm8c
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.343792251615684 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4132904465403784 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.259887970217322 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.162615552664051 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.312835727572871 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.39299132028368 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
2022-09-02 15:33:32,931 - wandb.wandb_agent - INFO - Cleaning up finished run: m4htpm8c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▇██▇▇▇▇█▇▇▇▆▆▆▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▇▇▇▇███▇▆▆▇▇█▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████▇███████▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced sandy-sweep-13: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m4htpm8c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153216-m4htpm8c/logs
2022-09-02 15:33:38,211 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:33:38,212 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.01192160078738291
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:33:38,227 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.01192160078738291 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:33:43,240 - wandb.wandb_agent - INFO - Running runs: ['jkgqf2mw']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153343-jkgqf2mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-25
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jkgqf2mw
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2984642561267346 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.391865851318504 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.239171339189931 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0956208719324625 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.112046456127607 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0266299681468563 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.273898384999814 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▆▆▅▆▆▆▆▆▇▆▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▇█▇███▇███▇▆▇▇▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁█▅▁▁▁█▁▁█▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced giddy-sweep-25: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jkgqf2mw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153343-jkgqf2mw/logs
2022-09-02 15:35:16,988 - wandb.wandb_agent - INFO - Cleaning up finished run: jkgqf2mw
2022-09-02 15:35:17,273 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:35:17,287 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0018719184907761263
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:35:17,294 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0018719184907761263 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:35:22,309 - wandb.wandb_agent - INFO - Running runs: ['tf2s115n']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153522-tf2s115n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-45
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tf2s115n
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0286520467281752 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9782867645622595 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.334931719182856 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3258558179881454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.489203830338786 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.186170097709348 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅▇██▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▄▆▇██████▇▇▇▇███
wandb:  prop_3 ▅▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▃▅█▇█▇▆▅▆▇▄██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.475
wandb:  prop_2 0.518
wandb:  prop_3 0.0
wandb: prop_NA 0.007
wandb:  reward 1.0
wandb: 
wandb: Synced warm-sweep-45: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tf2s115n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153522-tf2s115n/logs
2022-09-02 15:36:44,739 - wandb.wandb_agent - INFO - Cleaning up finished run: tf2s115n
2022-09-02 15:36:44,972 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:36:44,972 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005457211492659077
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:36:44,978 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005457211492659077 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:36:49,990 - wandb.wandb_agent - INFO - Running runs: ['mblnbvfl']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153650-mblnbvfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-58
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mblnbvfl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2169449678828745 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1898975189135825 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1947499229125844 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.58643959407385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3149861829420137 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.528190563172413 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇████▇▇▇▇▇█████▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▇▇██████▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁▁█▁▁▆▁▁▁█▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced wandering-sweep-58: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mblnbvfl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153650-mblnbvfl/logs
2022-09-02 15:38:12,372 - wandb.wandb_agent - INFO - Cleaning up finished run: mblnbvfl
2022-09-02 15:38:12,611 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:38:12,611 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0006343509860382922
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:38:12,655 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0006343509860382922 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:38:17,671 - wandb.wandb_agent - INFO - Running runs: ['bwkbtmjb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153819-bwkbtmjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-68
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bwkbtmjb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1833770735050555 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.447764177013309 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.234281101529477 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.24053189573427 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.366197746006722 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.025968223592681 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇██▇█▇▇▇▇▇▇█▇▇▇▆▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▇▆▆▆▅▅▅▅▆▆▆▆▆▆▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▁▁▁▁▁▁▁█▁▅▁▁▅▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced true-sweep-68: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bwkbtmjb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153819-bwkbtmjb/logs
2022-09-02 15:39:45,273 - wandb.wandb_agent - INFO - Cleaning up finished run: bwkbtmjb
2022-09-02 15:39:45,512 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:39:45,512 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0007675438966278284
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:39:45,517 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0007675438966278284 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:39:50,532 - wandb.wandb_agent - INFO - Running runs: ['j1o7qqrp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153950-j1o7qqrp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-86
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j1o7qqrp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3042751186626904 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.151806731256495 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1761220322121986 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.112111441680269 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0547639986094666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.704039893880066 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▆▆▆▆▆▇▇▆▆▆▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▄▆▇██▇▆▅▄▄▄▄▄▄▄▄▄▄▄
wandb:  prop_3 ▃▃▃▂▂▂▂▂▂▂▂▂▃▃▃▂▂▂▂▃▂▂▂▁▁▁▂▄▆▇██████▇▇▇▇
wandb: prop_NA ▇███████████▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂█▁▁▁▁▁▁█▁▁▁▁▃▇▂███▇████████████▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.496
wandb:  prop_3 0.483
wandb: prop_NA 0.021
wandb:  reward 0.92352
wandb: 
wandb: Synced atomic-sweep-86: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j1o7qqrp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153950-j1o7qqrp/logs
2022-09-02 15:41:12,976 - wandb.wandb_agent - INFO - Cleaning up finished run: j1o7qqrp
2022-09-02 15:41:13,371 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:41:13,371 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.011847208235064452
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:41:13,377 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.011847208235064452 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:41:18,390 - wandb.wandb_agent - INFO - Running runs: ['3cpuy1uk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154120-3cpuy1uk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-100
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3cpuy1uk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4202997949332152 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0070341854356113 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.282673770787021 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2895366109045994 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.869485156288391 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3513809276336133 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇███▇▇▇▇▆▆▆▆▆▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▆▇▇▆▇▇▆▇▇█▇▇▇▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▇▁▁█▁▁▁▁▁▁▅▁▁▁█▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced graceful-sweep-100: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3cpuy1uk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154120-3cpuy1uk/logs
2022-09-02 15:42:40,868 - wandb.wandb_agent - INFO - Cleaning up finished run: 3cpuy1uk
2022-09-02 15:42:41,122 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:42:41,122 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002764002190215324
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:42:41,140 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002764002190215324 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:42:46,154 - wandb.wandb_agent - INFO - Running runs: ['j9lt0qnn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154248-j9lt0qnn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-113
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j9lt0qnn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2443863869274945 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.15613537264246 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4807609906155332 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.303186244924298 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0431687361322775 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.149643825691645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0143226248134196 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.071571522665146 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ██▇▇▆▆▆▆▆▆▆▇▇▇▇▆▆▆▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▇▇▇█▇▇▆▆▇▇██▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▅▁▁▁▁█▁▁▄█▁▁▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.966
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.034
wandb:  reward 1.0
wandb: 
wandb: Synced deft-sweep-113: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j9lt0qnn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154248-j9lt0qnn/logs
2022-09-02 15:44:18,834 - wandb.wandb_agent - INFO - Cleaning up finished run: j9lt0qnn
2022-09-02 15:44:19,083 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:44:19,083 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00165669691391325
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:44:19,086 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00165669691391325 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:44:24,096 - wandb.wandb_agent - INFO - Running runs: ['wnam3wtg']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154425-wnam3wtg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-129
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wnam3wtg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2615570775859655 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.151971979148974 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.038866497780064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.078723127972585 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▁▁▃▅▆██▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:  prop_2 ██▇▇▇▇▇▆▆▆▆▆▆▆▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▁▁▃▆▇██▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb: prop_NA █▇▇▇▇▇████████▇▇█▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▇▁█▄▅▃▅▆█▅██████▇▆█▁▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.515
wandb:  prop_2 0.0
wandb:  prop_3 0.477
wandb: prop_NA 0.008
wandb:  reward 1.0
wandb: 
wandb: Synced revived-sweep-129: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wnam3wtg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154425-wnam3wtg/logs
2022-09-02 15:45:46,620 - wandb.wandb_agent - INFO - Cleaning up finished run: wnam3wtg
2022-09-02 15:45:46,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:45:46,878 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004382630952774776
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:45:46,895 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004382630952774776 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:45:51,909 - wandb.wandb_agent - INFO - Running runs: ['h4rn20s9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154553-h4rn20s9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-143
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h4rn20s9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3818214996489946 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.190896637329062 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.176504089508314 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4695661144944463 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▇▆▆▆▆▇███▇▇▆▆▆▆▆▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇████▇▇▇▇▇▇▇▇▆▇▆▇█▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇█████▇▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▅▁█▃█▁▁▂▄▁█▁▁▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced faithful-sweep-143: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h4rn20s9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154553-h4rn20s9/logs
2022-09-02 15:47:24,688 - wandb.wandb_agent - INFO - Cleaning up finished run: h4rn20s9
2022-09-02 15:47:24,927 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:47:24,927 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.029125659534325953
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:47:24,936 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.029125659534325953 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:47:29,949 - wandb.wandb_agent - INFO - Running runs: ['2laedwla']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154730-2laedwla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-161
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2laedwla
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.037541406275686 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.086899909405234 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.41600166846548 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4751222298328024 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4575039554315103 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▆▆▇▇█▇▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▃▆▇███▇▇▇▇▇▇▇▇█▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ███▇▇▇▇██▇▇▇▇▇▇██▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁█▁▁▁▁▁█▁▁▁██▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced rose-sweep-161: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2laedwla
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154730-2laedwla/logs
2022-09-02 15:48:57,552 - wandb.wandb_agent - INFO - Cleaning up finished run: 2laedwla
2022-09-02 15:48:57,816 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:48:57,816 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0003575622395806652
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:48:57,830 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0003575622395806652 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:49:02,842 - wandb.wandb_agent - INFO - Running runs: ['6uaeay7v']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154902-6uaeay7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-175
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6uaeay7v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1022119746033323 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0533583643258084 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.937908616330003 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.393671867105224 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▇▇▇▇▆▆▇▇▇▇▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇████▇▇▇███▇▇▆▆▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▁▁▆▁▁▁███▁▇▃█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.97
wandb:  prop_3 0.0
wandb: prop_NA 0.03
wandb:  reward 0.83716
wandb: 
wandb: Synced jumping-sweep-175: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6uaeay7v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154902-6uaeay7v/logs
2022-09-02 15:50:35,619 - wandb.wandb_agent - INFO - Cleaning up finished run: 6uaeay7v
2022-09-02 15:50:35,887 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:50:35,887 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.04125968414084625
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:50:35,896 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.04125968414084625 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:50:40,909 - wandb.wandb_agent - INFO - Running runs: ['pkwswr8a']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155040-pkwswr8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-191
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pkwswr8a
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.242959774083616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.38818535207792 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.055700607510327 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.328207105696438 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.437686458318673 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█████▇▇█▇▇▇▇▇▇█▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▇▇▆▇▇▇█▇▇▇▅▆▆▆▇█▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▇▁▁▁▁▁▁▁▁▁▁▅▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced silvery-sweep-191: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pkwswr8a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155040-pkwswr8a/logs
2022-09-02 15:52:03,317 - wandb.wandb_agent - INFO - Cleaning up finished run: pkwswr8a
2022-09-02 15:52:03,569 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:52:03,569 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0002527466996361119
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:52:03,589 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0002527466996361119 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:52:08,605 - wandb.wandb_agent - INFO - Running runs: ['5ggne7ic']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155210-5ggne7ic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-203
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5ggne7ic
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.010874360670725 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.914650554738792 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.292451965479669 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.288620912044468 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.189972345255936 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▄▅▅▅▅▅▄▅▅▅▆▅▅▅▅▅▅▅▅▇█▇▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▇▆▆▆▇▇██▇▇▇▆▆▇▆▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▂▇▁▁▁▁▁█▁▁▅▇▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.995
wandb: prop_NA 0.005
wandb:  reward 0.92352
wandb: 
wandb: Synced vocal-sweep-203: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5ggne7ic
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155210-5ggne7ic/logs
2022-09-02 15:53:31,025 - wandb.wandb_agent - INFO - Cleaning up finished run: 5ggne7ic
2022-09-02 15:53:31,264 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:53:31,264 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0007325317917408476
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:53:31,285 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0007325317917408476 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:53:36,298 - wandb.wandb_agent - INFO - Running runs: ['8al76shs']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155338-8al76shs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-217
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8al76shs
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.223909113403065 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1007735579642945 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1181386114769256 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.707334597559775 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.042402508494531 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.620877639288069 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▆▆▇▇▇▆▆▆▇▇▇▇▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆██▇▇▇▇█▇█████▇█▇▇▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▄█▁▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced smart-sweep-217: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8al76shs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155338-8al76shs/logs
2022-09-02 15:55:09,018 - wandb.wandb_agent - INFO - Cleaning up finished run: 8al76shs
2022-09-02 15:55:09,281 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:55:09,286 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0006396707241843792
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:55:09,296 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0006396707241843792 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:55:14,308 - wandb.wandb_agent - INFO - Running runs: ['73lltadk']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155514-73lltadk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-235
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/73lltadk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.380416725282798 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.453845339578697 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.058148684029376 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3896251377170272 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.25909253131333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1729987547427663 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.765058616006522 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▅▅▅▅▅▅▆▆▆▆▅▆▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇█▇▇▇▆▇████▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▂▂▂▁▁▂▂▂▂▂▂▂▂▁▁▁▂▄▆▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁█▁▆▁▁▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.001
wandb:  prop_2 0.0
wandb:  prop_3 0.985
wandb: prop_NA 0.014
wandb:  reward 0.92352
wandb: 
wandb: Synced sage-sweep-235: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/73lltadk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155514-73lltadk/logs
2022-09-02 15:56:47,083 - wandb.wandb_agent - INFO - Cleaning up finished run: 73lltadk
2022-09-02 15:56:47,338 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:56:47,339 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.003943346522415659
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:56:47,348 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.003943346522415659 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:56:52,369 - wandb.wandb_agent - INFO - Running runs: ['ybsa78cj']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155651-ybsa78cj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-251
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ybsa78cj
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.264713100505056 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4190531205610846 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.672504454564702 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1288845010661124 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5390585147470714 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ███▇▆▆▆▇██▇█▇▇█▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▆▅▆▆▆▇▆▆▆▆▆▆▅▆▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇█████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▇▅█▁▁▁▄▆▁▁▇▆█▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.964
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.036
wandb:  reward 1.0
wandb: 
wandb: Synced effortless-sweep-251: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ybsa78cj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155651-ybsa78cj/logs
2022-09-02 15:58:10,776 - wandb.wandb_agent - INFO - Cleaning up finished run: ybsa78cj
2022-09-02 15:58:11,002 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:58:11,002 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0013163806916706908
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:58:11,008 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0013163806916706908 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:58:16,021 - wandb.wandb_agent - INFO - Running runs: ['gqn4h06q']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155815-gqn4h06q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-260
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gqn4h06q
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.416430963368691 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.066972171293262 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.457066574030575 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484212770560893 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.33692821218774 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▇▇▇▇▇▇███▇▇▇▆▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████▇███████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▃▁▄▁█▁▁▅▅▁▆▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.965
wandb: prop_NA 0.035
wandb:  reward 0.92352
wandb: 
wandb: Synced solar-sweep-260: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gqn4h06q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155815-gqn4h06q/logs
2022-09-02 15:59:33,631 - wandb.wandb_agent - INFO - Cleaning up finished run: gqn4h06q
2022-09-02 15:59:33,871 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:59:33,871 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003702988781736083
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:59:33,881 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003702988781736083 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:59:38,894 - wandb.wandb_agent - INFO - Running runs: ['rp5ezsaa']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155941-rp5ezsaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-274
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rp5ezsaa
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4412805789494993 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.005206669844853 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.35737221475834 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0196619928125976 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9323923499001525 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇▇▇▇▇▆▆▆▆▆▇▆▆▆▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇████▇██▇▇▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇████████████▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▃▁▂▁▁▅▄█▁▁▁█▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced eager-sweep-274: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rp5ezsaa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155941-rp5ezsaa/logs
2022-09-02 16:01:06,489 - wandb.wandb_agent - INFO - Cleaning up finished run: rp5ezsaa
2022-09-02 16:01:06,747 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:01:06,747 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04919157965340422
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:01:06,759 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04919157965340422 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:01:11,773 - wandb.wandb_agent - INFO - Running runs: ['wg08mh0l']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160114-wg08mh0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-289
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wg08mh0l
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3145786289043384 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.91521166820438 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.068835759258046 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4705695734321225 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▇▇██▇▇██▇█▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▇▇▇▇▇▇▆▆▆▇▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▁▁▅▁█▁▁▁▁▅▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced earnest-sweep-289: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wg08mh0l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160114-wg08mh0l/logs
2022-09-02 16:02:37,644 - wandb.wandb_agent - INFO - Cleaning up finished run: wg08mh0l
2022-09-02 16:02:37,909 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:02:37,910 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.04175660783824874
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:02:37,945 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.04175660783824874 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:02:42,961 - wandb.wandb_agent - INFO - Running runs: ['03do0ya2']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160245-03do0ya2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-304
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/03do0ya2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.189312996029084 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.260735274749926 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1886936828375365 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0142662596814342 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.68819225798065 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇██████▇▇█▇▇▇▇▇▇▇▆▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ███▇▇▇▇▇▇▇▇██▇▇▇▇███▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▁▁▅▁▁▇▄▁▅▄▁▇▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced peach-sweep-304: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/03do0ya2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160245-03do0ya2/logs
2022-09-02 16:04:20,899 - wandb.wandb_agent - INFO - Cleaning up finished run: 03do0ya2
2022-09-02 16:04:21,172 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:04:21,178 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0025120724710671048
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:04:21,193 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0025120724710671048 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:04:26,207 - wandb.wandb_agent - INFO - Running runs: ['00r4oqfy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160425-00r4oqfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-323
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/00r4oqfy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4912457294212285 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.09221949600151 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.796616454909888 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4668280933531608 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇██▇█▇▇▇▆▇▆▆▆▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██████▇▇▇▇▇▇▇▇▇▇▇▆▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced classic-sweep-323: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/00r4oqfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160425-00r4oqfy/logs
2022-09-02 16:06:09,311 - wandb.wandb_agent - INFO - Cleaning up finished run: 00r4oqfy
2022-09-02 16:06:09,555 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:06:09,561 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0040465122802582475
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:06:09,567 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0040465122802582475 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:06:14,581 - wandb.wandb_agent - INFO - Running runs: ['12abkw0n']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160614-12abkw0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-342
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/12abkw0n
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.172372759464925 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2521189915602395 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0789304384758687 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.367848774274329 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.982615932971881 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██▇▆▆▇▇▇▇▆▆▇▆▇▇▆▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇███▇▇▇▇▇▇▇▆▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅▁▁▅▁▆▁▇▁▁▁▄▁▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced lunar-sweep-342: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/12abkw0n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160614-12abkw0n/logs
2022-09-02 16:07:37,690 - wandb.wandb_agent - INFO - Cleaning up finished run: 12abkw0n
2022-09-02 16:07:42,932 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:07:42,932 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.018539857231326697
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:07:42,941 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.018539857231326697 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:07:47,955 - wandb.wandb_agent - INFO - Running runs: ['344svmw1']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160748-344svmw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-353
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/344svmw1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.380548363836235 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0542005654732405 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4307106020632694 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.427133790604484 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.761722641837228 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▆▇▇▇▇▆▆▆▆▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇█▇▇█▇▇▇▇▆▆▆▆▆▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇█████████████████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▇▁▁██▆▁▇▄▁▁█▁▇▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced vibrant-sweep-353: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/344svmw1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160748-344svmw1/logs
2022-09-02 16:09:23,281 - wandb.wandb_agent - INFO - Cleaning up finished run: 344svmw1
2022-09-02 16:09:23,535 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:09:23,535 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.008773420964851406
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:09:23,542 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.008773420964851406 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:09:28,554 - wandb.wandb_agent - INFO - Running runs: ['esv9puwc']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160928-esv9puwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-371
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/esv9puwc
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.055093133488847 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.073919163883061 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.407394618505674 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.330679352529085 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇▆▆▆▆▆▆▆▆▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▄▆▇▆▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅▂▁▁▁█▁██▁▅▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced worthy-sweep-371: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/esv9puwc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160928-esv9puwc/logs
2022-09-02 16:10:56,730 - wandb.wandb_agent - INFO - Cleaning up finished run: esv9puwc
2022-09-02 16:10:56,979 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:10:56,979 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0004938000202524531
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:10:56,986 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0004938000202524531 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:11:02,000 - wandb.wandb_agent - INFO - Running runs: ['rsq5q79s']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161101-rsq5q79s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-386
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rsq5q79s
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4558569002904984 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.248281800575198 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3599554412486237 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.662227233932421 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.078668766554016 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.746823813880895 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.326390130243465 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.076700178754097 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: / 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: - 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: / 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: - 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇█▇██▇▇▇▇▆▇▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇█▇▇▇▇▆▆▅▆▆▆▇▇███▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▃▁▂▁▁▁▆██▁█▁▁█▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced ethereal-sweep-386: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rsq5q79s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161101-rsq5q79s/logs
2022-09-02 16:12:29,952 - wandb.wandb_agent - INFO - Cleaning up finished run: rsq5q79s
2022-09-02 16:12:30,204 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:12:30,205 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00045077391027904167
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:12:30,238 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00045077391027904167 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:12:35,254 - wandb.wandb_agent - INFO - Running runs: ['qphhqfzv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161234-qphhqfzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-401
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qphhqfzv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4373881352630176 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0145507342951103 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.023309602860484 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2836863648269503 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.448216016393 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0345267693160025 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.466879933177929 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▆▆▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▇▇▇███▇▇▇▇▇▇▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▃▁▁▄█▁▁▇▁▁▁▁▁▁▆▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced amber-sweep-401: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qphhqfzv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161234-qphhqfzv/logs
2022-09-02 16:14:08,131 - wandb.wandb_agent - INFO - Cleaning up finished run: qphhqfzv
2022-09-02 16:14:08,375 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:14:08,375 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.005146130923879338
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:14:08,382 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.005146130923879338 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:14:13,395 - wandb.wandb_agent - INFO - Running runs: ['ty6fjs09']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161412-ty6fjs09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-417
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ty6fjs09
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.070495496741434 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.892595788696032 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4157426986619273 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.071303714189539 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.269540207015658 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.711421146438487 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇█▇▇▇▇█████████▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆▆▆▆▆▇█████▇▇▇▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁▄▁▁▅▁▁█▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.981
wandb:  prop_3 0.0
wandb: prop_NA 0.019
wandb:  reward 0.83716
wandb: 
wandb: Synced graceful-sweep-417: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ty6fjs09
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161412-ty6fjs09/logs
2022-09-02 16:15:46,116 - wandb.wandb_agent - INFO - Cleaning up finished run: ty6fjs09
2022-09-02 16:15:46,351 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:15:46,351 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00191330752282604
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:15:46,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00191330752282604 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:15:51,371 - wandb.wandb_agent - INFO - Running runs: ['gu2yrqo7']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161551-gu2yrqo7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-432
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gu2yrqo7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.040860937443416 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1029840963392044 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.859616619964447 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3995969798147554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.866541659853885 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.302451172680617 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██████████████▇▇
wandb:  prop_2 █▇▇▇▇▇▇█▇▇▇▇▇▇▇████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▆▆▆▆▆▆▆▇██▇▇▆▇▇▇▇▆▄▃▂▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▆
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁█▁▁▁█▇▁▁█▅▁▁█▁▁█▃▅▅▆▂▇▂▅█▇█▂▄▇█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.848
wandb:  prop_2 0.0
wandb:  prop_3 0.102
wandb: prop_NA 0.05
wandb:  reward 1.0
wandb: 
wandb: Synced leafy-sweep-432: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gu2yrqo7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161551-gu2yrqo7/logs
2022-09-02 16:17:24,768 - wandb.wandb_agent - INFO - Cleaning up finished run: gu2yrqo7
2022-09-02 16:17:25,004 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:17:25,004 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0028828657226643985
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:17:25,009 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0028828657226643985 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:17:30,022 - wandb.wandb_agent - INFO - Running runs: ['3h6vsh5j']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161729-3h6vsh5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-447
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3h6vsh5j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.00440296515424 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.571762621275153 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4811292115627617 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.538819656058867 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3476323161123216 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▆▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▆▅▅▅▅▅▄▄▄▅▅▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇▇█▇█▇▇▇████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▁▅▁▁▁▁▆█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced classic-sweep-447: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3h6vsh5j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161729-3h6vsh5j/logs
2022-09-02 16:19:08,070 - wandb.wandb_agent - INFO - Cleaning up finished run: 3h6vsh5j
2022-09-02 16:19:08,323 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:19:08,323 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0003704642260683663
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:19:08,355 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0003704642260683663 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:19:13,367 - wandb.wandb_agent - INFO - Running runs: ['7coosi7f']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161913-7coosi7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-464
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7coosi7f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2452559380540684 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.665136390633757 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1104351280141604 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.285587654224667 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇█████▇▇▇▇▇███▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████▇▇▆▅▄▄▃▃▃
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▃▄▅▇▇███
wandb: prop_NA ██████▇▇██████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▁▃▁▁▇▁▅▁▇█▅▆█▄▇▁▁▁▂███▇█▂▆▄▆▄██████▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.421
wandb:  prop_3 0.574
wandb: prop_NA 0.005
wandb:  reward 0.92352
wandb: 
wandb: Synced upbeat-sweep-464: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7coosi7f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161913-7coosi7f/logs
2022-09-02 16:20:35,853 - wandb.wandb_agent - INFO - Cleaning up finished run: 7coosi7f
2022-09-02 16:20:36,095 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:20:36,095 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004387427746080149
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:20:36,112 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004387427746080149 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:20:41,128 - wandb.wandb_agent - INFO - Running runs: ['1yeyonup']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162041-1yeyonup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-477
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1yeyonup
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.269811720650309 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2910038897619724 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.240943098748277 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.274749334996824 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.204663921312613 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.496871457225791 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▆▇▇█▇▇▇▇▇▇▇▇▇▇▆▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▆▇▆▆▇▆▆▆▆▆▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▅▁▁█▇▃▁▁▁█▁▁█▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced still-sweep-477: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1yeyonup
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162041-1yeyonup/logs
2022-09-02 16:22:13,909 - wandb.wandb_agent - INFO - Cleaning up finished run: 1yeyonup
2022-09-02 16:22:14,168 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:22:14,169 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.010142109239824629
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:22:14,183 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.010142109239824629 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:22:19,198 - wandb.wandb_agent - INFO - Running runs: ['03q6qur2']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162218-03q6qur2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-492
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/03q6qur2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.319557511651487 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1106808812058127 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁█▁▁▁▁▁█▅▁▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced stoic-sweep-492: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/03q6qur2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162218-03q6qur2/logs
2022-09-02 16:23:52,155 - wandb.wandb_agent - INFO - Cleaning up finished run: 03q6qur2
2022-09-02 16:23:52,628 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:23:52,629 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0031166477872259014
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:23:52,641 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0031166477872259014 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:23:57,655 - wandb.wandb_agent - INFO - Running runs: ['297wtrsk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162358-297wtrsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-508
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/297wtrsk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.014000570653833 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.224433855383644 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4595799348403133 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇▇▇▇▇▇▇▇█████▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▆▇▇▇▇▇▇▇▇█▇███▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁█▁▁▁▅▁▁▁▁▁▁▁▁▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.98
wandb: prop_NA 0.02
wandb:  reward 0.92352
wandb: 
wandb: Synced breezy-sweep-508: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/297wtrsk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162358-297wtrsk/logs
2022-09-02 16:25:25,440 - wandb.wandb_agent - INFO - Cleaning up finished run: 297wtrsk
2022-09-02 16:25:25,688 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:25:25,689 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00014407990868798887
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:25:25,701 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00014407990868798887 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:25:30,713 - wandb.wandb_agent - INFO - Running runs: ['d4jj3wdf']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162531-d4jj3wdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-522
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d4jj3wdf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2350651131771584 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1810625113541393 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.064581631788067 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▆▆▇▇▇▇▇▇███▇▆▆▆▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇█▇▇▇▇▆▆▇▆▆▆▆▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂█▁▁▁▁█▅▁█▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced crisp-sweep-522: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d4jj3wdf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162531-d4jj3wdf/logs
2022-09-02 16:26:53,680 - wandb.wandb_agent - INFO - Cleaning up finished run: d4jj3wdf
2022-09-02 16:26:54,069 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:26:54,069 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0004871516012245976
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:26:54,089 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0004871516012245976 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:26:59,107 - wandb.wandb_agent - INFO - Running runs: ['5n7vu3p0']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162658-5n7vu3p0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-537
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5n7vu3p0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3405521244065053 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8582806785118215 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.42898733793136 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1745222501933688 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇█▇██▇█▇▇█▇█▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇█▇██▇█▇█▇▇▇▇▇███▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██████████▇▇▇███
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▁▁
wandb:  reward ▁▄▁▁█▁▄▁▁▁▁█▁▆█▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.956
wandb: prop_NA 0.044
wandb:  reward 0.92352
wandb: 
wandb: Synced peach-sweep-537: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5n7vu3p0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162658-5n7vu3p0/logs
2022-09-02 16:28:22,578 - wandb.wandb_agent - INFO - Cleaning up finished run: 5n7vu3p0
2022-09-02 16:28:22,856 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:28:22,857 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005938214288641833
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:28:22,865 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005938214288641833 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:28:27,877 - wandb.wandb_agent - INFO - Running runs: ['nc3rdeo5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162827-nc3rdeo5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-551
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nc3rdeo5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1453695628953415 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.880510340740545 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3993439914406745 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0229635767068084 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▆▇▆▇▆▇▇▆▆▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇████████████████▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▅▁▁▅▁▁▁▁▁▁▁▁▇▆▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced rare-sweep-551: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nc3rdeo5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162827-nc3rdeo5/logs
2022-09-02 16:29:50,721 - wandb.wandb_agent - INFO - Cleaning up finished run: nc3rdeo5
2022-09-02 16:29:51,006 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:29:51,006 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00043712216935651104
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:29:51,012 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00043712216935651104 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:29:56,026 - wandb.wandb_agent - INFO - Running runs: ['lhq06k5v']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162955-lhq06k5v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-562
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lhq06k5v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1181822692477166 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.370186726936109 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4404864995163362 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.980285258070303 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.286749903712087 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▇▇▇▇▆▇▇▇▇▇▇████▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▇████████▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▇█▁▄▁▁▁█▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced copper-sweep-562: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lhq06k5v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162955-lhq06k5v/logs
2022-09-02 16:31:23,839 - wandb.wandb_agent - INFO - Cleaning up finished run: lhq06k5v
2022-09-02 16:31:24,111 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:31:24,111 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03497995444615138
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:31:24,117 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03497995444615138 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:31:29,130 - wandb.wandb_agent - INFO - Running runs: ['sef9ekvv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163129-sef9ekvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-575
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sef9ekvv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▅▅▅▅▆▆▆▅▅▅▅▆▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▅▇█▇▇▇▆▆▇▇▇█▇▇█▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▂▇▁▁█▁▇▄▁▁▄▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced spring-sweep-575: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sef9ekvv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163129-sef9ekvv/logs
2022-09-02 16:33:07,163 - wandb.wandb_agent - INFO - Cleaning up finished run: sef9ekvv
2022-09-02 16:33:07,428 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:33:07,428 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.004234903336282237
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:33:07,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.004234903336282237 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:33:12,448 - wandb.wandb_agent - INFO - Running runs: ['c2493jjw']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163312-c2493jjw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-593
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c2493jjw
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0130361677837874 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.982846240040004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4025978353501456 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.145248693270567 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.795435586823907 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▇▇█▇▇▇▆▇▇▇▇▇▇▇▆▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▆▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁██▁▁▇▁▁▁▁▅▁▁▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced woven-sweep-593: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c2493jjw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163312-c2493jjw/logs
2022-09-02 16:34:35,301 - wandb.wandb_agent - INFO - Cleaning up finished run: c2493jjw
2022-09-02 16:34:35,551 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:34:35,551 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.044357742726888305
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:34:35,564 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.044357742726888305 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:34:40,577 - wandb.wandb_agent - INFO - Running runs: ['rf1nslmi']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163440-rf1nslmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-607
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rf1nslmi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.225997763948989 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.314704069215536 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.211754924746467 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.175900845959425 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.216096882282064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.524211334169944 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇███▇▇▇██▇█▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▆▇▇▇▇▇▇▇▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁▁▁▁█▁▄▁▁█▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced hearty-sweep-607: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rf1nslmi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163440-rf1nslmi/logs
2022-09-02 16:36:14,297 - wandb.wandb_agent - INFO - Cleaning up finished run: rf1nslmi
2022-09-02 16:36:14,545 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:36:14,545 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0010624877018300383
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:36:14,551 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0010624877018300383 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:36:19,563 - wandb.wandb_agent - INFO - Running runs: ['y33ztd1u']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163619-y33ztd1u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-623
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y33ztd1u
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3656844655469333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.449930578745354 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.48927853787683 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1136562626349433 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.244316876024884 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1147102177804684 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▄▁▁▁▁▁▇▁▁▁▁▇█▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dulcet-sweep-623: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y33ztd1u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163619-y33ztd1u/logs
2022-09-02 16:37:43,020 - wandb.wandb_agent - INFO - Cleaning up finished run: y33ztd1u
2022-09-02 16:37:43,250 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:37:43,250 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.010573839237542326
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:37:43,259 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.010573839237542326 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:37:48,273 - wandb.wandb_agent - INFO - Running runs: ['w6ruu0br']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163748-w6ruu0br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-637
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w6ruu0br
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1772200665980797 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4678262556764183 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.277493132959241 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2719748586524156 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.05036967695966 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▆▆▆▆▆▆▇▇██▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇██▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁█▁▁▁█▁█▁▁█▇▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced curious-sweep-637: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w6ruu0br
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163748-w6ruu0br/logs
2022-09-02 16:39:21,057 - wandb.wandb_agent - INFO - Cleaning up finished run: w6ruu0br
2022-09-02 16:39:21,308 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:39:21,308 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.006713569080694946
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:39:21,324 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.006713569080694946 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:39:26,338 - wandb.wandb_agent - INFO - Running runs: ['8mebwmtt']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163926-8mebwmtt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-651
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8mebwmtt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.288733621492459 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.926424436429655 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1042673063690813 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.203283039036354 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.446975600082261 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇▇▇▇██▇▇▇▇████▆▇▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▄▆▇████████████████
wandb:  prop_3 █▇▆▇▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇██████▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁█▁██▁▁▁▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced unique-sweep-651: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8mebwmtt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163926-8mebwmtt/logs
2022-09-02 16:40:59,154 - wandb.wandb_agent - INFO - Cleaning up finished run: 8mebwmtt
2022-09-02 16:40:59,393 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:40:59,393 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00015515814731657769
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:40:59,413 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00015515814731657769 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:41:04,429 - wandb.wandb_agent - INFO - Running runs: ['ta5yt8m0']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164104-ta5yt8m0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-667
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ta5yt8m0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0739796741089833 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3385813322034115 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0560075901193646 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.353415957607854 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.466338188060436 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅█▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▁▇▁▁▁▁▁█▁▄▁▅▄▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced sandy-sweep-667: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ta5yt8m0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164104-ta5yt8m0/logs
2022-09-02 16:42:42,428 - wandb.wandb_agent - INFO - Cleaning up finished run: ta5yt8m0
2022-09-02 16:42:42,681 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:42:42,689 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01053550038009399
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:42:42,703 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01053550038009399 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:42:47,717 - wandb.wandb_agent - INFO - Running runs: ['weyfozvh']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164247-weyfozvh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-684
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/weyfozvh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.476752171856254 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.687550889931126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.157130570549271 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1808376669773297 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4138622076697875 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇██████▇▇▇██▇▇▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▁▁▁▄▁▁▅▁██▁▆▁▁▁▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced silver-sweep-684: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/weyfozvh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164247-weyfozvh/logs
2022-09-02 16:44:10,205 - wandb.wandb_agent - INFO - Cleaning up finished run: weyfozvh
2022-09-02 16:44:10,535 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:44:10,542 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.002231157557681767
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:44:10,555 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.002231157557681767 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:44:15,569 - wandb.wandb_agent - INFO - Running runs: ['kt3fj1ac']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164415-kt3fj1ac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-698
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kt3fj1ac
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.132422427595072 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.120501058239337 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.163819876208653 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3295613105649005 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.072054397944717 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇████▇▇████████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇██▇▇▆▇▇▆▇▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁▁▁▁▁▁▁▅▄▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.982
wandb: prop_NA 0.018
wandb:  reward 0.92352
wandb: 
wandb: Synced dulcet-sweep-698: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kt3fj1ac
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164415-kt3fj1ac/logs
2022-09-02 16:45:45,482 - wandb.wandb_agent - INFO - Cleaning up finished run: kt3fj1ac
2022-09-02 16:45:45,721 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:45:45,721 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001718806493826349
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:45:45,738 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001718806493826349 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:45:50,753 - wandb.wandb_agent - INFO - Running runs: ['zxkux9kl']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164551-zxkux9kl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-713
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zxkux9kl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.47863412670113 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4196553027555705 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2670526715804677 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3690382952730897 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▁▂▄▅▇█████████████
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▇█▇▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▆▆▅▆▆▆▇▇▆▇▆▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇█▇████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▁▁▁▁█▁▁▄▁▁▁▁▁▁▇▇▁▁▂██▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced polar-sweep-713: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zxkux9kl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164551-zxkux9kl/logs
2022-09-02 16:47:23,723 - wandb.wandb_agent - INFO - Cleaning up finished run: zxkux9kl
2022-09-02 16:47:23,986 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:47:23,986 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0027963835037936964
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:47:23,991 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0027963835037936964 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:47:29,004 - wandb.wandb_agent - INFO - Running runs: ['1urh25yv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164730-1urh25yv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-729
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1urh25yv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.115410654003742 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0282167455491336 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7310754686707925 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆██▇▇▇▇▇██▇▇▇▇█████▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▆▇▇█▇▇▇▇▇███▇▇▆▆▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄█▁▁█▁█▁▁█▁▅▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced dutiful-sweep-729: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1urh25yv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164730-1urh25yv/logs
2022-09-02 16:49:07,141 - wandb.wandb_agent - INFO - Cleaning up finished run: 1urh25yv
2022-09-02 16:49:07,451 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:49:07,451 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.033677197634155345
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:49:07,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.033677197634155345 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:49:12,473 - wandb.wandb_agent - INFO - Running runs: ['bjgiw1oy']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164912-bjgiw1oy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-745
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bjgiw1oy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4080849278077388 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.838447211642216 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0323082361429354 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇█████▇▇▆▆▆▆▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▇▇████▇▇▇▇▇▇▇▇▇▇██▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▁▁▅▁▄█▁▅▁▁█▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced polar-sweep-745: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bjgiw1oy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164912-bjgiw1oy/logs
2022-09-02 16:50:34,960 - wandb.wandb_agent - INFO - Cleaning up finished run: bjgiw1oy
2022-09-02 16:50:35,205 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:50:35,206 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0027818720120820527
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:50:35,248 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0027818720120820527 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:50:40,265 - wandb.wandb_agent - INFO - Running runs: ['g6ixx8vg']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165039-g6ixx8vg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-759
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g6ixx8vg
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.40341623560451 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.439947439469659 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2205041565718506 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.996217836485819 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3105599415814186 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▆▇████▇▇▇▇▇▇▇▇▆▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆█▇▇▆▆▆▆▆▆▆▆▆▇▆▆▆▅▅▅▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▇▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dark-sweep-759: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g6ixx8vg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165039-g6ixx8vg/logs
2022-09-02 16:52:13,098 - wandb.wandb_agent - INFO - Cleaning up finished run: g6ixx8vg
2022-09-02 16:52:13,342 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:52:13,342 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0024668903684952983
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:52:13,350 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0024668903684952983 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:52:18,363 - wandb.wandb_agent - INFO - Running runs: ['8ik5sakw']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165218-8ik5sakw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-774
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8ik5sakw
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4833650787664983 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.535647247619355 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1370072242354734 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.420784733913519 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▆▆▆▆▆▇▇▇▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇█▇██▇█▇▇▇▇█▇████▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▅▁▁▁▁▅▁▁▁▇▇█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced fanciful-sweep-774: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8ik5sakw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165218-8ik5sakw/logs
2022-09-02 16:53:45,938 - wandb.wandb_agent - INFO - Cleaning up finished run: 8ik5sakw
2022-09-02 16:53:46,184 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:53:46,184 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0058542473150618906
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:53:46,190 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0058542473150618906 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:53:51,207 - wandb.wandb_agent - INFO - Running runs: ['sggqtagu']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165351-sggqtagu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-787
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sggqtagu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1668410040057133 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.400657002609112 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.780226842857938 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.224141852749711 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇███▇▇▆▆▆▆▆▆▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▇▇▇▇▇▇▇██▇▇█▇█▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █████████████▇▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁██▁█▁▁▁▁▁▆▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced breezy-sweep-787: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sggqtagu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165351-sggqtagu/logs
2022-09-02 16:55:13,996 - wandb.wandb_agent - INFO - Cleaning up finished run: sggqtagu
2022-09-02 16:55:14,242 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:55:14,242 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.003655211049015796
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:55:14,253 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.003655211049015796 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:55:19,266 - wandb.wandb_agent - INFO - Running runs: ['khh46e47']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165519-khh46e47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-801
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/khh46e47
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.390897146466765 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0533876486614955 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.773763526062371 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1181686486698146 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ███▇▇▇▇▇█████▇▇█▇▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇██▇███▇▇▇▇▇▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁█▄▁▇▁▁▁▁▁▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced efficient-sweep-801: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/khh46e47
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165519-khh46e47/logs
2022-09-02 16:56:41,658 - wandb.wandb_agent - INFO - Cleaning up finished run: khh46e47
2022-09-02 16:56:41,935 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:56:41,935 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00033737074741831304
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:56:41,946 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00033737074741831304 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:56:46,961 - wandb.wandb_agent - INFO - Running runs: ['09vppjq3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165647-09vppjq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-815
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/09vppjq3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.054076228077115 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.490764853181097 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.69682468987463 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.393677457984341 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3850120874531786 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▆▇▆▇▇▇███████▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ██▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁▁▁▂▁▆▁▁▇▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced crisp-sweep-815: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/09vppjq3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165647-09vppjq3/logs
2022-09-02 16:58:19,738 - wandb.wandb_agent - INFO - Cleaning up finished run: 09vppjq3
2022-09-02 16:58:19,981 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:58:19,982 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.008314999014155387
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:58:20,022 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.008314999014155387 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:58:25,033 - wandb.wandb_agent - INFO - Running runs: ['1jl2htdb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165825-1jl2htdb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-830
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1jl2htdb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0003487224981464 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0976328346003568 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.339080922688543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.141622543010016 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2370254823278612 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▆▆▆▆▆▆▆▆▇▇▇██▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▇▇██▇▇▇▆▆▆▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅▁▁▁▁▁▁▁▁▁█▅▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced silvery-sweep-830: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1jl2htdb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165825-1jl2htdb/logs
2022-09-02 16:59:52,803 - wandb.wandb_agent - INFO - Cleaning up finished run: 1jl2htdb
2022-09-02 16:59:53,097 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:59:53,098 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.016295909320376323
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:59:53,107 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.016295909320376323 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:59:58,120 - wandb.wandb_agent - INFO - Running runs: ['ny0ib5hn']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165957-ny0ib5hn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-845
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ny0ib5hn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3351451501201095 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.324217640471015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0000644529152645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.044036274052791 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇███▇▇▇▆▆▆▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▇▇███▇▆▇▇▇▇▇▇▇██▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▇▁▄▁▁▆▁▁▁▁▁▅▇▇▃█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glamorous-sweep-845: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ny0ib5hn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165957-ny0ib5hn/logs
2022-09-02 17:01:20,595 - wandb.wandb_agent - INFO - Cleaning up finished run: ny0ib5hn
2022-09-02 17:01:20,923 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:01:20,923 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.029323664177782437
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:01:20,943 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.029323664177782437 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:01:25,955 - wandb.wandb_agent - INFO - Running runs: ['cutjf70b']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170126-cutjf70b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-860
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cutjf70b
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2709504145878174 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2005262537968004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.843722023348341 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4855447596887896 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█████▇██▇▇▇▆▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▆▆▇▆▇▇▇▇▇▇▆▇▇██▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▂▁▁▅▁▁▁▁▁▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced neat-sweep-860: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cutjf70b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170126-cutjf70b/logs
2022-09-02 17:02:59,389 - wandb.wandb_agent - INFO - Cleaning up finished run: cutjf70b
2022-09-02 17:02:59,665 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:02:59,666 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0030422785858533817
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:02:59,678 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0030422785858533817 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:03:04,692 - wandb.wandb_agent - INFO - Running runs: ['t7w9ww02']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170304-t7w9ww02
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-875
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t7w9ww02
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4734559928073483 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.71301535844144 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.317719231342437 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4742595279627895 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▆▇▆▇▇▇▇▇▇▇▆▆▆▇▇▇██▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▇█▇██▇▇█▇█▇▇▇▇▇▇▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇█▇██▇█████▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▁▁▁▁▁▃▁▁▁▁▁█▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.961
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.039
wandb:  reward 1.0
wandb: 
wandb: Synced cerulean-sweep-875: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t7w9ww02
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170304-t7w9ww02/logs
2022-09-02 17:04:32,336 - wandb.wandb_agent - INFO - Cleaning up finished run: t7w9ww02
2022-09-02 17:04:32,647 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:04:32,648 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00039425186960383504
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:04:32,656 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00039425186960383504 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:04:37,669 - wandb.wandb_agent - INFO - Running runs: ['laihgeqk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170437-laihgeqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-890
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/laihgeqk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1317644891141705 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3742236893709014 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.309852000961874 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆████████████████
wandb:  prop_2 ▅▅▅▅▅▅▄▄▅▄▄▄▄▄▄▄▄▄▄▄▇█▇▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▇▇▇█▇▇▇▇▇█▇▇███▇▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇███▇██████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▂▁▁▁▁▁▂▁▁█▁▁▁▁█▂▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.999
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 1.0
wandb: 
wandb: Synced resilient-sweep-890: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/laihgeqk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170437-laihgeqk/logs
2022-09-02 17:06:10,588 - wandb.wandb_agent - INFO - Cleaning up finished run: laihgeqk
2022-09-02 17:06:10,889 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:06:10,889 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.009656083931487898
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:06:10,897 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.009656083931487898 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:06:15,916 - wandb.wandb_agent - INFO - Running runs: ['rgw9gnin']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170615-rgw9gnin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-905
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rgw9gnin
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.299659737967686 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.839492011955747 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0350487412708365 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▇▇▇▆▇▆▆▇▇██▇█▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▆▆▇▆▆▆▆▆▆▆▇▇▇██▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇▇██▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁█▁▁▁▁▁▁▁▄▁▅▅▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced charmed-sweep-905: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rgw9gnin
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170615-rgw9gnin/logs
2022-09-02 17:07:43,703 - wandb.wandb_agent - INFO - Cleaning up finished run: rgw9gnin
2022-09-02 17:07:44,863 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:07:44,863 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03762759459541861
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:07:44,887 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03762759459541861 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:07:49,901 - wandb.wandb_agent - INFO - Running runs: ['nnw2pl75']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170750-nnw2pl75
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-920
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nnw2pl75
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.248937767242727 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.553546160977118 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.378226435916847 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.290444655531844 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇█▇▇▇▆▇▇▇▇▆▆▇▇▇████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████▇▇███▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁█▅▁▁▁▁▅▁▁█▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.976
wandb:  prop_3 0.0
wandb: prop_NA 0.024
wandb:  reward 0.83716
wandb: 
wandb: Synced bumbling-sweep-920: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nnw2pl75
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170750-nnw2pl75/logs
2022-09-02 17:09:17,996 - wandb.wandb_agent - INFO - Cleaning up finished run: nnw2pl75
2022-09-02 17:09:18,356 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:09:18,356 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.006786527345681556
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:09:18,370 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.006786527345681556 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:09:23,380 - wandb.wandb_agent - INFO - Running runs: ['o59v6s6u']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170923-o59v6s6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-935
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o59v6s6u
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.476505799668175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.118608413474217 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.669559824627286 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇▇▇▇██▇█▇▇▇▇██▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆▇▇▇▇████▇▇▇█▇▇▇▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇▇▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁▁▁▁▁▅▁▁▁▁█▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced confused-sweep-935: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o59v6s6u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170923-o59v6s6u/logs
2022-09-02 17:10:51,219 - wandb.wandb_agent - INFO - Cleaning up finished run: o59v6s6u
2022-09-02 17:10:51,540 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:10:51,540 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0011591301300887746
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:10:51,546 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0011591301300887746 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:10:56,561 - wandb.wandb_agent - INFO - Running runs: ['70s7dugk']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171056-70s7dugk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-951
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/70s7dugk
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.052352075750624 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.142686496176301 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.115866474644479 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.117808718061743 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.426676182829909 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▆▆▆▆▆▆▇▇▇▇▇▇▆▅▆▆▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▇███▇███▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇██████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄▁▃▁▁▁██▁█▁▁█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dauntless-sweep-951: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/70s7dugk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171056-70s7dugk/logs
2022-09-02 17:12:19,152 - wandb.wandb_agent - INFO - Cleaning up finished run: 70s7dugk
2022-09-02 17:12:19,431 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:12:19,432 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001404396296772878
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:12:19,437 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001404396296772878 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:12:24,450 - wandb.wandb_agent - INFO - Running runs: ['qttzn0rb']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171224-qttzn0rb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-963
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qttzn0rb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0068022848011253 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.758014529408979 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4342668059944823 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4879784052678473 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1244955474718745 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▆▆▆▅▆▆▇▇▇▇▇▇▆▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▃▅▇▇▇█████▇█████
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▇██▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb: prop_NA ████████████████████▇▅▄▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁▃▁▁▁▂▁▁▁▁█▁▁▁▅▄▄▆▇████████████▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.518
wandb:  prop_3 0.477
wandb: prop_NA 0.005
wandb:  reward 0.92352
wandb: 
wandb: Synced bumbling-sweep-963: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qttzn0rb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171224-qttzn0rb/logs
2022-09-02 17:13:47,061 - wandb.wandb_agent - INFO - Cleaning up finished run: qttzn0rb
2022-09-02 17:13:47,355 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:13:47,357 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00472971388328803
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:13:47,364 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00472971388328803 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:13:52,385 - wandb.wandb_agent - INFO - Running runs: ['5krcbbly']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171352-5krcbbly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-977
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5krcbbly
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2229050765251284 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3428412414699453 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.271850273813078 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.096737584081791 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.382870883128511 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1076081296015268 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▅▅▆▆▇██▇▇▇▇█▇█▇▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██▇▇▇███▇█████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▃▁▁▁▁▁▁▁▁▄█▁▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced skilled-sweep-977: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5krcbbly
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171352-5krcbbly/logs
2022-09-02 17:15:25,306 - wandb.wandb_agent - INFO - Cleaning up finished run: 5krcbbly
2022-09-02 17:15:25,611 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:15:25,611 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00046252880075274967
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:15:25,626 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00046252880075274967 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:15:30,642 - wandb.wandb_agent - INFO - Running runs: ['ymlu7t1v']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171530-ymlu7t1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-994
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ymlu7t1v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3386974170936172 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.405840590383048 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1598562100834626 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.847204014310403 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4882374317304703 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 █▇▇▇▇▇██▇▇▇▇██▇█▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▇▇▇▇▆▆▆▆▆▆▆▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▅▂█▁▁▁▁▁▁█▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced upbeat-sweep-994: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ymlu7t1v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171530-ymlu7t1v/logs
2022-09-02 17:16:53,186 - wandb.wandb_agent - INFO - Cleaning up finished run: ymlu7t1v
2022-09-02 17:16:53,454 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:16:53,454 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.018796402560065126
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:16:53,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.018796402560065126 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:16:58,473 - wandb.wandb_agent - INFO - Running runs: ['d43lhicf']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171658-d43lhicf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-1005
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d43lhicf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.035396585887818 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3333061323836986 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.258607930617716 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.105980517935985 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▆▆▇▇▇█▇▇█▇▇▇▇██▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆█▇▇▇▇▇▆▆▆▇▇██▇▇▇▇▇▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇█████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ███▁▅▁▁▁▅▁▁▁▁▁▁▄▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced leafy-sweep-1005: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d43lhicf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171658-d43lhicf/logs
2022-09-02 17:18:41,644 - wandb.wandb_agent - INFO - Cleaning up finished run: d43lhicf
2022-09-02 17:18:41,934 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:18:41,934 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00013506107936314427
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:18:41,943 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00013506107936314427 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:18:46,955 - wandb.wandb_agent - INFO - Running runs: ['wxqwc3r3']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171846-wxqwc3r3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-1023
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wxqwc3r3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1038043697193074 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.20960498793449 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.125346559324486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.316650404000075 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.389260441520287 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇█████▇█▇████▇▇▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▄▆▅▅▆▅▆▆▆▇▇▆▆▆▆▆▆▆▆█▇▆▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆████████████████
wandb: prop_NA ████████▇█▇▇█▇▇▇▇████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁█▁▁█▁▁▁▁▅▁▁▁▁▁▂▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced ethereal-sweep-1023: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wxqwc3r3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171846-wxqwc3r3/logs
2022-09-02 17:20:19,802 - wandb.wandb_agent - INFO - Cleaning up finished run: wxqwc3r3
2022-09-02 17:20:20,114 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:20:20,115 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00028628105436896494
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:20:20,131 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00028628105436896494 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:20:25,144 - wandb.wandb_agent - INFO - Running runs: ['jh1ezb95']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172025-jh1ezb95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-1038
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jh1ezb95
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4316474884744554 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.369483059752922 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.898912433138392 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4263905958647016 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.13659819947014 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇████▇▇▇▇▇▇█▇█▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇██████████▇▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▃▁▁▁▁▁▆▁▁▄▁▁▅▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced trim-sweep-1038: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jh1ezb95
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172025-jh1ezb95/logs
2022-09-02 17:22:03,143 - wandb.wandb_agent - INFO - Cleaning up finished run: jh1ezb95
2022-09-02 17:22:03,448 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:22:03,448 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.012929741549823142
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:22:03,471 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.012929741549823142 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:22:08,485 - wandb.wandb_agent - INFO - Running runs: ['girt6ld9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172208-girt6ld9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-1054
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/girt6ld9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3223769594194024 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3335492466892007 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.136002788265749 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.459806989699928 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.578446660071231 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▇▇▇▇▆▆▆▆▇▆▇▇▇▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆█▇▇█▇██▇▇▇▇▇▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced wild-sweep-1054: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/girt6ld9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172208-girt6ld9/logs
2022-09-02 17:23:36,276 - wandb.wandb_agent - INFO - Cleaning up finished run: girt6ld9
2022-09-02 17:23:36,554 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:23:36,554 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.011201486780502468
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:23:36,570 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.011201486780502468 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:23:41,583 - wandb.wandb_agent - INFO - Running runs: ['vbbc12y0']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172341-vbbc12y0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-1067
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vbbc12y0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3170647806654534 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0494834425001693 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3775997382397716 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4994443053702677 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇███▇▇▇███▇▇▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▆▆▆▅▆▆▆▇▇█▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████▇▇▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▇▁▁▁▁▁▁▁█▅▁█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced eager-sweep-1067: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vbbc12y0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172341-vbbc12y0/logs
2022-09-02 17:25:04,155 - wandb.wandb_agent - INFO - Cleaning up finished run: vbbc12y0
2022-09-02 17:25:04,424 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:25:04,425 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00037504255167693977
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:25:04,430 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00037504255167693977 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:25:09,443 - wandb.wandb_agent - INFO - Running runs: ['x82ko4gx']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172510-x82ko4gx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-1081
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x82ko4gx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1432262558954625 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.828406987938749 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.122510401273158 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▆████▇▇▇▇▇███▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████▇▇▆▆▅▄▄▄▄
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▃▄▆▇███
wandb: prop_NA █████████▇▇█████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▇▁▁▁█▁▁▇█▁▁▁▁▆▁▄▂███▇█▂▆▄▆▄▄█████▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.445
wandb:  prop_3 0.538
wandb: prop_NA 0.017
wandb:  reward 0.92352
wandb: 
wandb: Synced morning-sweep-1081: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x82ko4gx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172510-x82ko4gx/logs
2022-09-02 17:26:37,398 - wandb.wandb_agent - INFO - Cleaning up finished run: x82ko4gx
2022-09-02 17:26:37,711 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:26:37,711 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0009962795872790755
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:26:37,717 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0009962795872790755 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:26:42,730 - wandb.wandb_agent - INFO - Running runs: ['iv00obbg']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172643-iv00obbg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-1096
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iv00obbg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.353461866300707 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3345424512816875 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3861326926072515 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▅▅▆▆▆▆▇████▇▇████▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▆▇▆▆▇▇▇▇▇▆▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ████████▇▇▇▇██▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁██▁▁▁▁▁▁▅▁█▇▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fast-sweep-1096: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iv00obbg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172643-iv00obbg/logs
2022-09-02 17:28:20,735 - wandb.wandb_agent - INFO - Cleaning up finished run: iv00obbg
2022-09-02 17:28:21,298 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:28:21,299 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00042136254889329333
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:28:21,308 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00042136254889329333 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:28:26,319 - wandb.wandb_agent - INFO - Running runs: ['jvpzzm8f']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172826-jvpzzm8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-1111
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jvpzzm8f
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.035575604772334 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.307915565700199 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.10026853026323 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0867018699878828 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.896992135127385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4748001102755333 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇████▇▇▇▇▇▇▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆█▇▇▇▇▇▇▇▇▇▇▆▇█████▇▆▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▁▁█▁█▁▁▁█▁█▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced crisp-sweep-1111: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jvpzzm8f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172826-jvpzzm8f/logs
2022-09-02 17:29:59,459 - wandb.wandb_agent - INFO - Cleaning up finished run: jvpzzm8f
2022-09-02 17:29:59,772 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:29:59,772 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01569073566751783
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:29:59,786 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01569073566751783 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:30:04,798 - wandb.wandb_agent - INFO - Running runs: ['8lu3oq8z']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173005-8lu3oq8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-1128
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8lu3oq8z
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.437987460311486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.279493395841916 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.380374712388382 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2228961506140092 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3479857637800734 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇█▇▇▇▇▆▇▇▇▇██▇█▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇█▇▇▇▇▇▆▆▆▆▆▆▇▇▇▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁██▁▄▁▁▁▁▁▁▁▁▁▁▁▇▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fine-sweep-1128: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8lu3oq8z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173005-8lu3oq8z/logs
2022-09-02 17:31:32,760 - wandb.wandb_agent - INFO - Cleaning up finished run: 8lu3oq8z
2022-09-02 17:31:33,052 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:31:33,053 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00015648666137837522
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:31:33,068 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00015648666137837522 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:31:38,086 - wandb.wandb_agent - INFO - Running runs: ['jspgnch1']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173137-jspgnch1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-1141
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jspgnch1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.401666441755133 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0949652008272945 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.74007431677251 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1908734468468194 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.149750400347277 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇██▇▇▆▆▆▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████████▇▇▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▄▁▁█▁▁▅▁▁▁▁▁▁▁▁█▆▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced true-sweep-1141: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jspgnch1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173137-jspgnch1/logs
2022-09-02 17:33:07,216 - wandb.wandb_agent - INFO - Cleaning up finished run: jspgnch1
2022-09-02 17:33:07,508 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:33:07,513 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004440108422515138
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:33:07,522 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004440108422515138 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:33:12,535 - wandb.wandb_agent - INFO - Running runs: ['n4xqajkd']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173312-n4xqajkd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-1159
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n4xqajkd
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.198310665134399 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.914945701325936 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.434039778552854 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.058136770025349 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▅▆▆▆▇▇▇▇▆▇▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇█▇▇▇▇▇▆▆▆▇▇▇▇▇▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████████▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▃▇▁▁▃▁▄▁▁▁█▁▁▁▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.987
wandb:  prop_3 0.0
wandb: prop_NA 0.013
wandb:  reward 0.83716
wandb: 
wandb: Synced pious-sweep-1159: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n4xqajkd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173312-n4xqajkd/logs
2022-09-02 17:34:46,446 - wandb.wandb_agent - INFO - Cleaning up finished run: n4xqajkd
2022-09-02 17:34:46,781 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:34:46,782 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.026946394635433808
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:34:46,796 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.026946394635433808 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:34:51,811 - wandb.wandb_agent - INFO - Running runs: ['cv22m3qg']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173450-cv22m3qg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-1176
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cv22m3qg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4287743364733516 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.115310061144842 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.098134750328034 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇███▇▇▇▇██▇▇▇▇▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇████▇▇▇▇▆▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇██▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁▁█▄▁█▁▁▁▁▁▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced likely-sweep-1176: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cv22m3qg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173450-cv22m3qg/logs
2022-09-02 17:36:14,544 - wandb.wandb_agent - INFO - Cleaning up finished run: cv22m3qg
2022-09-02 17:36:14,906 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:36:14,907 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.006081740362068967
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:36:14,915 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.006081740362068967 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:36:19,928 - wandb.wandb_agent - INFO - Running runs: ['59p06xou']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173619-59p06xou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-1191
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59p06xou
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4886117179979546 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.96696502251794 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.435594154905259 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.379829563748635 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇█████▇▇▇▇▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇█████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▄▁▅▁▁▂▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced noble-sweep-1191: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59p06xou
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173619-59p06xou/logs
2022-09-02 17:37:50,641 - wandb.wandb_agent - INFO - Cleaning up finished run: 59p06xou
2022-09-02 17:37:50,982 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:37:50,982 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.007834503643783741
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:37:50,994 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.007834503643783741 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:37:56,004 - wandb.wandb_agent - INFO - Running runs: ['4hun1hgm']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173755-4hun1hgm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-1206
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4hun1hgm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.029412741929699 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4361224506163253 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.498198186736645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.228393877654701 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇██▇▇▆▆▆▇▆▆▆▆▇▇▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇██████▇▇▇▆▇████▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇▇██████████████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▁▂█▁▁▁▁▇▄▁▁▄▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced royal-sweep-1206: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4hun1hgm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173755-4hun1hgm/logs
2022-09-02 17:39:30,536 - wandb.wandb_agent - INFO - Cleaning up finished run: 4hun1hgm
2022-09-02 17:39:30,831 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:39:30,831 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0023807944892907783
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:39:30,851 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0023807944892907783 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:39:35,866 - wandb.wandb_agent - INFO - Running runs: ['7pvfmkxb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173936-7pvfmkxb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-1221
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7pvfmkxb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.168940312614367 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2405378924914476 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.368113956923245 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▅▅▆▆▆▆▆▆▆▇███████▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇███▇████▇▇▆▆▆▆▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▂▁▁██▁▁▄▁▁▁█▁▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced graceful-sweep-1221: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7pvfmkxb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173936-7pvfmkxb/logs
2022-09-02 17:41:03,510 - wandb.wandb_agent - INFO - Cleaning up finished run: 7pvfmkxb
2022-09-02 17:41:03,842 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:41:03,842 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00010780427878719476
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:41:03,855 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00010780427878719476 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:41:08,866 - wandb.wandb_agent - INFO - Running runs: ['dc2miqna']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174109-dc2miqna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-1235
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dc2miqna
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.191100263595526 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.995679366314102 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2424244084236 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.896353553639961 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇██▇▆▇▆▇██▇▇▇▇▇▇█▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▅▁▁▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced peach-sweep-1235: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dc2miqna
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174109-dc2miqna/logs
2022-09-02 17:42:36,537 - wandb.wandb_agent - INFO - Cleaning up finished run: dc2miqna
2022-09-02 17:42:36,856 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:42:36,856 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0017770160167653495
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:42:36,885 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0017770160167653495 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:42:41,900 - wandb.wandb_agent - INFO - Running runs: ['tsgcceyr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174242-tsgcceyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-1250
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tsgcceyr
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2092048977112153 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484030632655309 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.825903578623296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.022477509716315 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▄▅▇█████▇▇
wandb:  prop_2 ▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇█████▇▅▃▂▁▁▁▁▁▂▂
wandb:  prop_3 █▆▇███▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁▅▁▇▁█▄▇██▁▁▅▇▁▇▁▂███▇█▂▆▄▁▇▄▂▄▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.752
wandb:  prop_2 0.216
wandb:  prop_3 0.0
wandb: prop_NA 0.032
wandb:  reward 1.0
wandb: 
wandb: Synced effortless-sweep-1250: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tsgcceyr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174242-tsgcceyr/logs
2022-09-02 17:44:09,652 - wandb.wandb_agent - INFO - Cleaning up finished run: tsgcceyr
2022-09-02 17:44:09,976 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:44:09,977 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004511672834143048
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:44:09,990 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004511672834143048 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:44:15,002 - wandb.wandb_agent - INFO - Running runs: ['59rkn4n8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174415-59rkn4n8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-1265
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59rkn4n8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0088344661598123 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4462732653468375 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2685372964585895 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇████▇▆▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇▇▇██████▇█▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅▁▁▁▁▁▅▁█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced stilted-sweep-1265: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59rkn4n8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174415-59rkn4n8/logs
2022-09-02 17:45:42,758 - wandb.wandb_agent - INFO - Cleaning up finished run: 59rkn4n8
2022-09-02 17:45:43,086 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:45:43,086 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0012539569331325492
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:45:43,125 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0012539569331325492 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:45:48,139 - wandb.wandb_agent - INFO - Running runs: ['qmcmbovr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174548-qmcmbovr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-1280
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qmcmbovr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.255437418344157 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▅▆▇▇█▇▇▇▆▆▆▆▆▆▆▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▇▁▁▅▁▁▁▁▁█▁▁▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced rural-sweep-1280: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qmcmbovr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174548-qmcmbovr/logs
2022-09-02 17:47:21,061 - wandb.wandb_agent - INFO - Cleaning up finished run: qmcmbovr
2022-09-02 17:47:21,350 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:47:21,351 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00791368100629209
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:47:21,379 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00791368100629209 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:47:26,393 - wandb.wandb_agent - INFO - Running runs: ['lvhycy0b']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174727-lvhycy0b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-1295
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lvhycy0b
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.337774811459095 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.43906955766644 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇█▇▇▇███▇▇▇▇██▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▁▁▁▇▁▁▁█▄▁▇▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced zany-sweep-1295: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lvhycy0b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174727-lvhycy0b/logs
2022-09-02 17:48:59,223 - wandb.wandb_agent - INFO - Cleaning up finished run: lvhycy0b
2022-09-02 17:48:59,504 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:48:59,505 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0007745446255745981
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:48:59,543 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0007745446255745981 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:49:04,559 - wandb.wandb_agent - INFO - Running runs: ['rbh1hrhl']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174905-rbh1hrhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-1310
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rbh1hrhl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.332753184283753 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.084322392713546 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2913997140076656 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇█████▇▇▆▅▃▃▂▂▂▁▂
wandb:  prop_2 ▅▆▆▆▇▇███▇▆▇▇▇▇▇▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▂▃▅▆▇▇▇███
wandb: prop_NA ▇█████▇▇▇███████████▇▆▄▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂
wandb:  reward ▁▁▁▁▁▁▁█▁▁▁▂▁▁▁▁▁▁▁▇█▃▅▅▆▂▇▂▅█▇█▇▆██▃▅▇█
wandb: 
wandb: Run summary:
wandb:  prop_1 0.167
wandb:  prop_2 0.0
wandb:  prop_3 0.729
wandb: prop_NA 0.104
wandb:  reward 0.92352
wandb: 
wandb: Synced pious-sweep-1310: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rbh1hrhl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174905-rbh1hrhl/logs
2022-09-02 17:50:37,553 - wandb.wandb_agent - INFO - Cleaning up finished run: rbh1hrhl
2022-09-02 17:50:37,833 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:50:37,833 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0004326526868018073
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:50:37,857 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0004326526868018073 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:50:42,871 - wandb.wandb_agent - INFO - Running runs: ['71bmp2we']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175044-71bmp2we
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-1325
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/71bmp2we
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4545704682126366 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.120210454762021 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.139326967911031 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇████▇██▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▇▇▇▇████▇▇▇▆▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▁▃▁▁▁▁▅▁▅▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced smart-sweep-1325: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/71bmp2we
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175044-71bmp2we/logs
2022-09-02 17:52:15,690 - wandb.wandb_agent - INFO - Cleaning up finished run: 71bmp2we
2022-09-02 17:52:15,974 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:52:15,974 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.017678458803427166
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:52:16,012 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.017678458803427166 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:52:21,026 - wandb.wandb_agent - INFO - Running runs: ['iz1wes57']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175221-iz1wes57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-1340
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iz1wes57
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2445467263570675 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.486020142912244 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇██▇▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇████▇█████▇█▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁█▁▄▁▁▁▁▇▁▁▁▁▁▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fluent-sweep-1340: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iz1wes57
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175221-iz1wes57/logs
2022-09-02 17:53:57,658 - wandb.wandb_agent - INFO - Cleaning up finished run: iz1wes57
2022-09-02 17:53:57,966 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:53:57,966 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00022095923842519927
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:53:57,972 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00022095923842519927 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:54:02,986 - wandb.wandb_agent - INFO - Running runs: ['19ke0h88']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175403-19ke0h88
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-1354
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/19ke0h88
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.016788398491889 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.040844094331755 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.024426340872903 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3101286468229385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.60153795694189 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇█▇▇▇▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇▇███▇█▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇████████████████▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇▄▁▅▁▁▁▁▅██▅▁█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.998
wandb: prop_NA 0.002
wandb:  reward 0.92352
wandb: 
wandb: Synced elated-sweep-1354: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/19ke0h88
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175403-19ke0h88/logs
2022-09-02 17:55:30,978 - wandb.wandb_agent - INFO - Cleaning up finished run: 19ke0h88
2022-09-02 17:55:31,317 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:55:31,318 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0001135785882299824
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:55:31,325 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0001135785882299824 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:55:36,338 - wandb.wandb_agent - INFO - Running runs: ['fxa584dx']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175537-fxa584dx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-1369
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fxa584dx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.125700372686396 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3129596967128494 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7031752238624325 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇█████████▇▇▇▆▅▄▃
wandb:  prop_2 ▅▇▆▆▆▇▇▆▇▇▇▇▇▇▇████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅▇█
wandb: prop_NA ███████████████▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁█▁█▁▁▁▁▁▁▁▄▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.307
wandb:  prop_2 0.0
wandb:  prop_3 0.69
wandb: prop_NA 0.003
wandb:  reward 0.92352
wandb: 
wandb: Synced dry-sweep-1369: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fxa584dx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175537-fxa584dx/logs
2022-09-02 17:56:58,908 - wandb.wandb_agent - INFO - Cleaning up finished run: fxa584dx
2022-09-02 17:56:59,175 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:56:59,176 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.006053479722373583
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:56:59,181 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.006053479722373583 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:57:04,195 - wandb.wandb_agent - INFO - Running runs: ['jl26sd7q']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175704-jl26sd7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-1384
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jl26sd7q
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3160669819242456 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.437510095142303 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.145331227879897 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1787375812125847 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.077720180351157 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.353778545945323 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇████▇▇███████▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ███▇▇▇▇▇▇▆▆▇▇█▇████▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇█████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▃▁▁▁▇▁▁▁▁▁▇▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced trim-sweep-1384: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jl26sd7q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175704-jl26sd7q/logs
2022-09-02 17:58:37,050 - wandb.wandb_agent - INFO - Cleaning up finished run: jl26sd7q
2022-09-02 17:58:37,337 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:58:37,337 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.007588836363880122
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:58:37,345 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.007588836363880122 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:58:42,360 - wandb.wandb_agent - INFO - Running runs: ['smbx8q72']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175842-smbx8q72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-1403
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/smbx8q72
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2236033221568676 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3993693722693985 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.522279611187313 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.33474607253864 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.633241363831291 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▅▆▆▆▇▇▇▇▇▇▇▇███▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇███████▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁█▁▁▁▄▆▅█▁▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced hardy-sweep-1403: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/smbx8q72
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175842-smbx8q72/logs
2022-09-02 18:00:15,402 - wandb.wandb_agent - INFO - Cleaning up finished run: smbx8q72
2022-09-02 18:00:15,742 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:00:15,742 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.01042993667432112
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:00:15,750 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.01042993667432112 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:00:20,765 - wandb.wandb_agent - INFO - Running runs: ['l2r8mt5l']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180019-l2r8mt5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-1421
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l2r8mt5l
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.090913305518136 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.279051825906876 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.044473955494485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.093848654685789 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.558961637999621 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▆▇▆▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▇▇▆▇▇▇███▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██▇█▇▇█▇▇▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▃▁▁▁▂▁▁▁▁▁▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced silvery-sweep-1421: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l2r8mt5l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180019-l2r8mt5l/logs
2022-09-02 18:01:53,679 - wandb.wandb_agent - INFO - Cleaning up finished run: l2r8mt5l
2022-09-02 18:01:53,990 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:01:53,990 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.003633538503144825
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:01:53,997 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.003633538503144825 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:01:59,033 - wandb.wandb_agent - INFO - Running runs: ['nizrv6v3']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180158-nizrv6v3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-1436
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nizrv6v3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2366565101077214 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0353216792679913 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.169034750589235 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7553417394285376 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▆▆▆▇▇▇▇█▇▇▇▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇██▇▇▇▇▆▆▆▆▆▆▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▅▂▁▁▁▁▁▁▄▁▁▁▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced dainty-sweep-1436: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nizrv6v3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180158-nizrv6v3/logs
2022-09-02 18:03:37,096 - wandb.wandb_agent - INFO - Cleaning up finished run: nizrv6v3
2022-09-02 18:03:37,351 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:03:37,352 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0007751997799944812
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:03:37,371 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0007751997799944812 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:03:42,386 - wandb.wandb_agent - INFO - Running runs: ['zfzyd9wi']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180343-zfzyd9wi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-1451
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zfzyd9wi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4714181213500126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.212015428253619 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.064500140427416 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆██████▇█▇▇▇▇▇█▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▇▆▇▇▆▆▆▆▇▇████▇▇▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇█▇▇████▇████▇█▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▅▁▁█▁▁██▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fearless-sweep-1451: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zfzyd9wi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180343-zfzyd9wi/logs
2022-09-02 18:05:05,176 - wandb.wandb_agent - INFO - Cleaning up finished run: zfzyd9wi
2022-09-02 18:05:05,451 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:05:05,452 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.017194426090467823
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:05:05,457 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.017194426090467823 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:05:10,485 - wandb.wandb_agent - INFO - Running runs: ['tu0gehcp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180510-tu0gehcp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-1465
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tu0gehcp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.05954151288635 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3384996126802795 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4677817575924026 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.117875209026597 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▆▆▆▇▇▆▆▆▆▇▇▇▇▆▆▇▇▇▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▆▆▆▆▆▇███▇▇▇▆▆▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇█████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▄▁▁▁▇▇▄▁▅▄▁▁███▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced radiant-sweep-1465: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tu0gehcp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180510-tu0gehcp/logs
2022-09-02 18:06:38,305 - wandb.wandb_agent - INFO - Cleaning up finished run: tu0gehcp
2022-09-02 18:06:38,625 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:06:38,627 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.011839564260397992
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:06:38,632 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.011839564260397992 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:06:43,647 - wandb.wandb_agent - INFO - Running runs: ['mmb9ybmt']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180644-mmb9ybmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-1480
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mmb9ybmt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.019442540490652 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆█▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇██▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇████████████████▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▁▁▁█▄█▁▁▁▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced astral-sweep-1480: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mmb9ybmt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180644-mmb9ybmt/logs
2022-09-02 18:08:12,035 - wandb.wandb_agent - INFO - Cleaning up finished run: mmb9ybmt
2022-09-02 18:08:12,295 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:08:12,295 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00015540477189080924
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:08:12,301 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00015540477189080924 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:08:17,316 - wandb.wandb_agent - INFO - Running runs: ['1uos1g88']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180817-1uos1g88
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-1495
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1uos1g88
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4112244537642162 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3573515820234485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0641282414363378 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1168918040748412 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7753812910483475 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃
wandb:  prop_2 ▃▅▅▅▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆▆█▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄▁▁▁▁▁▇▁█▁▁▁▁▃▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.036
wandb:  prop_2 0.0
wandb:  prop_3 0.955
wandb: prop_NA 0.009
wandb:  reward 0.92352
wandb: 
wandb: Synced swift-sweep-1495: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1uos1g88
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180817-1uos1g88/logs
2022-09-02 18:09:39,755 - wandb.wandb_agent - INFO - Cleaning up finished run: 1uos1g88
2022-09-02 18:09:40,070 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:09:40,071 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005939527789560235
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:09:40,077 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005939527789560235 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:09:45,091 - wandb.wandb_agent - INFO - Running runs: ['m8ha56j2']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180945-m8ha56j2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-1510
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m8ha56j2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.260481102948761 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.612361907441939 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▇▇▇▇█▇██▇█▇██▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▆████▇▇▇▇▇█▇█▇▇▇▇█▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇██▇██▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▁▁▆▁▁▁▁▁▁█▇▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dauntless-sweep-1510: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m8ha56j2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180945-m8ha56j2/logs
2022-09-02 18:11:07,736 - wandb.wandb_agent - INFO - Cleaning up finished run: m8ha56j2
2022-09-02 18:11:08,072 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:11:08,072 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00035278256174076864
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:11:08,078 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00035278256174076864 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:11:13,092 - wandb.wandb_agent - INFO - Running runs: ['i9411pc6']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181113-i9411pc6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-1524
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i9411pc6
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.265318849517603 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.626508047446674 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▆▆▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁█▁▁▁▁▁▁▁▁█▁▇▇▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.964
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.036
wandb:  reward 1.0
wandb: 
wandb: Synced deep-sweep-1524: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i9411pc6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181113-i9411pc6/logs
2022-09-02 18:12:40,834 - wandb.wandb_agent - INFO - Cleaning up finished run: i9411pc6
2022-09-02 18:12:41,187 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:12:41,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00032627867035517897
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:12:41,194 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00032627867035517897 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:12:46,209 - wandb.wandb_agent - INFO - Running runs: ['njrprf4s']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181246-njrprf4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-1539
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/njrprf4s
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3259653971941048 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.15352423994909 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0674155253151696 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.837756077265228 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.444506305278317 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.755356990991513 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▆▆▇▇▇██████▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇███▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇██▇▇▇▇█████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▃█▆█▁▅▁▁██▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.991
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.009
wandb:  reward 1.0
wandb: 
wandb: Synced trim-sweep-1539: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/njrprf4s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181246-njrprf4s/logs
2022-09-02 18:14:13,897 - wandb.wandb_agent - INFO - Cleaning up finished run: njrprf4s
2022-09-02 18:14:14,174 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:14:14,174 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.006188361639132584
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:14:14,178 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.006188361639132584 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:14:19,193 - wandb.wandb_agent - INFO - Running runs: ['dbec1d9i']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181419-dbec1d9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-1554
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dbec1d9i
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.142091119412001 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.512430350940998 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.404338645831523 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.035823169626499 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.132051039224727 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇██▇▇▇▆▇▇██████▇▇▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▆▇▇▇█▇█▇▇▇▇▇▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇▇████████████▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▂▇▁▁▁██▁▁█▅▁▆▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced northern-sweep-1554: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dbec1d9i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181419-dbec1d9i/logs
2022-09-02 18:15:52,088 - wandb.wandb_agent - INFO - Cleaning up finished run: dbec1d9i
2022-09-02 18:15:52,401 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:15:52,401 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.012245096552075866
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:15:52,408 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.012245096552075866 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:15:57,422 - wandb.wandb_agent - INFO - Running runs: ['o6b5am6y']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181559-o6b5am6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-1570
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o6b5am6y
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.221656925547842 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.01766753676108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4669615915354752 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▆▆▆▇▇▇▆▆▆▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇█▇███▇▇▇▇▇▇██▇█▇▇█▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁█▇▃▅▄▁▁▁▁▁▁▇▇█▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced worthy-sweep-1570: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o6b5am6y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181559-o6b5am6y/logs
2022-09-02 18:17:25,233 - wandb.wandb_agent - INFO - Cleaning up finished run: o6b5am6y
2022-09-02 18:17:25,533 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:17:25,533 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001877498321072456
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:17:25,545 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001877498321072456 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:17:30,562 - wandb.wandb_agent - INFO - Running runs: ['fcdi6pax']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181730-fcdi6pax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-1583
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fcdi6pax
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.497763950329306 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1020911310466723 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.591927764404389 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▅▅▅▅▅▅▅▅▅▆▆▆▆▅▅▅▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇█▇████▇▇▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▁▁▁▁▁█▁▁▁▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced clean-sweep-1583: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fcdi6pax
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181730-fcdi6pax/logs
2022-09-02 18:18:53,181 - wandb.wandb_agent - INFO - Cleaning up finished run: fcdi6pax
2022-09-02 18:18:54,458 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:18:54,458 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0028941451188047025
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:18:54,471 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0028941451188047025 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:18:59,487 - wandb.wandb_agent - INFO - Running runs: ['5v9w4y0p']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181859-5v9w4y0p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-1598
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5v9w4y0p
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1722133421471925 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2253741193540675 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▆▇▇▇██▇▆▆▆▇████▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▇▇▇▇▇▇█▇█▇▇▇▇██▇▇▇█▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▇▄▁▃▁▁▁▁▁▁▁█▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced icy-sweep-1598: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5v9w4y0p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181859-5v9w4y0p/logs
2022-09-02 18:20:21,977 - wandb.wandb_agent - INFO - Cleaning up finished run: 5v9w4y0p
2022-09-02 18:20:22,263 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:20:22,264 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00396840562838103
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:20:22,269 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00396840562838103 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:20:27,284 - wandb.wandb_agent - INFO - Running runs: ['0bfsj2i0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182028-0bfsj2i0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-1611
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0bfsj2i0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.073746712627979 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.52387479098959 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▆▆▆▆▆▆▆▆▆▆▇▇▇█▇▇▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▅▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▆█▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▄█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fresh-sweep-1611: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0bfsj2i0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182028-0bfsj2i0/logs
2022-09-02 18:21:54,961 - wandb.wandb_agent - INFO - Cleaning up finished run: 0bfsj2i0
2022-09-02 18:21:55,227 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:21:55,227 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.009513669037384258
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:21:55,233 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.009513669037384258 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:22:00,248 - wandb.wandb_agent - INFO - Running runs: ['mzxnu9ok']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182200-mzxnu9ok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-1626
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mzxnu9ok
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0118465875437255 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.414057261141764 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4296462877691454 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇████▇▇▆▆▇▇█████▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▆▆▆▅▅▅▅▆▆▇▇▆▆▅▅▅▅▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████▇▇██████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁█▁▁▄▇▁▁█▁▁█▆█▁▇▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced wandering-sweep-1626: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mzxnu9ok
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182200-mzxnu9ok/logs
2022-09-02 18:23:33,129 - wandb.wandb_agent - INFO - Cleaning up finished run: mzxnu9ok
2022-09-02 18:23:33,435 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:23:33,435 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04819683158142168
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:23:33,442 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04819683158142168 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:23:38,458 - wandb.wandb_agent - INFO - Running runs: ['ax45z9ff']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182338-ax45z9ff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-1643
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ax45z9ff
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3943753585932193 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.030104285179665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.017380567310094 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▆▆▆▇▇██▇▇▇▆▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▇▆▆▆▆▆▆▆▇▆▆▆▆▇▇██▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁▁█▁█▁▁▁▁▇█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced drawn-sweep-1643: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ax45z9ff
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182338-ax45z9ff/logs
2022-09-02 18:25:00,987 - wandb.wandb_agent - INFO - Cleaning up finished run: ax45z9ff
2022-09-02 18:25:01,285 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:25:01,285 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005290963741129271
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:25:01,292 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005290963741129271 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:25:06,308 - wandb.wandb_agent - INFO - Running runs: ['e7wtg3sh']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182505-e7wtg3sh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-1657
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e7wtg3sh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4617417094796914 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0762809049421973 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.928659774614221 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▆▆▇▇▇▇▆▆▆▆▆▆▆▇███▇▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▆▆▆▅▆▆▇███▇▇▇▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.98
wandb:  prop_3 0.0
wandb: prop_NA 0.02
wandb:  reward 0.83716
wandb: 
wandb: Synced colorful-sweep-1657: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e7wtg3sh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182505-e7wtg3sh/logs
2022-09-02 18:26:34,034 - wandb.wandb_agent - INFO - Cleaning up finished run: e7wtg3sh
2022-09-02 18:26:34,331 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:26:34,332 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0005508141347600368
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:26:34,352 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0005508141347600368 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:26:39,402 - wandb.wandb_agent - INFO - Running runs: ['zjb80co3']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182639-zjb80co3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-1670
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zjb80co3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4073923417143916 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.179094248478217 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2431265059971075 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.501975509772025 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇█▇█▇█████▇█▇▇▇▆▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▆▇▇▆▇▆▇▇▇█▇▇▇▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████▇█████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁█▁▁▁█▁▁█▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.998
wandb:  prop_3 0.0
wandb: prop_NA 0.002
wandb:  reward 0.83716
wandb: 
wandb: Synced drawn-sweep-1670: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zjb80co3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182639-zjb80co3/logs
2022-09-02 18:28:07,256 - wandb.wandb_agent - INFO - Cleaning up finished run: zjb80co3
2022-09-02 18:28:07,570 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:28:07,570 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011681992074845394
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:28:07,591 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011681992074845394 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:28:12,615 - wandb.wandb_agent - INFO - Running runs: ['c82sgukl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182811-c82sgukl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-1684
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c82sgukl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.20403461230141 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.695223572603503 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4151028557761727 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.415123855547913 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇███▇▇▇▇▇▆▆▆▇▇█▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇▄▁▁▁█▁▁▄██▄▁█▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced graceful-sweep-1684: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c82sgukl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182811-c82sgukl/logs
2022-09-02 18:29:40,299 - wandb.wandb_agent - INFO - Cleaning up finished run: c82sgukl
2022-09-02 18:29:40,640 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:29:40,641 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.021083673029970974
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:29:40,693 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.021083673029970974 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:29:45,710 - wandb.wandb_agent - INFO - Running runs: ['c77lgl5j']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182946-c77lgl5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-1699
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c77lgl5j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1452361887599887 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.700351253239985 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.404498776924435 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.376515156049694 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▆▇█████▇█▇▇██▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▆▆▆▆▆▆▆▆▅▅▅▆▅▆▅▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▁▄▁▁▁▁▁▁▁▁▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced astral-sweep-1699: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c77lgl5j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182946-c77lgl5j/logs
2022-09-02 18:31:18,526 - wandb.wandb_agent - INFO - Cleaning up finished run: c77lgl5j
2022-09-02 18:31:18,820 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:31:18,820 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0199201237347325
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:31:18,830 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0199201237347325 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:31:23,844 - wandb.wandb_agent - INFO - Running runs: ['jo6tnk70']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183124-jo6tnk70
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-1714
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jo6tnk70
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3735093316787967 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7220825805998246 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.288582071793786 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3392975841309065 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇████▇▇▇▆▆▆▇▇▇▇▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇██████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁█▁▁▁▁▁▁▁▁▅▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dulcet-sweep-1714: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jo6tnk70
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183124-jo6tnk70/logs
2022-09-02 18:32:52,568 - wandb.wandb_agent - INFO - Cleaning up finished run: jo6tnk70
2022-09-02 18:32:52,845 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:32:52,845 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00027635048930689814
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:32:52,854 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00027635048930689814 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:32:57,868 - wandb.wandb_agent - INFO - Running runs: ['xot8sqj8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183300-xot8sqj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-1729
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xot8sqj8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.435055202038091 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.380287681616121 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2620249316445857 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.033072947792631 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▇███▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▅▆▅▆▆▆▆▆▆▅▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇█▁▁▅▁█▁▁█▁▁▁▁▃██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.998
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.002
wandb:  reward 1.0
wandb: 
wandb: Synced generous-sweep-1729: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xot8sqj8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183300-xot8sqj8/logs
2022-09-02 18:34:30,808 - wandb.wandb_agent - INFO - Cleaning up finished run: xot8sqj8
2022-09-02 18:34:31,255 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:34:31,258 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00010617068507079688
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:34:31,265 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00010617068507079688 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:34:36,282 - wandb.wandb_agent - INFO - Running runs: ['ubzq58kb']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183435-ubzq58kb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-1750
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ubzq58kb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.203893936790001 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.414865425211328 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.130530107190091 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.656624925259192 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇██▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▅▇▇▇████▇▇▇▇▇▇▇▇▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁█▁█▃▁█▁▁▁▁▁▅▁▁▁▁▁▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced warm-sweep-1750: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ubzq58kb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183435-ubzq58kb/logs
2022-09-02 18:36:04,057 - wandb.wandb_agent - INFO - Cleaning up finished run: ubzq58kb
2022-09-02 18:36:04,675 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:36:04,679 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0008394693776261367
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:36:04,691 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0008394693776261367 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:36:09,725 - wandb.wandb_agent - INFO - Running runs: ['rx1css7c']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183609-rx1css7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-1765
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rx1css7c
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0905590443529163 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.136938135133964 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9212534164683905 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.076930427240342 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.322517758291502 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▆▆▆▇▇▇█▇████▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▇▁▁▁█▁▁▁▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced desert-sweep-1765: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rx1css7c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183609-rx1css7c/logs
2022-09-02 18:37:42,675 - wandb.wandb_agent - INFO - Cleaning up finished run: rx1css7c
2022-09-02 18:37:42,978 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:37:42,978 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001299587490895432
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:37:42,989 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001299587490895432 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:37:48,002 - wandb.wandb_agent - INFO - Running runs: ['6vq285d3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183748-6vq285d3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-1780
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6vq285d3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4105307167061687 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.418923671811999 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.298398857912898 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.10151496425898 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.853958493938558 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁█▅▅▁▁▁▁█▁▁▇▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced woven-sweep-1780: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6vq285d3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183748-6vq285d3/logs
2022-09-02 18:39:20,814 - wandb.wandb_agent - INFO - Cleaning up finished run: 6vq285d3
2022-09-02 18:39:21,086 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:39:21,086 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0018944685466097716
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:39:21,098 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0018944685466097716 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:39:26,113 - wandb.wandb_agent - INFO - Running runs: ['d5uef7xe']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183926-d5uef7xe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-1795
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d5uef7xe
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.438039749396689 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4354835078515693 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.724121644399703 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.373783965650195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8518776755810755 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█████▇▇▇▇▇▇████▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA █▇███████████▇█▇▇███▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁█▁▁▁▁▁▁█▁▁▇▆█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced earthy-sweep-1795: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d5uef7xe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183926-d5uef7xe/logs
2022-09-02 18:40:53,760 - wandb.wandb_agent - INFO - Cleaning up finished run: d5uef7xe
2022-09-02 18:40:54,048 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:40:54,048 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03212708710424433
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:40:54,058 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03212708710424433 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:40:59,073 - wandb.wandb_agent - INFO - Running runs: ['fh4utims']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184059-fh4utims
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-1810
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fh4utims
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.022312791611122 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.301480070437705 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.935979182316462 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇██▇▇▇▇█▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▆█▇▇▇▇█▇▆▆▆▇▆▇▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁█▁▁▁▇▅▁▆██▄▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced eager-sweep-1810: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fh4utims
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184059-fh4utims/logs
2022-09-02 18:42:37,004 - wandb.wandb_agent - INFO - Cleaning up finished run: fh4utims
2022-09-02 18:42:37,322 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:42:37,322 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.04975890276725311
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:42:37,328 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.04975890276725311 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:42:42,343 - wandb.wandb_agent - INFO - Running runs: ['oct7280w']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184242-oct7280w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-1826
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/oct7280w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.261599265398589 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.38026420379607 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0624368593473004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.994210352529718 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▅▇▇▇█████▇▇█▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆█▇▇▇▇▇▇▆▆▇▇▆▇▇▇█▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇██████████▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▅█▁▁▇▁▆▁▅▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced electric-sweep-1826: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/oct7280w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184242-oct7280w/logs
2022-09-02 18:44:11,382 - wandb.wandb_agent - INFO - Cleaning up finished run: oct7280w
2022-09-02 18:44:16,568 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:44:16,569 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.026851157216033116
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:44:16,579 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.026851157216033116 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:44:21,594 - wandb.wandb_agent - INFO - Running runs: ['9ds5luza']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184423-9ds5luza
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-1840
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9ds5luza
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.380485117893257 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇█▇▇▆▆▇▇▇▇▇▇▇██▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████▇██▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁█▁█▁▁▁▁▆█▁▁▁▁▁▁█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced usual-sweep-1840: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9ds5luza
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184423-9ds5luza/logs
2022-09-02 18:45:49,251 - wandb.wandb_agent - INFO - Cleaning up finished run: 9ds5luza
2022-09-02 18:45:49,524 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:45:49,524 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00027218264935151
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:45:49,530 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00027218264935151 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:45:54,546 - wandb.wandb_agent - INFO - Running runs: ['q6envwgb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184555-q6envwgb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-1855
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q6envwgb
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.297055775307052 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.130616312898664 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.76905714912812 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▅▆███████████████
wandb:  prop_2 ▄▄▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▇█▇▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆█▇▆▆▆▆▇▇▇▇▇▇▇▆▆▆▆▆▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇█████▇▇█▇▇█▇█████▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▄▁▃▁█▁▇▄▁▁▁▁▁▁▇██▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced zesty-sweep-1855: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q6envwgb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184555-q6envwgb/logs
2022-09-02 18:47:22,149 - wandb.wandb_agent - INFO - Cleaning up finished run: q6envwgb
2022-09-02 18:47:22,607 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:47:22,625 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0010824660344822526
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:47:22,631 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0010824660344822526 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:47:27,647 - wandb.wandb_agent - INFO - Running runs: ['rafwcytj']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184727-rafwcytj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-1871
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rafwcytj
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.478540788053174 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7435064670179266 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇▇▆▆▆▆▇▇████▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇███▇▇▇▆▆▆▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▄▅▅▁▁▂▁█▁▁▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.026
wandb:  prop_3 0.947
wandb: prop_NA 0.027
wandb:  reward 0.92352
wandb: 
wandb: Synced summer-sweep-1871: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rafwcytj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184727-rafwcytj/logs
2022-09-02 18:49:05,725 - wandb.wandb_agent - INFO - Cleaning up finished run: rafwcytj
2022-09-02 18:49:06,000 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:49:06,000 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0006940396574307136
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:49:06,008 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0006940396574307136 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:49:11,023 - wandb.wandb_agent - INFO - Running runs: ['f2iqkr76']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184911-f2iqkr76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-1887
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f2iqkr76
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.422101965398058 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.695377817863852 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0214386348758824 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.905485341803193 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▆▇▆▆▇▇██▇███▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇███▇▆▆▆▆▆▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▅▂▁▁▁▁▁▁▁▁▁▁▇▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced radiant-sweep-1887: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f2iqkr76
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184911-f2iqkr76/logs
2022-09-02 18:50:44,028 - wandb.wandb_agent - INFO - Cleaning up finished run: f2iqkr76
2022-09-02 18:50:44,322 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:50:44,322 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0081985134821196
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:50:44,327 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0081985134821196 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:50:49,344 - wandb.wandb_agent - INFO - Running runs: ['4c0khckl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185048-4c0khckl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-1901
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4c0khckl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4049139474193386 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.250556510141969 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.292999531507404 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.492778830831553 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4930855519985657 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▇▇████████▇▇██▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▆▅▅▅▅▅▆▅▆▅▅▆▅▆▆▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA █▇█████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁█▄█▁▁▁▁▁▁▁▁██▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced iconic-sweep-1901: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4c0khckl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185048-4c0khckl/logs
2022-09-02 18:52:22,121 - wandb.wandb_agent - INFO - Cleaning up finished run: 4c0khckl
2022-09-02 18:52:22,420 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:52:22,421 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0063702005568288325
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:52:22,426 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0063702005568288325 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:52:27,446 - wandb.wandb_agent - INFO - Running runs: ['hrp1vuow']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185226-hrp1vuow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-1916
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hrp1vuow
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0508038002148385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.922965334857759 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.44145529201203 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.692705920588719 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2653794146437627 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.309098799309858 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇██▇█▇▇▇▇█▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▆▆▇▇██▇█▇▆▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██▇▇▇▇▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▅█▁▁▅▁█▂▁█▁▁▇▇▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced giddy-sweep-1916: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hrp1vuow
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185226-hrp1vuow/logs
2022-09-02 18:53:49,931 - wandb.wandb_agent - INFO - Cleaning up finished run: hrp1vuow
2022-09-02 18:53:50,251 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:53:50,251 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0017806723391495657
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:53:50,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0017806723391495657 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:53:55,271 - wandb.wandb_agent - INFO - Running runs: ['22d7u277']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185355-22d7u277
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-1930
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/22d7u277
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0492720848834556 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2666943862237146 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0782547412335335 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4475709528719207 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.211378398733768 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▅▆▆▆▆▆▇▇▇▇▇████▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ███▇▆▆▆▆▇▇▇▇▇▆▇▆▆▆▆▇▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇███████▇██████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁▁▇▇▁▁▁▁▁▆▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced cosmic-sweep-1930: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/22d7u277
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185355-22d7u277/logs
2022-09-02 18:55:23,033 - wandb.wandb_agent - INFO - Cleaning up finished run: 22d7u277
2022-09-02 18:55:23,325 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:55:23,325 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005859490426384727
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:55:23,334 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005859490426384727 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:55:28,349 - wandb.wandb_agent - INFO - Running runs: ['qc6ojbdo']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185530-qc6ojbdo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-1944
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qc6ojbdo
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2453151859323306 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.083841203063856 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.500315965172133 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3713706444093865 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.170705109679652 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▇▇▇▇▇▇▇█▇▇█▇███▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▆█
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████▇▆▄▃
wandb: prop_NA █████████▇▇▇▇▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▅▁▄▁▁▄▁▁▁█▁▁▁▆▁▄▅▄▄▆█▅██████▇▆███▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.696
wandb:  prop_3 0.284
wandb: prop_NA 0.02
wandb:  reward 0.83716
wandb: 
wandb: Synced solar-sweep-1944: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qc6ojbdo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185530-qc6ojbdo/logs
2022-09-02 18:56:56,656 - wandb.wandb_agent - INFO - Cleaning up finished run: qc6ojbdo
2022-09-02 18:56:57,101 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:56:57,105 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.010197490188583276
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:56:57,114 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.010197490188583276 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:57:02,129 - wandb.wandb_agent - INFO - Running runs: ['n6dyn3e3']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185701-n6dyn3e3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-1964
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n6dyn3e3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.256478935866146 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.086656353507986 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.561326229445751 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2807112033032686 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.069892874694475 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇█████▇███▇▇▇▇██▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▁▁▁▁█▁▁▁█▅▁▇▆▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced sweet-sweep-1964: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n6dyn3e3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185701-n6dyn3e3/logs
2022-09-02 18:58:24,661 - wandb.wandb_agent - INFO - Cleaning up finished run: n6dyn3e3
2022-09-02 18:58:24,996 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:58:24,999 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0001600214397110273
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:58:25,018 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0001600214397110273 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:58:30,035 - wandb.wandb_agent - INFO - Running runs: ['dnez5qpz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185831-dnez5qpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-1976
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dnez5qpz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.346968750868486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.19928117951651 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.664423826431652 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.334880981780788 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.272200778172335 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▆▇▇▇█▇▇▇▇█████▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇█████████████▇▅▃
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅█
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁█▁▁▁▁█▂▁▁▁▁█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.35
wandb:  prop_3 0.623
wandb: prop_NA 0.027
wandb:  reward 0.92352
wandb: 
wandb: Synced glad-sweep-1976: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dnez5qpz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185831-dnez5qpz/logs
2022-09-02 18:59:57,839 - wandb.wandb_agent - INFO - Cleaning up finished run: dnez5qpz
2022-09-02 18:59:58,164 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:59:58,165 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0035654854146992907
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:59:58,176 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0035654854146992907 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 19:00:03,191 - wandb.wandb_agent - INFO - Running runs: ['r0uaa50y']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
slurmstepd: error: *** JOB 2474905 ON arc-c308 CANCELLED AT 2022-09-02T19:00:08 ***
