wandb: Starting wandb agent 🕵️
2022-09-02 15:32:10,133 - wandb.wandb_agent - INFO - Running runs: []
2022-09-02 15:32:10,788 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:32:10,788 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00022305781018195923
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:32:10,794 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00022305781018195923 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:32:15,806 - wandb.wandb_agent - INFO - Running runs: ['46k112wp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153216-46k112wp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-18
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/46k112wp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.486395600078107 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.117696866392826 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.046837585007849 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3632839521640534 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.791724047940544 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.373202841046008 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
2022-09-02 15:33:38,251 - wandb.wandb_agent - INFO - Cleaning up finished run: 46k112wp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▇▇▆▆▆▆▆▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████████████▇
wandb: prop_NA ▇▇███████████████▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▁▁▁▃▁█▇▁▁▁▁▅▇▆▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.024
wandb:  prop_3 0.928
wandb: prop_NA 0.048
wandb:  reward 0.92352
wandb: 
wandb: Synced electric-sweep-18: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/46k112wp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153216-46k112wp/logs
2022-09-02 15:33:43,227 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:33:43,227 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0012742356048369157
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:33:43,234 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0012742356048369157 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:33:48,246 - wandb.wandb_agent - INFO - Running runs: ['l51gikeg']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153347-l51gikeg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-30
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l51gikeg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4338810791243324 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3970658487545564 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.945093499802085 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2805327174380015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.20345477396413 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.315485098542479 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.677933132856001 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ██▇▇▇▆█▇▇▇▇▇▇▇▇▇███▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆█▇▆▇▇▇███▇▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▁▄▁▃▁▁▁▁▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.972
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.028
wandb:  reward 1.0
wandb: 
wandb: Synced pious-sweep-30: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l51gikeg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153347-l51gikeg/logs
2022-09-02 15:35:15,853 - wandb.wandb_agent - INFO - Cleaning up finished run: l51gikeg
2022-09-02 15:35:16,138 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:35:16,138 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.020271743130059017
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:35:16,145 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.020271743130059017 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:35:21,156 - wandb.wandb_agent - INFO - Running runs: ['ff7h0q4w']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153522-ff7h0q4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-42
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ff7h0q4w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3955615225505937 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.132143647377804 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.218732436736774 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.327680213697627 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.015323569018497 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.134180223147886 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇▇▇▆▇▇▆▆▇▇▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▆▆▆▇▇▇████▇▇█▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▃▁▁▁▁▁▁▁▁▄▁█▁▇▁▇▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced cool-sweep-42: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ff7h0q4w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153522-ff7h0q4w/logs
2022-09-02 15:36:43,605 - wandb.wandb_agent - INFO - Cleaning up finished run: ff7h0q4w
2022-09-02 15:36:43,876 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:36:43,876 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00010540480223298792
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:36:43,886 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00010540480223298792 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:36:48,898 - wandb.wandb_agent - INFO - Running runs: ['b3w1lhjk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153650-b3w1lhjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-55
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b3w1lhjk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2210645680907235 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.084465957466453 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2723252599874364 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.000067534417614 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.030987992550195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7193217929109235 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▆▇█████████████
wandb:  prop_2 ▂▂▂▂▂▂▂▃▃▃▂▂▂▂▃▃▃▃▃▃▄▆▇█▇▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇█▇█▇▆▇▆▇▇▇▇▇█▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁█▁▁▁█▁▄▆▁▅▁▁▁▁▂▁▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced generous-sweep-55: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b3w1lhjk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153650-b3w1lhjk/logs
2022-09-02 15:38:16,735 - wandb.wandb_agent - INFO - Cleaning up finished run: b3w1lhjk
2022-09-02 15:38:16,984 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:38:16,984 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.013215247952415384
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:38:16,990 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.013215247952415384 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:38:22,002 - wandb.wandb_agent - INFO - Running runs: ['vudnm47c']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153821-vudnm47c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-73
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vudnm47c
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.427526122017937 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.564106790987656 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2200205059556737 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.824353072439597 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1326123269274504 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8523180837700775 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▆▆▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▅▆▆▆▆▆▇▇▆▆▆▇██▇▇▇▆▆▆▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████▇▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁███▁█▁▄▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced serene-sweep-73: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vudnm47c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153821-vudnm47c/logs
2022-09-02 15:39:44,610 - wandb.wandb_agent - INFO - Cleaning up finished run: vudnm47c
2022-09-02 15:39:44,865 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:39:44,866 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.02351656329150579
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:39:44,871 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.02351656329150579 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:39:49,884 - wandb.wandb_agent - INFO - Running runs: ['5f5n5lrn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153950-5f5n5lrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-85
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5f5n5lrn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1959841415522776 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.560820411072699 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0361155465213874 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.632323318195756 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3055462176050066 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.294470732510098 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▆▇████▇▇▇▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ████▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇██████████▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁█▁▂▅█▁▁▁█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced good-sweep-85: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5f5n5lrn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153950-5f5n5lrn/logs
2022-09-02 15:41:12,302 - wandb.wandb_agent - INFO - Cleaning up finished run: 5f5n5lrn
2022-09-02 15:41:12,562 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:41:12,563 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002452685340658139
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:41:12,577 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002452685340658139 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:41:17,612 - wandb.wandb_agent - INFO - Running runs: ['kcshrd7a']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154117-kcshrd7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-99
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kcshrd7a
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.45709747064616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.23398564015649 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.870367344867658 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.091210173122305 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.546609867678662 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▆▇████████████████
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇▇███████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁▁█▆▁▁▁█▅█▁▁▃▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.999
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 1.0
wandb: 
wandb: Synced good-sweep-99: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kcshrd7a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154117-kcshrd7a/logs
2022-09-02 15:42:49,801 - wandb.wandb_agent - INFO - Cleaning up finished run: kcshrd7a
2022-09-02 15:42:50,057 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:42:50,057 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00022286319058515227
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:42:50,063 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00022286319058515227 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:42:55,075 - wandb.wandb_agent - INFO - Running runs: ['d7rj96b9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154254-d7rj96b9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-116
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d7rj96b9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.383416930464005 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.016223623884777 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.394680393568447 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.779987411912665 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▆▇███▇▇▆▆▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆█▇▇▆▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▁▆█▁▁▁█▅▁█▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.999
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 0.83716
wandb: 
wandb: Synced soft-sweep-116: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d7rj96b9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154254-d7rj96b9/logs
2022-09-02 15:44:17,922 - wandb.wandb_agent - INFO - Cleaning up finished run: d7rj96b9
2022-09-02 15:44:18,183 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:44:18,184 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0026218994797481267
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:44:18,206 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0026218994797481267 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:44:23,217 - wandb.wandb_agent - INFO - Running runs: ['8qr5h47r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154425-8qr5h47r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-128
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8qr5h47r
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.391440099138185 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0977994730370337 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2783959274260264 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.071712967388147 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▇▇▆▆▆▆▆▇▇▇█████▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▅▁▇▁▁▁▁▁▁▆▁▁▁▇▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fluent-sweep-128: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8qr5h47r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154425-8qr5h47r/logs
2022-09-02 15:45:56,003 - wandb.wandb_agent - INFO - Cleaning up finished run: 8qr5h47r
2022-09-02 15:45:56,257 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:45:56,258 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008642154302993409
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:45:56,281 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008642154302993409 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:46:01,296 - wandb.wandb_agent - INFO - Running runs: ['o1743qtn']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154600-o1743qtn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-146
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o1743qtn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.390335443756949 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.03850077602242 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.37816317512347 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2107279942691873 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4210676552786894 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.195208648358231 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇███▇▇▇█▇▇▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▅▁█▁▁▁▁▁▁▁▁█▁▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced swift-sweep-146: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o1743qtn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154600-o1743qtn/logs
2022-09-02 15:47:23,745 - wandb.wandb_agent - INFO - Cleaning up finished run: o1743qtn
2022-09-02 15:47:24,003 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:47:24,004 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.008839021203089796
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:47:24,024 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.008839021203089796 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:47:29,039 - wandb.wandb_agent - INFO - Running runs: ['xli2j1eb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154730-xli2j1eb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-159
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xli2j1eb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2636365602861828 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▆▇███▇▇▇▇▇▆▆▆▆▆▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▅▆▆▇▇████▇▇▇▇▇▇▇▇██▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▄▃█▁▇█▄▁█▁▁▁█▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced autumn-sweep-159: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xli2j1eb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154730-xli2j1eb/logs
2022-09-02 15:49:12,119 - wandb.wandb_agent - INFO - Cleaning up finished run: xli2j1eb
2022-09-02 15:49:12,360 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:49:12,361 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0014547643029558224
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:49:12,367 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0014547643029558224 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:49:17,379 - wandb.wandb_agent - INFO - Running runs: ['cx2op4ss']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154917-cx2op4ss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-179
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cx2op4ss
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3478795326619153 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.641589632573234 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2752429315941627 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4605027612779695 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.127902205028384 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇████▇▆▆▆▇▆▆▆▆▇▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆▆▆▆▇▇▇█████▇██▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁█▃█▆▁▁▁▁█▁▁█▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced celestial-sweep-179: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cx2op4ss
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154917-cx2op4ss/logs
2022-09-02 15:50:39,846 - wandb.wandb_agent - INFO - Cleaning up finished run: cx2op4ss
2022-09-02 15:50:40,103 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:50:40,104 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.049285065761495946
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:50:40,111 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.049285065761495946 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:50:45,124 - wandb.wandb_agent - INFO - Running runs: ['akkvxq3y']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155044-akkvxq3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-193
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/akkvxq3y
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1778631519689635 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.948485202428763 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.360823164270412 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7060551535164095 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.497006530456148 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4522752692274223 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▆▆▇▇▇▇▇▇▇███▇▇▆▇▆▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▃▁█▁▅▅▁▁▇▁▁▁▁▇▁█▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced mild-sweep-193: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/akkvxq3y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155044-akkvxq3y/logs
2022-09-02 15:52:12,648 - wandb.wandb_agent - INFO - Cleaning up finished run: akkvxq3y
2022-09-02 15:52:12,898 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:52:12,898 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.000720081860712264
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:52:12,904 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.000720081860712264 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:52:17,922 - wandb.wandb_agent - INFO - Running runs: ['fcyy71c5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155216-fcyy71c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-209
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fcyy71c5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3871629923500643 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.518420045042488 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.229871002415822 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.729208518744333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4051655160039527 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.87858840497098 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1792655468223865 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▇▇▇███▇▇▇▇███▇▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▇▃█▁█▂▁█▁▅█▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.976
wandb: prop_NA 0.024
wandb:  reward 0.92352
wandb: 
wandb: Synced noble-sweep-209: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fcyy71c5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155216-fcyy71c5/logs
2022-09-02 15:53:45,544 - wandb.wandb_agent - INFO - Cleaning up finished run: fcyy71c5
2022-09-02 15:53:45,785 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:53:45,785 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0006599828727670337
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:53:45,794 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0006599828727670337 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:53:50,809 - wandb.wandb_agent - INFO - Running runs: ['kl3thkye']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155349-kl3thkye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-223
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kl3thkye
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.080984129145231 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.455889937592563 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1603888034889067 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.784514334633766 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.012814710367789 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.233917088567355 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1789269321059312 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▇▆▆▇▇▇█▇▇███▇▆▇▇██▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁▆▁▇▁▁█▁▇▆▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.999
wandb: prop_NA 0.001
wandb:  reward 0.92352
wandb: 
wandb: Synced fearless-sweep-223: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kl3thkye
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155349-kl3thkye/logs
2022-09-02 15:55:18,995 - wandb.wandb_agent - INFO - Cleaning up finished run: kl3thkye
2022-09-02 15:55:19,251 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:55:19,252 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.000705312006078071
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:55:19,257 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.000705312006078071 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:55:24,271 - wandb.wandb_agent - INFO - Running runs: ['c5gmstu0']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155523-c5gmstu0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-238
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c5gmstu0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3800622445489172 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484961920864309 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.048160385069076 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2731653374985497 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.238284562807152 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0943532676142302 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.190614997364317 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▆▇▇▇▇▇▆▇▇▇██████▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇▇▇▇████▇▇▇▆▆▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁█▁▁▆▁█▁▁█▁▁▁▃██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.962
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.038
wandb:  reward 1.0
wandb: 
wandb: Synced likely-sweep-238: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c5gmstu0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155523-c5gmstu0/logs
2022-09-02 15:56:46,858 - wandb.wandb_agent - INFO - Cleaning up finished run: c5gmstu0
2022-09-02 15:56:47,111 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:56:47,111 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.016229912624633934
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:56:47,126 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.016229912624633934 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:56:52,139 - wandb.wandb_agent - INFO - Running runs: ['4080dnxz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155651-4080dnxz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-250
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4080dnxz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0809329472001594 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.599369325647149 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4136337737402105 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2288456060627113 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.862013875468841 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇█▇▇▇▇▇▇███▇█▇███▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▇▇▇▇█▇▇▇▇▇██▇█▇▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁█▃▅▁▇▂▁▁█▁▁▆▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced celestial-sweep-250: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4080dnxz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155651-4080dnxz/logs
2022-09-02 15:58:11,575 - wandb.wandb_agent - INFO - Cleaning up finished run: 4080dnxz
2022-09-02 15:58:11,813 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:58:11,813 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005939754269417255
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:58:11,819 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005939754269417255 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:58:16,832 - wandb.wandb_agent - INFO - Running runs: ['uzuyf1ps']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155816-uzuyf1ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-261
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uzuyf1ps
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2223522854789888 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.130702756706987 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.515090356594947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2463300071624843 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.044514853306023 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇▇▇▇▇▇▇███████▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆██▇▇▆▇▇▇▇▇▇▇▇███▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▄█▂█▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.976
wandb:  prop_3 0.0
wandb: prop_NA 0.024
wandb:  reward 0.83716
wandb: 
wandb: Synced grateful-sweep-261: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uzuyf1ps
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155816-uzuyf1ps/logs
2022-09-02 15:59:44,430 - wandb.wandb_agent - INFO - Cleaning up finished run: uzuyf1ps
2022-09-02 15:59:44,664 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:59:44,665 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0009630058309606936
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:59:44,669 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0009630058309606936 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:59:49,681 - wandb.wandb_agent - INFO - Running runs: ['vksxdg9l']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155949-vksxdg9l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-279
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vksxdg9l
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0026909396218735 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4907235745343765 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.604204008264289 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.197448366825479 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.405821324013428 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.038567030535081 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.063370686651159 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▆▇▇████▇▇▇▇▇▇▇▇██▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆█▇▆▆▆▇▇█████▇▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced playful-sweep-279: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vksxdg9l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155949-vksxdg9l/logs
2022-09-02 16:01:17,344 - wandb.wandb_agent - INFO - Cleaning up finished run: vksxdg9l
2022-09-02 16:01:17,576 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:01:17,577 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005613848040471955
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:01:17,582 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005613848040471955 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:01:22,594 - wandb.wandb_agent - INFO - Running runs: ['jg77xtbn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160124-jg77xtbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-294
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jg77xtbn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.220766712464907 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.117527423605443 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.073899754369931 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.157555082492255 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.273306197642217 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▇▇▇▇▆▇▇▇██████▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇▆▆▆▆▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅██▂▁▁█▁█▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.966
wandb: prop_NA 0.034
wandb:  reward 0.92352
wandb: 
wandb: Synced dainty-sweep-294: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jg77xtbn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160124-jg77xtbn/logs
2022-09-02 16:02:58,387 - wandb.wandb_agent - INFO - Cleaning up finished run: jg77xtbn
2022-09-02 16:02:58,648 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:02:58,649 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0006602967948492165
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:02:58,656 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0006602967948492165 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:03:03,668 - wandb.wandb_agent - INFO - Running runs: ['a2opu5t4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160303-a2opu5t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-314
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a2opu5t4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4581159279267584 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.239955770911632 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3677665485231008 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.047819407357516 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4206808006967093 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▆▇▇█▇▇▇▇▇█▇▇▇███▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▇▇▇▇▇▇█████▇█▇██▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁█▆▁▁▄▁▁█▇▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced easy-sweep-314: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a2opu5t4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160303-a2opu5t4/logs
2022-09-02 16:04:31,596 - wandb.wandb_agent - INFO - Cleaning up finished run: a2opu5t4
2022-09-02 16:04:40,999 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:04:40,999 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005495785222066527
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:04:41,027 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005495785222066527 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:04:46,043 - wandb.wandb_agent - INFO - Running runs: ['bus5d76m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160446-bus5d76m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-327
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bus5d76m
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0523462011257116 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3132931593808195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1048036056022705 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.763305345652763 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.358290602007995 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.318974238187171 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▆▆▆▆▆▇▇▇█▇▇▆▇▇███▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇▇▇▇▆▆▇▇▇▇▇█▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁▁▁█▁██▁▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced light-sweep-327: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bus5d76m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160446-bus5d76m/logs
2022-09-02 16:06:13,667 - wandb.wandb_agent - INFO - Cleaning up finished run: bus5d76m
2022-09-02 16:06:13,911 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:06:13,911 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.010204905276201291
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:06:13,919 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.010204905276201291 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:06:18,933 - wandb.wandb_agent - INFO - Running runs: ['3qcxr2l4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160618-3qcxr2l4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-343
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3qcxr2l4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0261593547723202 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.763669644531138 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.092323277709801 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.820148302067461 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.255964414659652 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▇▇▇▇▇████▇█▇▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇████████████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▁▁▁▆▁▁▁██▄▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced solar-sweep-343: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3qcxr2l4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160618-3qcxr2l4/logs
2022-09-02 16:07:41,347 - wandb.wandb_agent - INFO - Cleaning up finished run: 3qcxr2l4
2022-09-02 16:07:42,912 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:07:42,925 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0031009629284101618
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:07:42,940 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0031009629284101618 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:07:47,956 - wandb.wandb_agent - INFO - Running runs: ['1801zm1w']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160748-1801zm1w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-354
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1801zm1w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4792497991942595 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.635370606062034 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.37138011675216 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.265291458573586 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▅▅▆▆▆▆▇▇▇██▇▇▆▆▆▇▇▇▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▆▇▇██▇▇▇▆▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇▇▇▇█▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁█▁█▁▁▂▁▁▁▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.98
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.02
wandb:  reward 1.0
wandb: 
wandb: Synced faithful-sweep-354: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1801zm1w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160748-1801zm1w/logs
2022-09-02 16:09:20,866 - wandb.wandb_agent - INFO - Cleaning up finished run: 1801zm1w
2022-09-02 16:09:22,761 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:09:22,761 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008063085245125117
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:09:22,781 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008063085245125117 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:09:27,796 - wandb.wandb_agent - INFO - Running runs: ['za3e5rg6']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160927-za3e5rg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-370
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/za3e5rg6
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0014782994074727 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.515540318838665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.394109715994993 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4788034899079388 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▆▆▆▆▇▇▇▇▇▇██▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇▆▆▆▆▆▆▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▁▁▁▁███▁▁▁▄▁▆▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced bumbling-sweep-370: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/za3e5rg6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160927-za3e5rg6/logs
2022-09-02 16:10:50,425 - wandb.wandb_agent - INFO - Cleaning up finished run: za3e5rg6
2022-09-02 16:10:50,672 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:10:50,673 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03110163214243764
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:10:50,688 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03110163214243764 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:10:55,703 - wandb.wandb_agent - INFO - Running runs: ['wl7qee6k']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161057-wl7qee6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-384
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wl7qee6k
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2193449448067004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.732962105397598 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3320482526668096 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.255102654346675 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2947780308870716 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.146689468487207 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0716726767088787 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.240752141275414 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇█▇▇▇▇▇▆▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ███████▇██████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄█▁▅▁█▁▅▁▁▇▄▁▅▁▁▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced solar-sweep-384: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wl7qee6k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161057-wl7qee6k/logs
2022-09-02 16:12:18,535 - wandb.wandb_agent - INFO - Cleaning up finished run: wl7qee6k
2022-09-02 16:12:18,768 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:12:18,768 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.016480963183179754
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:12:18,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.016480963183179754 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:12:23,804 - wandb.wandb_agent - INFO - Running runs: ['p670qirh']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161225-p670qirh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-392
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/p670qirh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0545813100198256 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.19926333522785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.070963754726378 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1294714930601253 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.619015849541007 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▇▆▇▇▇▇▇▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▇▇▇▇▇▇▇▇▇▆▇▆▇▇▇▇█▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁██▁▁▁▁▁▆▁▁▁▆▁▅▇▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced swift-sweep-392: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/p670qirh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161225-p670qirh/logs
2022-09-02 16:14:01,692 - wandb.wandb_agent - INFO - Cleaning up finished run: p670qirh
2022-09-02 16:14:02,006 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:14:02,006 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005866253629436425
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:14:02,014 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005866253629436425 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:14:07,028 - wandb.wandb_agent - INFO - Running runs: ['8tsqlx7m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161407-8tsqlx7m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-414
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8tsqlx7m
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0273261158829237 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.055500096427726 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1082648308992926 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.007337915692627 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1661963669790687 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.275442346074906 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▇▇▇▆▇▇█▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▂▃▄▄▄▄▅
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████▇██▇
wandb: prop_NA ███████████████▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▇▁▁▁█▁▁▁▁▁▁█▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.069
wandb:  prop_2 0.0
wandb:  prop_3 0.931
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced noble-sweep-414: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8tsqlx7m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161407-8tsqlx7m/logs
2022-09-02 16:15:38,154 - wandb.wandb_agent - INFO - Cleaning up finished run: 8tsqlx7m
2022-09-02 16:15:38,505 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:15:38,506 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01624898584866323
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:15:38,528 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01624898584866323 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:15:43,541 - wandb.wandb_agent - INFO - Running runs: ['0ara8acz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161543-0ara8acz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-427
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0ara8acz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4211879210182565 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.030206960417649 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.119514069831047 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.209097815434299 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.827431988804285 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.15242642594759 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▇▆▇▇▇████▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇█████▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▄▁▁█▁▁▃▁▁▁▁▅▁▁▁▁▁▃▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.972
wandb:  prop_3 0.0
wandb: prop_NA 0.028
wandb:  reward 0.83716
wandb: 
wandb: Synced stilted-sweep-427: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0ara8acz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161543-0ara8acz/logs
2022-09-02 16:17:06,034 - wandb.wandb_agent - INFO - Cleaning up finished run: 0ara8acz
2022-09-02 16:17:06,278 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:17:06,278 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004546635430559107
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:17:06,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004546635430559107 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:17:11,301 - wandb.wandb_agent - INFO - Running runs: ['spcyl087']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161710-spcyl087
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-441
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/spcyl087
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.132552135255065 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.250241319966829 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2906577495935148 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.678882490580606 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇█▇▇▇▇▇██▇▇▆▇▇██▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▇▇▇▇▇████▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▁▁▃▁▄█▁▁▁▁▄▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced elated-sweep-441: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/spcyl087
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161710-spcyl087/logs
2022-09-02 16:18:44,143 - wandb.wandb_agent - INFO - Cleaning up finished run: spcyl087
2022-09-02 16:18:44,400 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:18:44,400 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0006578322032109668
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:18:44,408 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0006578322032109668 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:18:49,420 - wandb.wandb_agent - INFO - Running runs: ['m1l7lvtz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161849-m1l7lvtz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-457
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m1l7lvtz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.097318734061126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0030187749320536 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.090499904473313 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3449474000257293 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.254876145497352 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇██▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▅▅▅▅▅▅▅▅▅▅▅▅▄▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇██████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▄▁█▁▁▁▁██▁▁▁▃█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.001
wandb:  prop_2 0.985
wandb:  prop_3 0.0
wandb: prop_NA 0.014
wandb:  reward 0.83716
wandb: 
wandb: Synced polar-sweep-457: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m1l7lvtz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161849-m1l7lvtz/logs
2022-09-02 16:20:17,001 - wandb.wandb_agent - INFO - Cleaning up finished run: m1l7lvtz
2022-09-02 16:20:17,287 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:20:17,288 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006073601776133727
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:20:17,294 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006073601776133727 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:20:22,306 - wandb.wandb_agent - INFO - Running runs: ['2jnwg41b']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162021-2jnwg41b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-473
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2jnwg41b
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.490009654897195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.240997086612889 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.98797302225015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3243420142271556 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0402125160040394 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇█
wandb:  prop_2 █▇▇▆▆▆▅▆▆▅▆▅▅▅▅▆▆▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▇███████████▇▅▃▂▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅█▁▁▁▁▁▁▁▁▁▃▁▅▄▄▆█▅██████▇▆██▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced summer-sweep-473: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2jnwg41b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162021-2jnwg41b/logs
2022-09-02 16:21:44,743 - wandb.wandb_agent - INFO - Cleaning up finished run: 2jnwg41b
2022-09-02 16:21:44,985 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:21:44,985 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00016943009852058458
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:21:44,992 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00016943009852058458 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:21:50,004 - wandb.wandb_agent - INFO - Running runs: ['3n12vxii']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162151-3n12vxii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-485
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3n12vxii
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4631134201684324 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0088776208016332 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.31534286932873 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1367075921711125 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.53381200736287 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇█▇█▇▇▇▇██▇▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇█████▇▇▇▇▇▇▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA █████████████████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▁█▇▁▁▁▁▁▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced jolly-sweep-485: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3n12vxii
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162151-3n12vxii/logs
2022-09-02 16:23:22,913 - wandb.wandb_agent - INFO - Cleaning up finished run: 3n12vxii
2022-09-02 16:23:23,171 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:23:23,171 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008756249899558496
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:23:23,177 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008756249899558496 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:23:28,193 - wandb.wandb_agent - INFO - Running runs: ['7csewbxy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162328-7csewbxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-498
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7csewbxy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.48110129604976 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0433721709904527 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9790732592659435 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2465601298495055 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.918241689126373 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ███▇▇▇▇▆▇▆▆▆▇▆▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇█████████████▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁█▁▁▁▁▄▁▁█▆██▁▇▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced blooming-sweep-498: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7csewbxy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162328-7csewbxy/logs
2022-09-02 16:24:50,933 - wandb.wandb_agent - INFO - Cleaning up finished run: 7csewbxy
2022-09-02 16:24:51,210 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:24:51,210 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.02875957559397049
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:24:51,220 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.02875957559397049 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:24:56,231 - wandb.wandb_agent - INFO - Running runs: ['astiwwpk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162458-astiwwpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-511
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/astiwwpk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.004665624918114 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.732336960949095 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.223107412236869 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9782429331628215 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.404991359300963 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5305942533216825 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▇▇▇▇▇▇██▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▆▇▇▆▆▆▆▇▇▇▇▆▆▇▇▇▇▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁█▁▁▆▁▅▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced ethereal-sweep-511: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/astiwwpk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162458-astiwwpk/logs
2022-09-02 16:26:34,681 - wandb.wandb_agent - INFO - Cleaning up finished run: astiwwpk
2022-09-02 16:26:34,949 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:26:34,949 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.007149724356104734
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:26:34,958 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.007149724356104734 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:26:39,971 - wandb.wandb_agent - INFO - Running runs: ['hn05et74']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162642-hn05et74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-530
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hn05et74
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.44662826535951 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3243377557945717 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.07702620715125 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.261704896676144 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▆▆▇▇█▇▇▇▇▇▇▇▆▇▇▇██▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇█▇▇████▇▇▇▇▇▇▇▇▇█▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▃▁▄▇█▁▁█▁█▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced bumbling-sweep-530: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hn05et74
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162642-hn05et74/logs
2022-09-02 16:28:08,024 - wandb.wandb_agent - INFO - Cleaning up finished run: hn05et74
2022-09-02 16:28:08,314 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:28:08,315 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.040914344457931635
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:28:08,323 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.040914344457931635 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:28:13,336 - wandb.wandb_agent - INFO - Running runs: ['xc1hmysh']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162813-xc1hmysh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-543
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xc1hmysh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0990609288857693 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0303668230278085 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.615100186850179 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4153988646641458 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4610279343185812 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇████▇▇▆▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▆▆▅▆▆▆▇▇▇████▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇████████▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▇▂▄▁▅▁▁▁▁▁▁▁▇▆▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced smart-sweep-543: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xc1hmysh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162813-xc1hmysh/logs
2022-09-02 16:29:51,412 - wandb.wandb_agent - INFO - Cleaning up finished run: xc1hmysh
2022-09-02 16:29:51,680 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:29:51,680 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00010672717638392678
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:29:51,686 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00010672717638392678 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:29:56,698 - wandb.wandb_agent - INFO - Running runs: ['x564jzrp']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162956-x564jzrp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-563
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x564jzrp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.19341788576771 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.309268023777426 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3175118398610124 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████████████▇
wandb:  prop_3 █▇▆▆▆▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▄
wandb: prop_NA ▇▇██████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▂▇▁▁▁█▁▁▁▁▁▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.903
wandb:  prop_3 0.074
wandb: prop_NA 0.023
wandb:  reward 0.83716
wandb: 
wandb: Synced crimson-sweep-563: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x564jzrp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162956-x564jzrp/logs
2022-09-02 16:31:24,294 - wandb.wandb_agent - INFO - Cleaning up finished run: x564jzrp
2022-09-02 16:31:24,545 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:31:24,545 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0010194245489723963
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:31:24,557 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0010194245489723963 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:31:29,570 - wandb.wandb_agent - INFO - Running runs: ['sdtdv5nr']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163129-sdtdv5nr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-576
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sdtdv5nr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.474835567526417 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.083859646046025 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.851820669806035 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2079104920098493 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.437079069504189 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▆▇▇▇█▇▇█▇▇▇▆▇▇▇██▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▆▆▅▆▆▇▇▇▇▆▆▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇██████████████▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁█▁▁▁█▁▁▁▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.976
wandb:  prop_2 0.005
wandb:  prop_3 0.0
wandb: prop_NA 0.019
wandb:  reward 1.0
wandb: 
wandb: Synced playful-sweep-576: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sdtdv5nr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163129-sdtdv5nr/logs
2022-09-02 16:32:57,141 - wandb.wandb_agent - INFO - Cleaning up finished run: sdtdv5nr
2022-09-02 16:32:57,390 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:32:57,390 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00012965983405139524
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:32:57,398 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00012965983405139524 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:33:02,419 - wandb.wandb_agent - INFO - Running runs: ['c9rsra1m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163302-c9rsra1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-591
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c9rsra1m
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3913886835474436 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.522450744879901 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0576736941096994 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.787602224638856 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0525227469756064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.672252675759566 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▆▆▆▇▇▇▇▇▇▇▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇▇████▇█▇██▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁▁▁▆▁▇▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced earthy-sweep-591: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c9rsra1m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163302-c9rsra1m/logs
2022-09-02 16:34:30,051 - wandb.wandb_agent - INFO - Cleaning up finished run: c9rsra1m
2022-09-02 16:34:30,308 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:34:30,308 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001706460855138419
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:34:30,325 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001706460855138419 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:34:35,338 - wandb.wandb_agent - INFO - Running runs: ['j05ojq42']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163434-j05ojq42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-606
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j05ojq42
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.335875780660474 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0692751757620877 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.001705813675134 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0143853249016717 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.266205981125211 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.330841128642516 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6652775936017195 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇███▇███▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆▆▇▇█▇▆▆▆▇▇█▇█████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▇▁▁▅▁▁▇▁▁▁▅▅▁▇▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced genial-sweep-606: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j05ojq42
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163434-j05ojq42/logs
2022-09-02 16:36:08,100 - wandb.wandb_agent - INFO - Cleaning up finished run: j05ojq42
2022-09-02 16:36:08,899 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:36:08,900 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.010689545378084395
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:36:08,933 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.010689545378084395 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:36:13,949 - wandb.wandb_agent - INFO - Running runs: ['9dvmxmg4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163614-9dvmxmg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-621
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9dvmxmg4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2218168587947185 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.084102967251508 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.907237702586946 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2603288932131425 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1519569702288552 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9462072419481755 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 █▆▆▆▆▆▆▆▇▆▆▆▅▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ████▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▃█▁▁▃▁▁█▂▁▁▁██▁▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced curious-sweep-621: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9dvmxmg4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163614-9dvmxmg4/logs
2022-09-02 16:37:39,618 - wandb.wandb_agent - INFO - Cleaning up finished run: 9dvmxmg4
2022-09-02 16:37:39,887 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:37:39,888 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0009272292280608944
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:37:39,929 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0009272292280608944 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:37:44,946 - wandb.wandb_agent - INFO - Running runs: ['r3bbubqg']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163745-r3bbubqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-635
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r3bbubqg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.026087726811515 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.227382247065691 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0888169070562017 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.083444324505616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.378265288172367 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██████▇▇▇▇▇▇▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▅▅▆▆▆▇▇▇▇████▇▇▇▇█▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁█▁▁▁▁▇▄▁█▁█▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced playful-sweep-635: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r3bbubqg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163745-r3bbubqg/logs
2022-09-02 16:39:23,520 - wandb.wandb_agent - INFO - Cleaning up finished run: r3bbubqg
2022-09-02 16:39:23,830 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:39:23,830 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01026853755314066
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:39:23,836 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01026853755314066 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:39:28,849 - wandb.wandb_agent - INFO - Running runs: ['fgjf4j3z']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163927-fgjf4j3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-652
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fgjf4j3z
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.438439158968044 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.027399612697021 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.390186919723665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3317193536510965 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.519457939795791 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇██▇█▇▇▇▇▇▇▇▇▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆▇▇▇▇▆▆▆▇▇▇██▇█▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▃▁▁█▁▅▁█▁▁▆▁▅▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced wobbly-sweep-652: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fgjf4j3z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163927-fgjf4j3z/logs
2022-09-02 16:40:51,285 - wandb.wandb_agent - INFO - Cleaning up finished run: fgjf4j3z
2022-09-02 16:40:51,561 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:40:51,562 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.008855210461758176
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:40:51,589 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.008855210461758176 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:40:56,604 - wandb.wandb_agent - INFO - Running runs: ['45w6yket']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164056-45w6yket
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-665
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/45w6yket
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3651265012773424 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.416740879212344 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4116761160134734 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3061389028573442 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.260116195801178 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▆▆▆▆▆▆▇▇▇▇▇▇██▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁▄█▁▁█▇▁█▁▁▇▁▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced expert-sweep-665: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/45w6yket
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164056-45w6yket/logs
2022-09-02 16:42:29,717 - wandb.wandb_agent - INFO - Cleaning up finished run: 45w6yket
2022-09-02 16:42:30,163 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:42:30,166 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0023049065915278296
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:42:30,206 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0023049065915278296 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:42:35,222 - wandb.wandb_agent - INFO - Running runs: ['8erxy84f']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164234-8erxy84f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-681
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8erxy84f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4174920994115228 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.344572436404019 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.155114106548882 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.47691716294117 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▇▇▇▇▇▇▇█▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▅▅▆▆▆▇▇▇▆▆▅▆▆▇▇██▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇██████▇▇█████▇█▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅▄▁▁▁▁▁█▄▁▁▅▇▁▇▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced splendid-sweep-681: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8erxy84f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164234-8erxy84f/logs
2022-09-02 16:44:08,590 - wandb.wandb_agent - INFO - Cleaning up finished run: 8erxy84f
2022-09-02 16:44:08,836 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:44:08,836 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0003351800580818444
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:44:08,851 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0003351800580818444 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:44:13,865 - wandb.wandb_agent - INFO - Running runs: ['0ojcvljv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164414-0ojcvljv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-696
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0ojcvljv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1487687671227604 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1200469725161897 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.736893545780832 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0840568458336692 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇████▇█▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇███▇▇▇▇▇██▇▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ██████▇▇████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁█▁▁▁▁▇▅▆█▁▇▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.99
wandb: prop_NA 0.01
wandb:  reward 0.92352
wandb: 
wandb: Synced sunny-sweep-696: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0ojcvljv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164414-0ojcvljv/logs
2022-09-02 16:45:36,483 - wandb.wandb_agent - INFO - Cleaning up finished run: 0ojcvljv
2022-09-02 16:45:36,744 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:45:36,745 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01315611117513257
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:45:36,765 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01315611117513257 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:45:41,778 - wandb.wandb_agent - INFO - Running runs: ['e8gp6jag']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164541-e8gp6jag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-711
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e8gp6jag
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.123569352824401 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1257011248911564 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2846500458466337 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.476131360109813 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0136723776348235 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇█▇▇█████▇▇▇▇█▇▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇██▇▇▇▆▆▆▆▆▆▆▆▆▇▆▆▅▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇██████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇█▁▁▁█▁▁▁█▁▁▁▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glorious-sweep-711: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e8gp6jag
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164541-e8gp6jag/logs
2022-09-02 16:47:04,236 - wandb.wandb_agent - INFO - Cleaning up finished run: e8gp6jag
2022-09-02 16:47:04,499 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:47:04,508 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.044261609070041466
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:47:04,520 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.044261609070041466 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:47:09,534 - wandb.wandb_agent - INFO - Running runs: ['zbphnofb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164709-zbphnofb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-724
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zbphnofb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4952729393206106 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.629107044741545 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.302417512463497 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.475575723127675 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.886294372567976 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▆▇▇██▇█▇▇▇▇▇▇███▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▇▆▇▇▇▇▇█▇▇█▇███▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁█▁▁▇██▁█▁▁█▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced unique-sweep-724: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zbphnofb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164709-zbphnofb/logs
2022-09-02 16:48:42,528 - wandb.wandb_agent - INFO - Cleaning up finished run: zbphnofb
2022-09-02 16:48:42,815 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:48:42,819 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0006639551942957697
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:48:42,834 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0006639551942957697 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:48:47,848 - wandb.wandb_agent - INFO - Running runs: ['bs6dobli']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164847-bs6dobli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-742
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bs6dobli
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2652116113718836 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.088149132455052 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2657515933177064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.459889188441734 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1376566598541253 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇███▇▇▆▆▇██▇▇▆▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▇▆▇▆▇▇▇█▇▇▇▇▇▇█▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▅▁▁▁▅▁▅▁█▁▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.967
wandb:  prop_3 0.0
wandb: prop_NA 0.033
wandb:  reward 0.83716
wandb: 
wandb: Synced grateful-sweep-742: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bs6dobli
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164847-bs6dobli/logs
2022-09-02 16:50:25,775 - wandb.wandb_agent - INFO - Cleaning up finished run: bs6dobli
2022-09-02 16:50:26,028 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:50:26,028 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.02650622466617335
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:50:26,044 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.02650622466617335 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:50:31,059 - wandb.wandb_agent - INFO - Running runs: ['oy2mbxqt']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165031-oy2mbxqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-757
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/oy2mbxqt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.113342921767729 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.850090282060464 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.102017444565407 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.100215493488975 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.855910144701812 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇█▇▇█▇███▇▇██▇█▇██▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▅█▄▁▁▁▁▁▄▁▆▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced swift-sweep-757: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/oy2mbxqt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165031-oy2mbxqt/logs
2022-09-02 16:51:58,757 - wandb.wandb_agent - INFO - Cleaning up finished run: oy2mbxqt
2022-09-02 16:51:59,005 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:51:59,005 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.005701775657453636
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:51:59,018 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.005701775657453636 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:52:04,032 - wandb.wandb_agent - INFO - Running runs: ['1a9x4ues']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165203-1a9x4ues
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-771
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1a9x4ues
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.120739229833119 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.04126053435652 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.64368058399743 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4097439886947964 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.330290650339795 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇███▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▁▅▁▁▁▁█▁▄▁▇▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced copper-sweep-771: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1a9x4ues
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165203-1a9x4ues/logs
2022-09-02 16:53:36,839 - wandb.wandb_agent - INFO - Cleaning up finished run: 1a9x4ues
2022-09-02 16:53:37,226 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:53:37,227 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003527074919898196
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:53:37,236 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003527074919898196 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:53:42,251 - wandb.wandb_agent - INFO - Running runs: ['5zkfngpu']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165341-5zkfngpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-786
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5zkfngpu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.240607858554813 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1387901900160977 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.199434525375182 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3058761934303367 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▆▆▆▇▇▇▇█▇█▇▇▇▇▇▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▆▇▇▆▇▇▇▇▇▆▇▇█▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁▁▁▁▇▁▅▁█▁▁▁▅▅▁█▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dazzling-sweep-786: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5zkfngpu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165341-5zkfngpu/logs
2022-09-02 16:55:09,834 - wandb.wandb_agent - INFO - Cleaning up finished run: 5zkfngpu
2022-09-02 16:55:10,078 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:55:10,078 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0007786771869555603
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:55:10,094 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0007786771869555603 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:55:15,109 - wandb.wandb_agent - INFO - Running runs: ['cfgcp61f']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165514-cfgcp61f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-800
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cfgcp61f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3843687948114396 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4613220222171144 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.163807518337077 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.241857889243449 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.310429744924348 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇█▇▇▇▆▇▇▇▆▇▇▇▇▇▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▆██▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▄▆▇████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▁▁▄▁▁▄▁▁▁▁▁▁▁▁█▇▂████▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.046
wandb:  prop_3 0.929
wandb: prop_NA 0.025
wandb:  reward 0.92352
wandb: 
wandb: Synced still-sweep-800: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cfgcp61f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165514-cfgcp61f/logs
2022-09-02 16:56:42,753 - wandb.wandb_agent - INFO - Cleaning up finished run: cfgcp61f
2022-09-02 16:56:43,007 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:56:43,008 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0008348409008635618
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:56:43,034 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0008348409008635618 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:56:48,049 - wandb.wandb_agent - INFO - Running runs: ['u7mt2xx0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165648-u7mt2xx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-816
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u7mt2xx0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4160372863171897 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4362077561391056 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2401911798175576 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3652682039331205 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▆▆▆▇▇▇▇▆▆▆▇███▇▇█▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇███▇▇▇▇█▇▇▇▆▆▇▇▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▁█▁▁▁▇▁▁▁▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.992
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.008
wandb:  reward 1.0
wandb: 
wandb: Synced dry-sweep-816: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u7mt2xx0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165648-u7mt2xx0/logs
2022-09-02 16:58:26,198 - wandb.wandb_agent - INFO - Cleaning up finished run: u7mt2xx0
2022-09-02 16:58:26,466 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:58:26,466 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01972392607904615
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:58:26,503 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01972392607904615 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:58:31,520 - wandb.wandb_agent - INFO - Running runs: ['3cwnx085']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165832-3cwnx085
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-832
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3cwnx085
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.183481282869565 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.963246705945419 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3052281014790217 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3627104084362163 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▇████▇██▇█▇████▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▁▁▁▁▄▁▁▁▁█▄▇▆▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced jumping-sweep-832: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3cwnx085
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165832-3cwnx085/logs
2022-09-02 16:59:54,052 - wandb.wandb_agent - INFO - Cleaning up finished run: 3cwnx085
2022-09-02 16:59:54,316 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:59:54,317 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0033449912581334593
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:59:54,325 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0033449912581334593 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:59:59,336 - wandb.wandb_agent - INFO - Running runs: ['10utol4p']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165958-10utol4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-846
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/10utol4p
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2256254156093322 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.558388923367381 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.384523046913447 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484455461075831 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▆▆▆▆▆▆▆▆▆▇██▇▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▆▇▇▆▇▆▇▇▆▆▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇████████████▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▂▁▁▅▁▁█▁█▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced stellar-sweep-846: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/10utol4p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165958-10utol4p/logs
2022-09-02 17:01:37,677 - wandb.wandb_agent - INFO - Cleaning up finished run: 10utol4p
2022-09-02 17:01:37,965 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:01:37,965 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.007716250481453435
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:01:37,980 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.007716250481453435 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:01:42,992 - wandb.wandb_agent - INFO - Running runs: ['d1ye7fmt']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170143-d1ye7fmt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-862
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d1ye7fmt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2832128904088203 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.41140611342895 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆██▇▇▆▆▇▇▇▇▇▇██▇▇▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▄▁▁▁▁▁▁▅▁▁▅▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced zany-sweep-862: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d1ye7fmt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170143-d1ye7fmt/logs
2022-09-02 17:03:11,055 - wandb.wandb_agent - INFO - Cleaning up finished run: d1ye7fmt
2022-09-02 17:03:11,376 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:03:11,376 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.013525672607695834
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:03:11,391 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.013525672607695834 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:03:16,405 - wandb.wandb_agent - INFO - Running runs: ['fyr4z9oj']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170316-fyr4z9oj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-876
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fyr4z9oj
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1680175419211904 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.100410156358273 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▄▆██▇▇█▇▇█▇▇▇▇████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇██▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁█▁▁▁▂▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dashing-sweep-876: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fyr4z9oj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170316-fyr4z9oj/logs
2022-09-02 17:04:50,874 - wandb.wandb_agent - INFO - Cleaning up finished run: fyr4z9oj
2022-09-02 17:04:51,146 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:04:51,146 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.015620161537345996
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:04:51,163 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.015620161537345996 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:04:56,175 - wandb.wandb_agent - INFO - Running runs: ['vg1w6e4m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170456-vg1w6e4m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-891
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vg1w6e4m
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.026718263472721 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2636211868149583 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██▇▇▆▆▇▇▇▇▇▇▇▇▆▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▆▆▆▆▆▅▆▆▆▇▆▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ██▇█████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▄█▁▁▁▁▄▁▁▁▁▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced jumping-sweep-891: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vg1w6e4m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170456-vg1w6e4m/logs
2022-09-02 17:06:18,684 - wandb.wandb_agent - INFO - Cleaning up finished run: vg1w6e4m
2022-09-02 17:06:18,998 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:06:18,999 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0006025982063683111
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:06:19,013 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0006025982063683111 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:06:24,027 - wandb.wandb_agent - INFO - Running runs: ['8rz1sxop']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170623-8rz1sxop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-906
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8rz1sxop
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4366775087510772 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0721304746468188 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1353153551147286 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▆▆▇▇▆▆▆▆▆▆▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▆▆▆▆▆▅▆▆▆▆▆▆▆▅▅▅▅▅▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁█▁▁▅▁▁█▁▁▁▁▅▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.97
wandb: prop_NA 0.03
wandb:  reward 0.92352
wandb: 
wandb: Synced expert-sweep-906: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8rz1sxop
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170623-8rz1sxop/logs
2022-09-02 17:07:51,617 - wandb.wandb_agent - INFO - Cleaning up finished run: 8rz1sxop
2022-09-02 17:07:52,029 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:07:52,029 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005990350220838151
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:07:52,035 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005990350220838151 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:07:57,048 - wandb.wandb_agent - INFO - Running runs: ['qr3mb6av']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170756-qr3mb6av
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-921
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qr3mb6av
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4151741829924824 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.143912233161179 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.878199318546757 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2512470747602022 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅████▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▆▇▇█████████▇█▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇█▁▁▁▁█▁▁█▁█▁▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced sandy-sweep-921: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qr3mb6av
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170756-qr3mb6av/logs
2022-09-02 17:09:19,649 - wandb.wandb_agent - INFO - Cleaning up finished run: qr3mb6av
2022-09-02 17:09:19,936 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:09:19,936 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0015668659916441793
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:09:19,942 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0015668659916441793 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:09:24,981 - wandb.wandb_agent - INFO - Running runs: ['0auo1y5z']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170925-0auo1y5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-936
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0auo1y5z
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1053970242825555 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.316557114102835 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.084377414416812 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇████▇▇▇▇▇▇▇▇▇▆▆▆▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▇▇▇▇▇▇▇▇▇▇▆▆▇▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▁▇▁▁▁▁▁▁▁▁▁█▅▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.96
wandb: prop_NA 0.04
wandb:  reward 0.92352
wandb: 
wandb: Synced splendid-sweep-936: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0auo1y5z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170925-0auo1y5z/logs
2022-09-02 17:10:48,525 - wandb.wandb_agent - INFO - Cleaning up finished run: 0auo1y5z
2022-09-02 17:10:48,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:10:48,879 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003983229132310874
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:10:48,889 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003983229132310874 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:10:53,903 - wandb.wandb_agent - INFO - Running runs: ['c9wmi1od']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171053-c9wmi1od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-950
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c9wmi1od
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3789984890729183 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.795073149019904 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.253927260503521 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.469741634872246 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2987708479646867 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.247282306522654 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▆▆▆▆▆▇▇▇▇▇▆▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▄▅▆▆▆▆▆▆▇▇▇████▇▆▇▇▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▅▁▁▁▁▁█▁█▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced magic-sweep-950: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c9wmi1od
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171053-c9wmi1od/logs
2022-09-02 17:12:21,579 - wandb.wandb_agent - INFO - Cleaning up finished run: c9wmi1od
2022-09-02 17:12:21,858 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:12:21,858 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03428774062064095
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:12:21,866 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03428774062064095 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:12:26,879 - wandb.wandb_agent - INFO - Running runs: ['8f9ca2wh']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171226-8f9ca2wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-965
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8f9ca2wh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0476312826176923 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.416834343018895 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.912436920006147 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1389746957933324 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0141353868539746 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.883298562843887 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▇▇████▇▇▇██▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▇▇███▇▇██▇█▇▇▇▇▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▁▁▇▁▁▁▁▂▄▁█▅▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dazzling-sweep-965: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8f9ca2wh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171226-8f9ca2wh/logs
2022-09-02 17:13:49,361 - wandb.wandb_agent - INFO - Cleaning up finished run: 8f9ca2wh
2022-09-02 17:13:49,691 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:13:49,692 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0253284932772187
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:13:49,697 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0253284932772187 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:13:54,712 - wandb.wandb_agent - INFO - Running runs: ['kp78ocbl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171354-kp78ocbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-979
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kp78ocbl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2910591823349638 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.452283181287126 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.403598045683648 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.458127253719889 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.729536089044139 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2932166876722455 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2211835246358795 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▃▄▅▆▆▆▆▆▆▆▇▇▇▇█▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▅▁▁▁▁▅▆▁▄█▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced daily-sweep-979: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kp78ocbl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171354-kp78ocbl/logs
2022-09-02 17:15:22,341 - wandb.wandb_agent - INFO - Cleaning up finished run: kp78ocbl
2022-09-02 17:15:22,656 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:15:22,656 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01574520026285065
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:15:22,664 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01574520026285065 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:15:27,678 - wandb.wandb_agent - INFO - Running runs: ['5m5jakgz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171527-5m5jakgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-992
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5m5jakgz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4936773713644302 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.068332980424041 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.363226739831479 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.220084789540597 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4712778945717466 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▆▇▇▇██▇▇▆▆▆▇▆▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇██▇▇▇▆▇▇▇▇▆▅▅▆▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇███████▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁█▁▁▄▇▁▁▁▁█▁▇█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced worldly-sweep-992: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5m5jakgz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171527-5m5jakgz/logs
2022-09-02 17:16:50,251 - wandb.wandb_agent - INFO - Cleaning up finished run: 5m5jakgz
2022-09-02 17:16:50,538 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:16:50,539 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004445130032012238
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:16:50,544 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004445130032012238 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:16:55,566 - wandb.wandb_agent - INFO - Running runs: ['gxewma4o']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171654-gxewma4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-1003
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gxewma4o
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4802123115283363 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.172038700799501 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1449207171334868 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.670952027058972 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3236747043063257 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.827768659888715 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇█▇▇▆▆▆▆▆▇▇█▇▇▇▇▇█▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▄▁▁█▇▁▁▁▅▁▇▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glorious-sweep-1003: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gxewma4o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171654-gxewma4o/logs
2022-09-02 17:18:23,167 - wandb.wandb_agent - INFO - Cleaning up finished run: gxewma4o
2022-09-02 17:18:23,463 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:18:23,463 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0017702734932448303
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:18:23,468 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0017702734932448303 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:18:28,481 - wandb.wandb_agent - INFO - Running runs: ['mqjom371']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171828-mqjom371
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-1017
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mqjom371
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4975005161630466 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.382096880505257 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.189648674899358 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.098652322586645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.272706279654464 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▇▇▇█████▇▇▇▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▇▇▇▇▆▆▆▆▆▆▆▆▇▆▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▁▁▄▁▁▅▁█▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced solar-sweep-1017: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mqjom371
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171828-mqjom371/logs
2022-09-02 17:20:01,517 - wandb.wandb_agent - INFO - Cleaning up finished run: mqjom371
2022-09-02 17:20:01,822 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:20:01,822 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0030633762113740325
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:20:01,828 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0030633762113740325 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:20:06,840 - wandb.wandb_agent - INFO - Running runs: ['prhv9zbl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172005-prhv9zbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-1034
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/prhv9zbl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.37128548288334 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3584523634042487 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.580627348786396 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4889038426299472 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4293167699998635 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▅▅▅▅▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▇▇███▇▇▇▇▇▆▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▁▁▁█▁▁▆▅▁██▇▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.962
wandb: prop_NA 0.038
wandb:  reward 0.92352
wandb: 
wandb: Synced avid-sweep-1034: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/prhv9zbl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172005-prhv9zbl/logs
2022-09-02 17:21:35,434 - wandb.wandb_agent - INFO - Cleaning up finished run: prhv9zbl
2022-09-02 17:21:35,714 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:21:35,714 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00638136921674342
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:21:35,720 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00638136921674342 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:21:40,733 - wandb.wandb_agent - INFO - Running runs: ['e0a5vnda']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172140-e0a5vnda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-1046
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e0a5vnda
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1125524999968004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.525847803979529 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4526408587969253 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2990578295252373 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.704776788190536 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇█▇█▇▇▆▆▇███▇▇▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████▇▇▇██████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁██▁▃▁▁▁▇▁▁▁▁▁▆▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced earthy-sweep-1046: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e0a5vnda
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172140-e0a5vnda/logs
2022-09-02 17:23:03,154 - wandb.wandb_agent - INFO - Cleaning up finished run: e0a5vnda
2022-09-02 17:23:03,444 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:23:03,444 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00016629012575922298
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:23:03,451 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00016629012575922298 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:23:08,464 - wandb.wandb_agent - INFO - Running runs: ['8c0kti5f']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172309-8c0kti5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-1060
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8c0kti5f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.292144365250383 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.614134906662101 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.330726517250425 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4799168183022733 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.849136630870762 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▆▇▆▆▆▆▇▇▇▆▆▆▆▆▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇██▇▆▆▇▇█▇▇▇████▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁█▁▁▁▅▄█▁▁▁▅▁▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced proud-sweep-1060: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8c0kti5f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172309-8c0kti5f/logs
2022-09-02 17:24:36,089 - wandb.wandb_agent - INFO - Cleaning up finished run: 8c0kti5f
2022-09-02 17:24:36,414 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:24:36,415 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003912631524896397
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:24:36,420 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003912631524896397 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:24:41,449 - wandb.wandb_agent - INFO - Running runs: ['6xitoa6l']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172440-6xitoa6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-1075
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6xitoa6l
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.259035609118156 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.048286174022544 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.095850436508236 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇█▇██▇▇▇▇▆▇▇▇█▇███▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇██▇▇▇▇▇▇▇▇▇███▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁█▄▁▁▄▁▁▅██▁▇▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.018
wandb:  prop_2 0.967
wandb:  prop_3 0.0
wandb: prop_NA 0.015
wandb:  reward 0.83716
wandb: 
wandb: Synced exalted-sweep-1075: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6xitoa6l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172440-6xitoa6l/logs
2022-09-02 17:26:09,251 - wandb.wandb_agent - INFO - Cleaning up finished run: 6xitoa6l
2022-09-02 17:26:09,557 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:26:09,558 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00017414476144732378
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:26:09,563 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00017414476144732378 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:26:14,577 - wandb.wandb_agent - INFO - Running runs: ['ig73tmwh']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172614-ig73tmwh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-1090
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ig73tmwh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.20991514610507 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1382997341701024 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.06395581702839 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.362959801508856 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇██▇▇▇▆▇▆▆▅▆▅▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆▆▆▇▇▇▇▇▇▇▆▇▆▆▆▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇█▇▇█▇██▇██████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁▁██▁▇▁▄▁█▁▁▆▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.006
wandb:  prop_2 0.984
wandb:  prop_3 0.0
wandb: prop_NA 0.01
wandb:  reward 0.83716
wandb: 
wandb: Synced pretty-sweep-1090: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ig73tmwh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172614-ig73tmwh/logs
2022-09-02 17:27:47,318 - wandb.wandb_agent - INFO - Cleaning up finished run: ig73tmwh
2022-09-02 17:27:47,610 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:27:47,611 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.027380355331407095
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:27:47,616 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.027380355331407095 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:27:52,628 - wandb.wandb_agent - INFO - Running runs: ['1s6ftc7j']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172752-1s6ftc7j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-1105
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1s6ftc7j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3150939460120226 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4237471706477343 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.434623781074569 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.061381666467581 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▆▆▅▆▅▅▅▅▅▆▆▅▅▅▅▅▅▅▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▅▆▆▇████▇▇▇▇▆▆▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▇▁▁▁▁▁▁▂▄▁▁▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced silver-sweep-1105: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1s6ftc7j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172752-1s6ftc7j/logs
2022-09-02 17:29:16,050 - wandb.wandb_agent - INFO - Cleaning up finished run: 1s6ftc7j
2022-09-02 17:29:16,324 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:29:16,325 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.01797786333489001
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:29:16,330 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.01797786333489001 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:29:21,343 - wandb.wandb_agent - INFO - Running runs: ['fzwz1zjp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172921-fzwz1zjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-1119
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fzwz1zjp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.180067686508406 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0865216291110382 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▅▅▅▅▆▅▅▅▅▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▆▆▆▆▇▇▇▇▆▇▇███▇▇▇▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▁▁█▁█▁█▁█▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glamorous-sweep-1119: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fzwz1zjp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172921-fzwz1zjp/logs
2022-09-02 17:30:54,183 - wandb.wandb_agent - INFO - Cleaning up finished run: fzwz1zjp
2022-09-02 17:30:54,675 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:30:54,675 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.031799930031495977
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:30:54,681 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.031799930031495977 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:30:59,701 - wandb.wandb_agent - INFO - Running runs: ['1sw0dk0a']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173059-1sw0dk0a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-1134
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1sw0dk0a
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.076639672164666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.366276008276945 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.018158035978327 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.203873148383261 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▆▆▆▇▇▇▇▆▇▆▆▇▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▆█▆▇▇▇▇▇▇▇████▇▇▇███▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇██████████▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁█▁█▁▁▁██▁▁█▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced scarlet-sweep-1134: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1sw0dk0a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173059-1sw0dk0a/logs
2022-09-02 17:32:22,296 - wandb.wandb_agent - INFO - Cleaning up finished run: 1sw0dk0a
2022-09-02 17:32:22,571 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:32:22,571 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00010364808793129816
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:32:22,577 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00010364808793129816 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:32:27,590 - wandb.wandb_agent - INFO - Running runs: ['en8ad296']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173227-en8ad296
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-1149
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/en8ad296
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4245387045276128 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.212346139519882 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.304196827520564 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3383084605353806 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1013473990823512 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.572978742402566 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▆▆▇▇▇█▇▇▇▆▆▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▇▇▇▇▆▆▆▇▇▇▇▇▇██▇▇▆▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ██████████████████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▁▁▁▁█▆▁█▁▁▁▁▇▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced cool-sweep-1149: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/en8ad296
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173227-en8ad296/logs
2022-09-02 17:33:55,204 - wandb.wandb_agent - INFO - Cleaning up finished run: en8ad296
2022-09-02 17:33:55,863 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:33:55,864 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0007151480092350594
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:33:55,879 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0007151480092350594 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:34:00,894 - wandb.wandb_agent - INFO - Running runs: ['z4r7h9us']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173403-z4r7h9us
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-1163
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z4r7h9us
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2493748853066293 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3188126541192253 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.216478699893871 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▅▆▇████▇█▇▇▇▇▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▆▆▇▇▇███▇█▇▇█▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁█▁▁▅▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced lucky-sweep-1163: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z4r7h9us
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173403-z4r7h9us/logs
2022-09-02 17:35:38,818 - wandb.wandb_agent - INFO - Cleaning up finished run: z4r7h9us
2022-09-02 17:35:39,138 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:35:39,138 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.023044659723773033
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:35:39,156 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.023044659723773033 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:35:44,171 - wandb.wandb_agent - INFO - Running runs: ['3pymspe5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173543-3pymspe5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-1180
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3pymspe5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2708420779140086 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1902798538585486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.446416304481274 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.132251856277069 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.183407709584735 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█████▇▇▇▇▇█▇███▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb:  prop_3 █▆█▇▇▆▅▆▆▆▆▆▆▇▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇█████████████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▇▁▁▄▇▇▁▁▁▁▁▆▁▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced lively-sweep-1180: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3pymspe5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173543-3pymspe5/logs
2022-09-02 17:37:09,212 - wandb.wandb_agent - INFO - Cleaning up finished run: 3pymspe5
2022-09-02 17:37:12,660 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:37:12,660 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004269762994006294
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:37:12,665 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004269762994006294 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:37:17,678 - wandb.wandb_agent - INFO - Running runs: ['u9tufeqr']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173717-u9tufeqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-1194
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u9tufeqr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0413325830690026 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.156745634112911 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.859402806983476 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▇▇▆▇▆▇▇███▇▇▇▇▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁█▁▁▁▅██▇█▁█▁▅▇▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced expert-sweep-1194: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u9tufeqr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173717-u9tufeqr/logs
2022-09-02 17:38:50,388 - wandb.wandb_agent - INFO - Cleaning up finished run: u9tufeqr
2022-09-02 17:38:50,698 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:38:50,698 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.000520624937277522
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:38:50,704 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.000520624937277522 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:38:55,718 - wandb.wandb_agent - INFO - Running runs: ['jrrm3onc']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173856-jrrm3onc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-1211
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jrrm3onc
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.236225244868257 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0958360935950004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3710247970710743 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2816778579789805 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▆▅▅▅▆▆▆▆▆▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▆▆▆▆▆▆▆▆▅▆▅▅▅▆▆▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▅▁▁▁▇▄▁█▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced rosy-sweep-1211: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jrrm3onc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173856-jrrm3onc/logs
2022-09-02 17:40:23,742 - wandb.wandb_agent - INFO - Cleaning up finished run: jrrm3onc
2022-09-02 17:40:24,038 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:40:24,038 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0017546609918967818
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:40:24,043 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0017546609918967818 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:40:29,057 - wandb.wandb_agent - INFO - Running runs: ['jk7kuig9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174029-jk7kuig9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-1226
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jk7kuig9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3675250300881108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.016320016078699 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.890426139297172 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.103953768109516 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████████▇▅▄▂▁
wandb:  prop_2 ▅▆▇▆▇▇▇█▇▇▇▇██▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇█
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂
wandb:  reward ▁▁▁▁▇▁▁▅▁█▁▁▅▆█▁▁█▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▃▁▇█
wandb: 
wandb: Run summary:
wandb:  prop_1 0.124
wandb:  prop_2 0.0
wandb:  prop_3 0.758
wandb: prop_NA 0.118
wandb:  reward 0.92352
wandb: 
wandb: Synced icy-sweep-1226: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jk7kuig9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174029-jk7kuig9/logs
2022-09-02 17:41:51,621 - wandb.wandb_agent - INFO - Cleaning up finished run: jk7kuig9
2022-09-02 17:41:51,920 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:41:51,920 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0002785324154190678
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:41:51,929 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0002785324154190678 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:41:56,940 - wandb.wandb_agent - INFO - Running runs: ['e19k657l']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174156-e19k657l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-1239
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e19k657l
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1518958716944154 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.011746880883802 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.616420461289197 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.005648210010662 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9922360734120925 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2964166428283797 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.642889794788352 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▇▇▆▆▆▆▆▆▆▆▅▆▆▇▇▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▆
wandb:  prop_2 ▅▇▇██▇█▇▇▇▇█▇▇▇▆▇▇█▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████████████▇
wandb: prop_NA █▇▇▇▇███████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁█▁▁█▁▁▅▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇█
wandb: 
wandb: Run summary:
wandb:  prop_1 0.091
wandb:  prop_2 0.0
wandb:  prop_3 0.892
wandb: prop_NA 0.017
wandb:  reward 0.92352
wandb: 
wandb: Synced volcanic-sweep-1239: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e19k657l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174156-e19k657l/logs
2022-09-02 17:43:19,439 - wandb.wandb_agent - INFO - Cleaning up finished run: e19k657l
2022-09-02 17:43:19,698 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:43:19,698 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00017598753396583109
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:43:19,720 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00017598753396583109 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:43:24,733 - wandb.wandb_agent - INFO - Running runs: ['katpfnzu']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174327-katpfnzu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-1252
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/katpfnzu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4981673117886127 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.14255285086807 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4164301839449145 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4848537207111914 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.564343041217787 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇███▇▇▇▇██▇█▇██▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▇▇▇▇██▇▇▇▆▇▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇█████▇▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁██▁▁▇█▁▁▁▁▁█▁▁▁█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced swift-sweep-1252: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/katpfnzu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174327-katpfnzu/logs
2022-09-02 17:45:02,675 - wandb.wandb_agent - INFO - Cleaning up finished run: katpfnzu
2022-09-02 17:45:02,980 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:45:02,980 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004073875853518892
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:45:02,986 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004073875853518892 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:45:07,999 - wandb.wandb_agent - INFO - Running runs: ['60q2q48v']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174510-60q2q48v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-1270
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/60q2q48v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.189734282532018 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0107374855679807 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.897590227575485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.442454799427527 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4488526967268 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▇▅▆▇▇█████▇▇▇██▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▇▇▆▇▆▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁██▁▁▁█▁▁█▁▇▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced still-sweep-1270: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/60q2q48v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174510-60q2q48v/logs
2022-09-02 17:46:40,772 - wandb.wandb_agent - INFO - Cleaning up finished run: 60q2q48v
2022-09-02 17:46:42,281 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:46:42,282 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001934541551825855
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:46:42,290 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001934541551825855 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:46:47,307 - wandb.wandb_agent - INFO - Running runs: ['wuh6hbhu']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174647-wuh6hbhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-1288
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wuh6hbhu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.00596836694345 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.00979477100002 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.46835520952405 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1704144655705546 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.656609850116075 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.347053671129461 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▆█▇▇▇▇▇▇▇▇███▇▇▇▇▆▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▆▇▇▇▇▇▇███▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁█▁▁▅▁█▁▁▁▁▅▇▆▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sandy-sweep-1288: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wuh6hbhu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174647-wuh6hbhu/logs
2022-09-02 17:48:25,819 - wandb.wandb_agent - INFO - Cleaning up finished run: wuh6hbhu
2022-09-02 17:48:26,149 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:48:26,149 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.021859892666813197
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:48:26,153 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.021859892666813197 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:48:31,163 - wandb.wandb_agent - INFO - Running runs: ['e2glyece']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174832-e2glyece
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-1308
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e2glyece
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.145958375215173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.49168104075783 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.465359676978229 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.98576229901893 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0680509457201195 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▇▇▇▇▇▇▇▇▇██▇▆▆▆▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇██████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▁▁▄███▁▅▁▁█▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced iconic-sweep-1308: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/e2glyece
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174832-e2glyece/logs
2022-09-02 17:49:58,778 - wandb.wandb_agent - INFO - Cleaning up finished run: e2glyece
2022-09-02 17:49:59,061 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:49:59,061 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00018797527320368505
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:49:59,067 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00018797527320368505 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:50:04,081 - wandb.wandb_agent - INFO - Running runs: ['7wma1b57']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175004-7wma1b57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-1323
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7wma1b57
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4734580307311407 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3271632315041364 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.250551110614052 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.888703885819253 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇████▇▇▇▇▇▇████▇▆▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▅▆▇▇▇▇▇██▇▇▇▇▇▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ███▇█▇▇▇▇▇██▇█▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▄▁█▁▁▁▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced gallant-sweep-1323: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7wma1b57
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175004-7wma1b57/logs
2022-09-02 17:51:36,947 - wandb.wandb_agent - INFO - Cleaning up finished run: 7wma1b57
2022-09-02 17:51:37,252 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:51:37,252 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03933011729868973
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:51:37,259 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03933011729868973 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:51:42,270 - wandb.wandb_agent - INFO - Running runs: ['drq48tfp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175142-drq48tfp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-1338
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/drq48tfp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4724657145619973 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.150295600547033 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1060488949966554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.691715729445944 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▅▆▆▇▇▇▇▇▇▇█▇▇▆▆▆▆▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇▇▇▇▇▇▆▇▇██▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▅▁▇▁▁▆▁▁▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced giddy-sweep-1338: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/drq48tfp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175142-drq48tfp/logs
2022-09-02 17:53:15,000 - wandb.wandb_agent - INFO - Cleaning up finished run: drq48tfp
2022-09-02 17:53:15,368 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:53:15,368 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004897751352979558
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:53:15,388 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004897751352979558 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:53:20,403 - wandb.wandb_agent - INFO - Running runs: ['27yrzdby']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175320-27yrzdby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-1352
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/27yrzdby
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0647621986463127 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.269846685826878 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇███▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆▇▇▇█▇▇██▇█▇███████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced twilight-sweep-1352: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/27yrzdby
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175320-27yrzdby/logs
2022-09-02 17:54:53,218 - wandb.wandb_agent - INFO - Cleaning up finished run: 27yrzdby
2022-09-02 17:54:53,615 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:54:53,616 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00018445934598426857
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:54:53,621 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00018445934598426857 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:54:58,634 - wandb.wandb_agent - INFO - Running runs: ['w0isis4j']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175458-w0isis4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-1368
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w0isis4j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0838946237721716 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.047806088098149 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.256151856041398 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇██▇██▇▇▇▇▇▇▆▆▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▄▇▇█▇▇▇▆▆▇▇▇████▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅█▇▃▁▆▁▁▁▆▁▄▁█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced morning-sweep-1368: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w0isis4j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175458-w0isis4j/logs
2022-09-02 17:56:21,474 - wandb.wandb_agent - INFO - Cleaning up finished run: w0isis4j
2022-09-02 17:56:21,744 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:56:21,745 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0007072653788951046
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:56:21,754 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0007072653788951046 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:56:26,767 - wandb.wandb_agent - INFO - Running runs: ['2z5fjh7r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175627-2z5fjh7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-1382
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2z5fjh7r
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.408521897903251 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2731991150566593 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9959263099112 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇█▇▇█▇████▇▆▆▆▇▇█▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇███▇█▇▇▆▆▆▆▇▆▇▆▆▆▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇█████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁█▇▁▁▅▄█▁▇█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.982
wandb:  prop_3 0.0
wandb: prop_NA 0.018
wandb:  reward 0.83716
wandb: 
wandb: Synced laced-sweep-1382: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2z5fjh7r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175627-2z5fjh7r/logs
2022-09-02 17:57:49,247 - wandb.wandb_agent - INFO - Cleaning up finished run: 2z5fjh7r
2022-09-02 17:57:49,770 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:57:49,771 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011511770364172722
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:57:49,779 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011511770364172722 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:57:54,791 - wandb.wandb_agent - INFO - Running runs: ['pgvwjklj']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175755-pgvwjklj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-1397
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pgvwjklj
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1648676488123297 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.248974898266131 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.335498844532989 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇█▇██▇▇▇▇▇▇▇███▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇██▇███▇▇▇▆▇▇▇▇█▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇█▇▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▁▁█▁▂▁▁▁▁▁▁▇██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced feasible-sweep-1397: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pgvwjklj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175755-pgvwjklj/logs
2022-09-02 17:59:22,498 - wandb.wandb_agent - INFO - Cleaning up finished run: pgvwjklj
2022-09-02 17:59:22,792 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:59:22,792 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001172941801018742
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:59:22,798 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001172941801018742 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:59:27,812 - wandb.wandb_agent - INFO - Running runs: ['efj5mg90']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175928-efj5mg90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-1411
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/efj5mg90
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.263069855078523 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▃▄▅▆▆▇███████
wandb:  prop_2 ███▇▇▇▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▇██▇▆▅▄▃▂▂▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▇▁▁▅▁▁▁▁▁▁█▄▁▁▁▁▅▄▄▆█▅▇█▅█▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced olive-sweep-1411: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/efj5mg90
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175928-efj5mg90/logs
2022-09-02 18:00:55,520 - wandb.wandb_agent - INFO - Cleaning up finished run: efj5mg90
2022-09-02 18:00:55,827 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:00:55,827 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0026988345290584973
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:00:55,832 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0026988345290584973 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:01:00,848 - wandb.wandb_agent - INFO - Running runs: ['u6we611k']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180101-u6we611k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-1426
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u6we611k
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.187492723395247 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.535736815261196 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.275188376532099 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▇▇▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▆▆▆▆▆▇▇▇▇▆▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced rich-sweep-1426: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u6we611k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180101-u6we611k/logs
2022-09-02 18:02:33,595 - wandb.wandb_agent - INFO - Cleaning up finished run: u6we611k
2022-09-02 18:02:33,873 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:02:33,873 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0009524518642825188
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:02:33,879 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0009524518642825188 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:02:38,895 - wandb.wandb_agent - INFO - Running runs: ['qhg7reat']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180238-qhg7reat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-1440
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qhg7reat
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.025164797215822 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.356024516459666 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.457639459405993 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▆▆▆▆▇███▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▇▇▆▇█▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▇█▇▃▁▆█▂█▁▁█▁█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.972
wandb:  prop_3 0.0
wandb: prop_NA 0.028
wandb:  reward 0.83716
wandb: 
wandb: Synced pleasant-sweep-1440: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qhg7reat
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180238-qhg7reat/logs
2022-09-02 18:04:06,528 - wandb.wandb_agent - INFO - Cleaning up finished run: qhg7reat
2022-09-02 18:04:06,838 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:04:06,838 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0012663060662184936
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:04:06,843 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0012663060662184936 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:04:11,867 - wandb.wandb_agent - INFO - Running runs: ['38xqsawx']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180411-38xqsawx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-1455
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/38xqsawx
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.44927984168123 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1375801287583367 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.052291115064154 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅▆██▆▅▄▄▄▄▅▅▅▅▅▅▅▅▅
wandb:  prop_2 ▄▅▆▆▆▆▇▇▆▆▆▆▇▇▇▆▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▃▅▇██████▇▇▇▇▇▇▇
wandb: prop_NA ██████▇███████▇████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▅▁▁▁▁▆▁▁▄▁▁▁▁▁▁▁█▃▅▆█▅██████▇▆██▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.514
wandb:  prop_2 0.0
wandb:  prop_3 0.483
wandb: prop_NA 0.003
wandb:  reward 1.0
wandb: 
wandb: Synced sandy-sweep-1455: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/38xqsawx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180411-38xqsawx/logs
2022-09-02 18:05:35,472 - wandb.wandb_agent - INFO - Cleaning up finished run: 38xqsawx
2022-09-02 18:05:35,767 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:05:35,768 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0007221905398687926
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:05:35,787 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0007221905398687926 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:05:40,810 - wandb.wandb_agent - INFO - Running runs: ['5oeouk4s']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180541-5oeouk4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-1468
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5oeouk4s
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4235214659824638 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4885578776888493 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.028447686338862 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▇▇▇▇▇▆▆▇▇██▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇███▇▆▇▇▇▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁█▂▇▁▁▁█▁▁▁▅█▁▁▃██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.998
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.002
wandb:  reward 1.0
wandb: 
wandb: Synced ethereal-sweep-1468: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5oeouk4s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180541-5oeouk4s/logs
2022-09-02 18:07:08,809 - wandb.wandb_agent - INFO - Cleaning up finished run: 5oeouk4s
2022-09-02 18:07:09,120 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:07:09,120 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0010324911720425891
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:07:09,132 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0010324911720425891 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:07:14,146 - wandb.wandb_agent - INFO - Running runs: ['msgvn4w0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180714-msgvn4w0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-1483
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/msgvn4w0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2362756096965946 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3578840867732347 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▆▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▅▄▁▃█▁▁▂▄▁▁▅▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced rosy-sweep-1483: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/msgvn4w0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180714-msgvn4w0/logs
2022-09-02 18:08:52,183 - wandb.wandb_agent - INFO - Cleaning up finished run: msgvn4w0
2022-09-02 18:08:52,614 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:08:52,614 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001745993841848135
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:08:52,620 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001745993841848135 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:08:57,636 - wandb.wandb_agent - INFO - Running runs: ['6bnw2vt3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180857-6bnw2vt3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-1499
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6bnw2vt3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.124142778753381 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.383043766119663 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.173592026580664 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.305873914153785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.022027224882338 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.445030388155142 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇██▇▇▇▇▇▇▇▇█▇▇▇▆▆▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▇▇██▇▇▆▆▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁█▅▅█▇▁▅▁▁█▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced royal-sweep-1499: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6bnw2vt3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180857-6bnw2vt3/logs
2022-09-02 18:10:25,445 - wandb.wandb_agent - INFO - Cleaning up finished run: 6bnw2vt3
2022-09-02 18:10:30,596 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:10:30,596 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01180100630044881
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:10:30,602 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01180100630044881 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:10:35,618 - wandb.wandb_agent - INFO - Running runs: ['cwqrfpth']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181035-cwqrfpth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-1514
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cwqrfpth
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4616187133002185 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.024936583388436 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.280098717366383 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.226598017933366 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.527602187334264 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇▇▇▇▇▇████▇▇████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▆▆▆▆▆▅▆▆▆▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▇█▁██▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced glamorous-sweep-1514: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cwqrfpth
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181035-cwqrfpth/logs
2022-09-02 18:12:03,312 - wandb.wandb_agent - INFO - Cleaning up finished run: cwqrfpth
2022-09-02 18:12:03,619 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:12:03,619 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00013301918298075016
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:12:03,625 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00013301918298075016 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:12:08,640 - wandb.wandb_agent - INFO - Running runs: ['93jmrsad']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181208-93jmrsad
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-1531
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/93jmrsad
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0570881473262554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.322690629813938 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3958942687438287 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.201976917824107 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.668917269740938 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▆▆▅▆▇▇████▇▇▇▆▆▆▆▆▆▆▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▇▆▆▆▆▆▆▇▇▇▆▆▇▇▇▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇██▇▇█████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁█▁▁▁█▁▁▁▁▁▁▁▇▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced cool-sweep-1531: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/93jmrsad
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181208-93jmrsad/logs
2022-09-02 18:13:41,533 - wandb.wandb_agent - INFO - Cleaning up finished run: 93jmrsad
2022-09-02 18:13:41,848 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:13:41,848 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001984199323029041
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:13:41,851 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001984199323029041 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:13:46,865 - wandb.wandb_agent - INFO - Running runs: ['90o2qws4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181346-90o2qws4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-1552
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/90o2qws4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0034491144356514 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.489295682002821 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.379348414050885 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.487730819414765 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.804855688505567 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3095995025519853 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇██▇▇▇▇▇▇████▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▇▆▆▆▆▆▆▆▆▆▆▅▆▅▅▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁█▁▇▁▁█▁▅▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced rare-sweep-1552: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/90o2qws4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181346-90o2qws4/logs
2022-09-02 18:15:14,558 - wandb.wandb_agent - INFO - Cleaning up finished run: 90o2qws4
2022-09-02 18:15:14,870 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:15:14,870 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0025670258614380603
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:15:14,877 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0025670258614380603 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:15:19,892 - wandb.wandb_agent - INFO - Running runs: ['dbdq5w2n']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181518-dbdq5w2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-1566
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dbdq5w2n
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.334619639540053 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.509328227454744 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4439326835024375 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2343583151400406 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1562584189254608 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.137167043252528 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▇▇▇▇███▇▇▆▆▆▇▇▇██▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▆▆▅▆▆▆▇▆▆▆▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████▇▇██████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fallen-sweep-1566: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dbdq5w2n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181518-dbdq5w2n/logs
2022-09-02 18:16:57,997 - wandb.wandb_agent - INFO - Cleaning up finished run: dbdq5w2n
2022-09-02 18:16:58,289 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:16:58,289 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.04830728720818273
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:16:58,370 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.04830728720818273 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:17:03,388 - wandb.wandb_agent - INFO - Running runs: ['jr7xp6se']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181704-jr7xp6se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-1581
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jr7xp6se
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4212213469827084 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.11563604701282 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.101283863637266 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.542918811738594 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇█▇█▇▇▇▇▇██▇▇▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▆▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄▄█▅▁▁▁▄▁▁▁▇▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced treasured-sweep-1581: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jr7xp6se
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181704-jr7xp6se/logs
2022-09-02 18:18:36,562 - wandb.wandb_agent - INFO - Cleaning up finished run: jr7xp6se
2022-09-02 18:18:37,002 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:18:37,002 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00018013917387632518
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:18:37,008 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00018013917387632518 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:18:42,024 - wandb.wandb_agent - INFO - Running runs: ['4vif3qbr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181842-4vif3qbr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-1596
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4vif3qbr
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4783549921864125 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3245266181320554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.066958862516841 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.278495283927268 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▇▇▆▆▆▇▇▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▇▇▆▇▇▇▇▇▇▇███▇▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅█▇█▁▁▁▁▁▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced misunderstood-sweep-1596: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4vif3qbr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181842-4vif3qbr/logs
2022-09-02 18:20:25,174 - wandb.wandb_agent - INFO - Cleaning up finished run: 4vif3qbr
2022-09-02 18:20:25,448 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:20:25,448 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004168383882484312
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:20:25,456 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004168383882484312 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:20:30,471 - wandb.wandb_agent - INFO - Running runs: ['zr6xqmhz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182030-zr6xqmhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-1613
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zr6xqmhz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2088621297485633 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.697282078317954 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3383376254088146 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇▆▆▇▇████▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▆▆▇▇▇█▇████▇▇▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁██▁▁▁▆▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced peach-sweep-1613: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zr6xqmhz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182030-zr6xqmhz/logs
2022-09-02 18:21:58,133 - wandb.wandb_agent - INFO - Cleaning up finished run: zr6xqmhz
2022-09-02 18:21:58,426 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:21:58,427 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00035108336714887643
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:21:58,432 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00035108336714887643 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:22:03,446 - wandb.wandb_agent - INFO - Running runs: ['c3upvz7f']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182203-c3upvz7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-1628
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c3upvz7f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3431321858264402 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.481039566258023 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1191279184396046 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.212064988707678 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0157883307115325 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▄▆▆▇▇▇█▇▇▇▇▇▇▇▇████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅▆▁█▅▁▁▅▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced driven-sweep-1628: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c3upvz7f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182203-c3upvz7f/logs
2022-09-02 18:23:25,947 - wandb.wandb_agent - INFO - Cleaning up finished run: c3upvz7f
2022-09-02 18:23:26,308 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:23:26,308 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0011637102221268266
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:23:26,403 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0011637102221268266 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:23:31,415 - wandb.wandb_agent - INFO - Running runs: ['xzd6la62']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182332-xzd6la62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-1642
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xzd6la62
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.286114731355518 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.017476985516557 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2580720276698094 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▆▆▆▆▅▅▅▆▆▆▆▆▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄█▁█▁▁█▆▁█▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced blooming-sweep-1642: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xzd6la62
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182332-xzd6la62/logs
2022-09-02 18:24:59,791 - wandb.wandb_agent - INFO - Cleaning up finished run: xzd6la62
2022-09-02 18:25:00,077 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:25:00,077 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.015559398022670066
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:25:00,084 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.015559398022670066 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:25:05,100 - wandb.wandb_agent - INFO - Running runs: ['rfl2sty9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182504-rfl2sty9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-1656
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rfl2sty9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3583857224048557 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2856049304074855 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2596692836120535 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.513228907917346 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇▇▇▇▆▆▆▆▆▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ██▇██▇▇▆▆▇▇████▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇▇███▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▁▁▁██▁▁▁▁▁▁▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced true-sweep-1656: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rfl2sty9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182504-rfl2sty9/logs
2022-09-02 18:26:37,975 - wandb.wandb_agent - INFO - Cleaning up finished run: rfl2sty9
2022-09-02 18:26:38,274 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:26:38,274 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004632167873080523
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:26:38,281 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004632167873080523 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:26:43,295 - wandb.wandb_agent - INFO - Running runs: ['q0s1la3a']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182644-q0s1la3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-1671
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q0s1la3a
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.061787835479629 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.409559563903736 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.269041277336429 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.095540283342776 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇▇▇▆▇▆▆▇▇▇▇▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▄▆▇▇▇▇▆▆▆▇▇▇▇▆▇▇▇██▇▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▄█▁▄▁▁▁▁▁█▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced volcanic-sweep-1671: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q0s1la3a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182644-q0s1la3a/logs
2022-09-02 18:28:21,221 - wandb.wandb_agent - INFO - Cleaning up finished run: q0s1la3a
2022-09-02 18:28:21,544 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:28:21,544 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01673019928204727
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:28:21,550 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01673019928204727 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:28:26,566 - wandb.wandb_agent - INFO - Running runs: ['v86gm2go']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182827-v86gm2go
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-1687
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v86gm2go
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0404568569902723 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7506509687684915 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0988292123891306 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.095103788758652 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇███▇▇▆▆▆▅▆▇▇▇▇▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▅▅▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇█▇▇████████▇▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▅▂▁▃▅▆▁▁▁▁▅▅▁▁▃▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced misunderstood-sweep-1687: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v86gm2go
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182827-v86gm2go/logs
2022-09-02 18:29:59,447 - wandb.wandb_agent - INFO - Cleaning up finished run: v86gm2go
2022-09-02 18:29:59,775 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:29:59,775 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0012435181550269378
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:29:59,783 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0012435181550269378 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:30:04,798 - wandb.wandb_agent - INFO - Running runs: ['lywwumh2']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183005-lywwumh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-1704
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lywwumh2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.457651075525565 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.656734150507716 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0390721965086263 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.303199087806666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4310191521806743 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇████▇▇█▇██▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁▁▁▁▅▁▁▁▁▁▁█▅▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced spring-sweep-1704: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lywwumh2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183005-lywwumh2/logs
2022-09-02 18:31:43,613 - wandb.wandb_agent - INFO - Cleaning up finished run: lywwumh2
2022-09-02 18:31:43,956 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:31:43,957 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.021127438187947125
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:31:43,962 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.021127438187947125 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:31:48,977 - wandb.wandb_agent - INFO - Running runs: ['c2cec88n']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183148-c2cec88n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-1725
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c2cec88n
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.397914398920982 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.245913014800062 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.338630223757324 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇█▇█▆▇▇▇███▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████▇▇▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▇▃▁▁▁▁▁█▁▅▁█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fast-sweep-1725: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c2cec88n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183148-c2cec88n/logs
2022-09-02 18:33:23,674 - wandb.wandb_agent - INFO - Cleaning up finished run: c2cec88n
2022-09-02 18:33:23,959 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:33:23,959 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.027154271033093653
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:33:23,965 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.027154271033093653 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:33:28,979 - wandb.wandb_agent - INFO - Running runs: ['xghgsfw4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183330-xghgsfw4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-1740
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xghgsfw4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3003135391592573 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1788116331420975 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.144367899070805 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2821788343734175 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▆▆▇▇▇▇▇▆▆▇▇████▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▇▇▇▇▆▇▇▇█▇▇▇▇▇▇█▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇██████████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃█▁▁▁▁▁▁▁▁▆█▄▇█▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced fast-sweep-1740: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xghgsfw4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183330-xghgsfw4/logs
2022-09-02 18:34:56,772 - wandb.wandb_agent - INFO - Cleaning up finished run: xghgsfw4
2022-09-02 18:34:57,101 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:34:57,102 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04211948397871509
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:34:57,108 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04211948397871509 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:35:02,122 - wandb.wandb_agent - INFO - Running runs: ['ij7xq6x3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183503-ij7xq6x3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-1754
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ij7xq6x3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0754909742436136 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.680905424654018 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.368015379214551 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.777762778131831 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▆▆▆▆▆▅▆▆▆▆▆▆▆▅▅▅▅▅▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▂▁▁▁▁▁▁▁▁▅▁▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced mild-sweep-1754: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ij7xq6x3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183503-ij7xq6x3/logs
2022-09-02 18:36:25,334 - wandb.wandb_agent - INFO - Cleaning up finished run: ij7xq6x3
2022-09-02 18:36:25,693 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:36:25,693 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001233730927266306
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:36:25,698 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001233730927266306 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:36:30,714 - wandb.wandb_agent - INFO - Running runs: ['dn2cw9er']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183630-dn2cw9er
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-1769
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dn2cw9er
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1925661024795597 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.641445443970852 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.130286983164547 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.825875298740422 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇█████▇▇▇▇▇▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▆▇██████▇▇▇▆▅▃▂▁▁▁
wandb:  prop_3 ▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▃▄▆▇███
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅▄▁▁▁▁▁▅▁▁█▁▂███▇█▂▆▄█▄█▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced frosty-sweep-1769: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dn2cw9er
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183630-dn2cw9er/logs
2022-09-02 18:37:58,444 - wandb.wandb_agent - INFO - Cleaning up finished run: dn2cw9er
2022-09-02 18:37:58,747 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:37:58,748 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006261329016863445
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:37:58,792 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006261329016863445 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:38:03,807 - wandb.wandb_agent - INFO - Running runs: ['pksfl3i8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183804-pksfl3i8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-1784
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pksfl3i8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4297978122835033 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.879299237068734 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4719229530775624 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ██▇▇▆▆▇▇▇▇▇▇▆▇▇▆▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▆▇▇▇██▇▇▇▇█▇▇█▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁█▁▁▁▁▁▁██▁▁█▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced blooming-sweep-1784: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pksfl3i8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183804-pksfl3i8/logs
2022-09-02 18:39:26,243 - wandb.wandb_agent - INFO - Cleaning up finished run: pksfl3i8
2022-09-02 18:39:26,538 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:39:26,539 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004988393637058511
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:39:26,544 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004988393637058511 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:39:31,560 - wandb.wandb_agent - INFO - Running runs: ['59uxxyeq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183931-59uxxyeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-1798
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59uxxyeq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2893363183747186 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.523954504890844 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2501861639553673 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.932182519428032 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▆▆▇▆▇▇▇███▇▇▆▆▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆▇▇▇▇▇██▇▇▆▆▇▇█▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▅▁▁▃▅▁█▂▁██▁▁▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced neat-sweep-1798: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59uxxyeq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183931-59uxxyeq/logs
2022-09-02 18:40:59,344 - wandb.wandb_agent - INFO - Cleaning up finished run: 59uxxyeq
2022-09-02 18:40:59,637 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:40:59,637 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.009246044439767589
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:40:59,643 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.009246044439767589 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:41:04,657 - wandb.wandb_agent - INFO - Running runs: ['01p1ux6o']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184105-01p1ux6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-1812
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/01p1ux6o
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1098989921273295 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4373009182041496 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.189841238452954 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3454129799030854 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇██▇▇▇▇▇▇▇▇▇▆▆▅▆▆▆▆▅▅▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▅▆▆▆▆▇▆▇▇▇███▇▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁▁▁▁▆▁▂▁▁█▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced lucky-sweep-1812: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/01p1ux6o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184105-01p1ux6o/logs
2022-09-02 18:42:38,910 - wandb.wandb_agent - INFO - Cleaning up finished run: 01p1ux6o
2022-09-02 18:42:39,229 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:42:39,230 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.007784989371981881
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:42:39,235 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.007784989371981881 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:42:44,250 - wandb.wandb_agent - INFO - Running runs: ['s0kxl4do']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184245-s0kxl4do
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-1828
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/s0kxl4do
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.059311729669596 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.464155264376572 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4619022885476323 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.513416714036561 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇████▇▇▇▇▇▇▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▇▇▇▇▇▇███▇▇▇▇▇▇█▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████▇▇▇███▇▇▇█████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▇▄▇▁▁▁▁▁▄▁▁▁▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced silver-sweep-1828: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/s0kxl4do
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184245-s0kxl4do/logs
2022-09-02 18:44:24,487 - wandb.wandb_agent - INFO - Cleaning up finished run: s0kxl4do
2022-09-02 18:44:24,805 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:44:24,805 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00031541623566856247
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:44:24,811 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00031541623566856247 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:44:29,826 - wandb.wandb_agent - INFO - Running runs: ['y7e5craj']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184430-y7e5craj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-1843
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y7e5craj
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3766075202536476 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.392675542374785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.168405724379402 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.259591576286755 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▃▃▃▃▃▃▄▄▄▃▃▃▃▄▄▃▃▃▃▄▆█▇▇▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇███████████████
wandb:  prop_3 ▇███▇▇▆▆▆▆▆▇▇▇▇▆▆▆▅▅▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▁▁▄▅▁▁▁▁▁▁█▁▁▁▁▁████▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced golden-sweep-1843: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y7e5craj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184430-y7e5craj/logs
2022-09-02 18:45:57,607 - wandb.wandb_agent - INFO - Cleaning up finished run: y7e5craj
2022-09-02 18:45:57,955 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:45:57,955 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.004660138631326507
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:45:57,960 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.004660138631326507 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:46:02,976 - wandb.wandb_agent - INFO - Running runs: ['vxgieebz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184603-vxgieebz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-1859
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vxgieebz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.097369995369016 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2258259817983848 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.547571243854023 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▅▆▇▇▇█████████▇▆▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇██▇▇▇▇▇███▇█▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁▁▁▇▁▁▁█▁▁▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced charmed-sweep-1859: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vxgieebz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184603-vxgieebz/logs
2022-09-02 18:47:25,492 - wandb.wandb_agent - INFO - Cleaning up finished run: vxgieebz
2022-09-02 18:47:25,819 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:47:25,819 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.000840191374331421
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:47:25,824 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.000840191374331421 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:47:30,840 - wandb.wandb_agent - INFO - Running runs: ['xur5akgr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184730-xur5akgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-1873
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xur5akgr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.260620825387421 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0560722987945637 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.748511267366362 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇█▇▇████▇▇▇▇▇▇▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆▅▆▆▆▇▇▇▇▇███▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁█▁██▁▁▁▇██▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced glad-sweep-1873: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xur5akgr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184730-xur5akgr/logs
2022-09-02 18:48:59,241 - wandb.wandb_agent - INFO - Cleaning up finished run: xur5akgr
2022-09-02 18:48:59,539 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:48:59,539 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.012204813520671666
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:48:59,551 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.012204813520671666 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:49:04,568 - wandb.wandb_agent - INFO - Running runs: ['c9wii9uu']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184906-c9wii9uu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-1885
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c9wii9uu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.048755815927062 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3741172197808518 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.837846969899575 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▆▆▇▆▇▆▇▇▇▇▆▆▆▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇██▇▇█▇▆▆▆▆▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██████████████████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁▁▁▄▁▁▁▆▅█▇▁██▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dark-sweep-1885: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c9wii9uu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184906-c9wii9uu/logs
2022-09-02 18:50:33,341 - wandb.wandb_agent - INFO - Cleaning up finished run: c9wii9uu
2022-09-02 18:50:33,651 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:50:33,651 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004870661656305279
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:50:33,657 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004870661656305279 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:50:38,701 - wandb.wandb_agent - INFO - Running runs: ['yvlfe22x']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185040-yvlfe22x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-1899
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yvlfe22x
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.179560294787521 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.71240997612653 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.492643213333869 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.856657496075219 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇█▇▇▇▇████████▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▂▃▄▄▅
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇███████████████▇
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▄▁▁▁█▂▅█▁▁▁▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.073
wandb:  prop_3 0.92
wandb: prop_NA 0.007
wandb:  reward 0.92352
wandb: 
wandb: Synced eternal-sweep-1899: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yvlfe22x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185040-yvlfe22x/logs
2022-09-02 18:52:16,738 - wandb.wandb_agent - INFO - Cleaning up finished run: yvlfe22x
2022-09-02 18:52:17,051 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:52:17,051 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.042774902463616905
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:52:17,062 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.042774902463616905 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:52:22,081 - wandb.wandb_agent - INFO - Running runs: ['t62b4qef']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185223-t62b4qef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-1914
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t62b4qef
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.179540346316833 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.322252262240437 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.361378946427101 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.484098130992063 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▆▆▇▇▇▇▆▇▇▇▇▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ██████▇▇▇▇▇▇▇▇▇▇███▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▇▁▇▁▁▆▁▂▁█▁▁█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced glamorous-sweep-1914: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t62b4qef
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185223-t62b4qef/logs
2022-09-02 18:54:00,085 - wandb.wandb_agent - INFO - Cleaning up finished run: t62b4qef
2022-09-02 18:54:00,433 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:54:00,433 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0004708800828128965
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:54:00,441 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0004708800828128965 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:54:05,456 - wandb.wandb_agent - INFO - Running runs: ['4k7ebb0j']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185405-4k7ebb0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-1935
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4k7ebb0j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0014712521870965 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.340473782006173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.582761701017463 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2377940819979276 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.547647749689198 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇██▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▅▆▇▇██▇███▇▇▇▇▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▄▁▁█▁▁▄▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.001
wandb:  prop_2 0.996
wandb:  prop_3 0.0
wandb: prop_NA 0.003
wandb:  reward 0.83716
wandb: 
wandb: Synced dandy-sweep-1935: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4k7ebb0j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185405-4k7ebb0j/logs
2022-09-02 18:55:33,609 - wandb.wandb_agent - INFO - Cleaning up finished run: 4k7ebb0j
2022-09-02 18:55:33,903 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:55:33,903 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0005063221732001498
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:55:33,911 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0005063221732001498 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:55:38,926 - wandb.wandb_agent - INFO - Running runs: ['hjmkbcpq']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185537-hjmkbcpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-1951
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hjmkbcpq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.081779822033991 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1030135863885824 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.591499217676308 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4313556068453166 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1511977759001315 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▃▄▆████████████
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▇█▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▅▅▅▅▅▆▆▆▆▆▆▆▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▇▁▄▁▁▁█▁▁▁▁▄▇▁▁▁▂███▇▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dulcet-sweep-1951: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hjmkbcpq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185537-hjmkbcpq/logs
2022-09-02 18:57:01,840 - wandb.wandb_agent - INFO - Cleaning up finished run: hjmkbcpq
2022-09-02 18:57:02,136 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:57:02,136 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.007288571359682824
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:57:02,142 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.007288571359682824 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:57:07,158 - wandb.wandb_agent - INFO - Running runs: ['twu7jet7']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185707-twu7jet7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-1965
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/twu7jet7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2700020840606743 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2988656487231265 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.773190642447903 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0162253606830465 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.144178194418145 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇▇▇▇▇█▇▇▇▇▇▇▆▆▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇▇████▇▇▆▆▆▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▇▁▁█▁█▁█▅▆▁▁▇▁▇▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced comfy-sweep-1965: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/twu7jet7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185707-twu7jet7/logs
2022-09-02 18:58:29,922 - wandb.wandb_agent - INFO - Cleaning up finished run: twu7jet7
2022-09-02 18:58:30,242 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:58:30,242 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00015556814333487066
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:58:30,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00015556814333487066 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:58:35,281 - wandb.wandb_agent - INFO - Running runs: ['xe7k0an7']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185834-xe7k0an7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-1978
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xe7k0an7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4905775975513897 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4366195944018756 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.382248328901074 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▂▃▃▅▅▅
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████████▇▇▇▇▇
wandb:  prop_3 ▆▆▆▇▇▇▇▇▇▇▇████▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▅▁▁▁█▆▇▇▅▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃█
wandb: 
wandb: Run summary:
wandb:  prop_1 0.078
wandb:  prop_2 0.918
wandb:  prop_3 0.0
wandb: prop_NA 0.004
wandb:  reward 0.83716
wandb: 
wandb: Synced scarlet-sweep-1978: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xe7k0an7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185834-xe7k0an7/logs
2022-09-02 19:00:08,253 - wandb.wandb_agent - INFO - Cleaning up finished run: xe7k0an7
slurmstepd: error: *** JOB 2474907 ON arc-c308 CANCELLED AT 2022-09-02T19:00:08 ***
