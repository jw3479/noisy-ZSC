wandb: Starting wandb agent 🕵️
2022-09-02 15:32:10,126 - wandb.wandb_agent - INFO - Running runs: []
2022-09-02 15:32:10,686 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:32:10,697 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.006061017481494525
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:32:10,703 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.006061017481494525 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:32:15,717 - wandb.wandb_agent - INFO - Running runs: ['nxh4bisr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153216-nxh4bisr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-15
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nxh4bisr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.04656766420113 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3843030641045733 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.77961229509698 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3072084309412775 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.017386385793477 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0207709212091194 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.45298623388654 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
2022-09-02 15:33:38,508 - wandb.wandb_agent - INFO - Cleaning up finished run: nxh4bisr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▇▇▇███▇▇█▇█▇██▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████████▇██████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁█▁▁▂▁▁▅▄▁▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced lunar-sweep-15: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nxh4bisr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153216-nxh4bisr/logs
2022-09-02 15:33:44,109 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:33:44,110 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0014294154648941376
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:33:44,117 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0014294154648941376 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:33:49,128 - wandb.wandb_agent - INFO - Running runs: ['srmmth9i']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153348-srmmth9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-31
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/srmmth9i
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.496700793095008 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1560741092165463 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.506754159157454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3482295984927464 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.05075046293831 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441353951580344 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▅▇▇▇███▇▇▇▇███▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇████▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▇▁▁██▁▁█▅▁▁▁▁▁▇██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.993
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.007
wandb:  reward 1.0
wandb: 
wandb: Synced lemon-sweep-31: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/srmmth9i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153348-srmmth9i/logs
2022-09-02 15:35:16,805 - wandb.wandb_agent - INFO - Cleaning up finished run: srmmth9i
2022-09-02 15:35:17,073 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:35:17,073 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0003437752529564902
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:35:17,080 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0003437752529564902 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:35:22,090 - wandb.wandb_agent - INFO - Running runs: ['r9mh6rpr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153522-r9mh6rpr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-44
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r9mh6rpr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3380967485753903 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2863265891769755 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.149092888778571 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.222726150822883 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.404930535268476 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.383521497864308 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇███▇▇▇▇█▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆▇███▇▆▆▆▆▇▇▇▇▇▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇█▇▇▇▇▇▇▇▇██▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁█▁▁▄▁█▁▁▁▅▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced radiant-sweep-44: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r9mh6rpr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153522-r9mh6rpr/logs
2022-09-02 15:36:44,612 - wandb.wandb_agent - INFO - Cleaning up finished run: r9mh6rpr
2022-09-02 15:36:44,854 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:36:44,854 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00025790284191839455
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:36:44,861 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00025790284191839455 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:36:49,874 - wandb.wandb_agent - INFO - Running runs: ['f5b3x90a']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153650-f5b3x90a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-57
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f5b3x90a
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.289434157206676 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.807149896945731 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.201938657103938 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.18422209131665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2963344093163007 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.349253229039556 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆██▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▇████▇▇▇▆▇▇▇▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▄▅▇████████████
wandb: prop_NA ███▇▇▇▇▇▇▇██████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▅▁▁▅▁▁█▁▁▁▁▄▁▁▁▁█▃▅▅█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.998
wandb: prop_NA 0.002
wandb:  reward 0.92352
wandb: 
wandb: Synced misunderstood-sweep-57: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f5b3x90a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153650-f5b3x90a/logs
2022-09-02 15:38:13,266 - wandb.wandb_agent - INFO - Cleaning up finished run: f5b3x90a
2022-09-02 15:38:13,497 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:38:13,497 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0058868026000557915
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:38:13,503 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0058868026000557915 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:38:18,515 - wandb.wandb_agent - INFO - Running runs: ['cixoz5ib']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153819-cixoz5ib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-70
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cixoz5ib
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2735509160640794 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.102479837044341 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0639938882409483 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.12727705958148 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0136898929370193 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.117137312147074 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▆▇▇▇▇████▇▇▆▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▆▇▆▇▇▆▆▆▆▆▆▅▅▅▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▅▁▆▁▂▁▁█▄▇▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced splendid-sweep-70: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cixoz5ib
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153819-cixoz5ib/logs
2022-09-02 15:39:40,991 - wandb.wandb_agent - INFO - Cleaning up finished run: cixoz5ib
2022-09-02 15:39:41,240 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:39:41,240 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00034582029488311526
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:39:41,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00034582029488311526 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:39:46,273 - wandb.wandb_agent - INFO - Running runs: ['r0sz65cn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153948-r0sz65cn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-83
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r0sz65cn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1202645637631528 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.300935463662737 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0020646869723056 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9920196500518355 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3878798306602236 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.262042906822337 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▂▂▂▂▂▁▁▁▁▁▂▃▅▆▇█████▇▇
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████▇▆▅▅▄▃▃▃▃▃▄▄
wandb:  prop_3 ▄▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇▆▆█▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▁▁▁▅▁▁▁▅▁▅▅▁▁█▁▂███▇█▂▆▅▆▇▁██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.543
wandb:  prop_2 0.43
wandb:  prop_3 0.0
wandb: prop_NA 0.027
wandb:  reward 1.0
wandb: 
wandb: Synced honest-sweep-83: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r0sz65cn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153948-r0sz65cn/logs
2022-09-02 15:41:08,763 - wandb.wandb_agent - INFO - Cleaning up finished run: r0sz65cn
2022-09-02 15:41:09,023 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:41:09,024 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.029965297381868497
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:41:09,063 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.029965297381868497 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:41:14,077 - wandb.wandb_agent - INFO - Running runs: ['6x1c0aik']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154116-6x1c0aik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-98
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6x1c0aik
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.497908375084974 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4355172606378472 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.250845733042912 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2818997340970415 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.601305140182783 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▆▇▇▇▇▇████▇██████▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇██▇▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇██████▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▅▁▁▁▁█▁▁▇▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced deep-sweep-98: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6x1c0aik
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154116-6x1c0aik/logs
2022-09-02 15:42:41,702 - wandb.wandb_agent - INFO - Cleaning up finished run: 6x1c0aik
2022-09-02 15:42:41,979 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:42:41,979 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.01958285394871298
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:42:41,987 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.01958285394871298 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:42:47,000 - wandb.wandb_agent - INFO - Running runs: ['hf6q41bi']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154248-hf6q41bi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-114
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hf6q41bi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.436143540012342 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.050387584213381 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.34247507781501 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2793610332440353 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.478767936898641 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.015115043709666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3136873947203025 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇██▇▇▇▇▆▆▆▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▆▇▇███▇▆▇▇▇▇████▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▁▁▇▁▁▁▁█▁▁▁▁▁▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced worthy-sweep-114: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hf6q41bi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154248-hf6q41bi/logs
2022-09-02 15:44:19,768 - wandb.wandb_agent - INFO - Cleaning up finished run: hf6q41bi
2022-09-02 15:44:20,054 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:44:20,054 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00017133062259142603
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:44:20,059 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00017133062259142603 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:44:25,070 - wandb.wandb_agent - INFO - Running runs: ['qs13qevw']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154425-qs13qevw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-131
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qs13qevw
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.132736937669002 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3705862475749306 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.050884716368281 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.066668615278876 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▇▆▆▆▆▅▅▆▅▅▅▅▅▆▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▇▇▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▇▄▄▁▁▆█▁▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced vocal-sweep-131: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qs13qevw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154425-qs13qevw/logs
2022-09-02 15:45:57,810 - wandb.wandb_agent - INFO - Cleaning up finished run: qs13qevw
2022-09-02 15:45:58,050 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:45:58,050 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.002315734181933595
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:45:58,057 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.002315734181933595 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:46:03,072 - wandb.wandb_agent - INFO - Running runs: ['qdh4fjzz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154602-qdh4fjzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-147
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qdh4fjzz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.238404337240594 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0128901625102635 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1347792636549645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.148995125368823 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.107626008150623 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.794194252837412 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇▇▆▇▇▇▇█▇▇█▇███▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇██▇▇▇▇███▇▆▆▆▆▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████▇▇▇█████▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▃█▁▁▃▁▁██▅█▁▅▁█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced zesty-sweep-147: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qdh4fjzz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154602-qdh4fjzz/logs
2022-09-02 15:47:30,880 - wandb.wandb_agent - INFO - Cleaning up finished run: qdh4fjzz
2022-09-02 15:47:31,164 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:47:31,164 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.008539287088057148
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:47:31,170 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.008539287088057148 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:47:36,183 - wandb.wandb_agent - INFO - Running runs: ['qx1c6apq']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154735-qx1c6apq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-163
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qx1c6apq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3538394560757125 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.145933922430345 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.671689192103265 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3932361320118174 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0418212405533214 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▃▆▆▆▆▆▆▅▆▆▇█▇▇▆▇▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▇▄▁█▅▁█▇▁▁▁▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced likely-sweep-163: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qx1c6apq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154735-qx1c6apq/logs
2022-09-02 15:49:08,965 - wandb.wandb_agent - INFO - Cleaning up finished run: qx1c6apq
2022-09-02 15:49:09,559 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:49:09,563 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.001151489599265628
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:49:09,581 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.001151489599265628 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:49:14,603 - wandb.wandb_agent - INFO - Running runs: ['yg958sb4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154914-yg958sb4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-178
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yg958sb4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2192008649684194 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6772686730937325 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1658625309085604 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.922295311472633 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3176272123440342 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▂▁▅▁▁▇▁▁▆▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced visionary-sweep-178: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yg958sb4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154914-yg958sb4/logs
2022-09-02 15:50:37,475 - wandb.wandb_agent - INFO - Cleaning up finished run: yg958sb4
2022-09-02 15:50:37,740 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:50:37,740 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00016461319894795206
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:50:37,747 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00016461319894795206 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:50:42,760 - wandb.wandb_agent - INFO - Running runs: ['ivfbd1ld']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155042-ivfbd1ld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-192
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ivfbd1ld
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.460105279037854 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.162192320594006 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0014989484539396 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.993289291692769 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3265621668313043 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▄▆▇█████
wandb:  prop_2 █▇▇▇▇▇▇▇▇▆▆▇▇▇▇▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▆▇███████▇▅▃▂▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁██▁█▁▁▁▁█▁▁▁▁▁█▁▁▅▄▄▆█▅██████▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced restful-sweep-192: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ivfbd1ld
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155042-ivfbd1ld/logs
2022-09-02 15:52:05,273 - wandb.wandb_agent - INFO - Cleaning up finished run: ivfbd1ld
2022-09-02 15:52:05,522 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:52:05,522 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004806995700712997
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:52:05,531 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004806995700712997 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:52:10,543 - wandb.wandb_agent - INFO - Running runs: ['7l9hwp89']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155210-7l9hwp89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-205
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7l9hwp89
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.347536415042587 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.396391224908644 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1285602300507955 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.340332558749708 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0549209026331536 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.273958814556356 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▇▇▇▇████▇▇▇▆▇▇▇█▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▆▆▇▆▇▇▆▆▆▇▇██▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▁▇▁▁▁▁▇▁▁▁▁▁█▇▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced cerulean-sweep-205: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7l9hwp89
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155210-7l9hwp89/logs
2022-09-02 15:53:38,109 - wandb.wandb_agent - INFO - Cleaning up finished run: 7l9hwp89
2022-09-02 15:53:38,389 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:53:38,389 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003348087847801378
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:53:38,395 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003348087847801378 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:53:43,408 - wandb.wandb_agent - INFO - Running runs: ['1uwt7wty']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155343-1uwt7wty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-221
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1uwt7wty
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2101995443695435 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0650312582993355 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5554825863366935 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1670221569463513 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.368310355712247 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0420420355156765 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.152321591983816 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ██▇▇▇▇▇▇▇██▇█▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇█████▇█▇▇▇▇▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇██████████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▄▁▅▁▁▁██▁▁█▆▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sparkling-sweep-221: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1uwt7wty
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155343-1uwt7wty/logs
2022-09-02 15:55:06,018 - wandb.wandb_agent - INFO - Cleaning up finished run: 1uwt7wty
2022-09-02 15:55:06,312 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:55:06,313 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.003922464799711389
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:55:06,322 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.003922464799711389 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:55:11,334 - wandb.wandb_agent - INFO - Running runs: ['wve4a0kq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155511-wve4a0kq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-232
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wve4a0kq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0684904174945595 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1388622285109453 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.204081179777343 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4300626213014938 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.566602835667884 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇▇███▇▇▇▆▆▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇███▇▆▇▇▇▇▇▇▇▇▇██▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇▇██▇████▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▁█▁▁▁▁▁▁▁▁█▅▇▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced celestial-sweep-232: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wve4a0kq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155511-wve4a0kq/logs
2022-09-02 15:56:39,142 - wandb.wandb_agent - INFO - Cleaning up finished run: wve4a0kq
2022-09-02 15:56:39,512 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:56:39,517 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002055640056259067
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:56:39,531 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002055640056259067 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:56:44,545 - wandb.wandb_agent - INFO - Running runs: ['t7biahf0']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155644-t7biahf0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-247
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t7biahf0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.053369835482499 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.308302179321231 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.150993949111125 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.569893866320909 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.022294755254209 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.445342632565965 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▅▆▇▇▇█▇██▇▇▇▇▇▇▆▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▇▆▇▇▇▇▇▆▇████▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▆▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.999
wandb: prop_NA 0.001
wandb:  reward 0.92352
wandb: 
wandb: Synced eager-sweep-247: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/t7biahf0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155644-t7biahf0/logs
2022-09-02 15:58:12,091 - wandb.wandb_agent - INFO - Cleaning up finished run: t7biahf0
2022-09-02 15:58:12,356 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:58:12,361 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00013596100694338826
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:58:12,367 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00013596100694338826 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:58:17,381 - wandb.wandb_agent - INFO - Running runs: ['39vpw1xy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155817-39vpw1xy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-262
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/39vpw1xy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1730077261013054 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1995156775318443 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.277023223270837 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3008011672883724 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.851736140851395 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▆▇▇███▇▆▆▆▆▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇██▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ███████▇▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁▅▁▁▁▁█▅▄▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced lucky-sweep-262: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/39vpw1xy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155817-39vpw1xy/logs
2022-09-02 15:59:45,019 - wandb.wandb_agent - INFO - Cleaning up finished run: 39vpw1xy
2022-09-02 15:59:45,277 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:59:45,283 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.003679121518180084
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:59:45,289 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.003679121518180084 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:59:50,302 - wandb.wandb_agent - INFO - Running runs: ['qj2iq8ef']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155949-qj2iq8ef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-281
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qj2iq8ef
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2829736388437847 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1011672504767773 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.296799171321669 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.529500170662686 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2889652564862426 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.628710484387148 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ██▇▇▇▇▆▇▇▇▇▆▇███▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ███▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁█▁▇▁██▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced legendary-sweep-281: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qj2iq8ef
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155949-qj2iq8ef/logs
2022-09-02 16:01:12,785 - wandb.wandb_agent - INFO - Cleaning up finished run: qj2iq8ef
2022-09-02 16:01:13,022 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:01:13,023 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0001955913055849972
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:01:13,029 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0001955913055849972 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:01:18,056 - wandb.wandb_agent - INFO - Running runs: ['y7no94gr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160119-y7no94gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-292
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y7no94gr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.367198076610198 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.95583576429123 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.300988020670255 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.085650733150519 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇█▇▇█████▇▇▆▆▆▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇███████████████▇
wandb:  prop_3 ▅▇███▇▇▇▇▆▆▇▇▇▇▇▇█▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇█▇▇▇▇█████████████▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁▁▁▁▄█▁▁▁▇▅██▁▇██▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃█
wandb: 
wandb: Run summary:
wandb:  prop_1 0.045
wandb:  prop_2 0.933
wandb:  prop_3 0.0
wandb: prop_NA 0.022
wandb:  reward 0.83716
wandb: 
wandb: Synced swift-sweep-292: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y7no94gr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160119-y7no94gr/logs
2022-09-02 16:02:43,080 - wandb.wandb_agent - INFO - Cleaning up finished run: y7no94gr
2022-09-02 16:02:43,346 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:02:43,346 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0011830339306649696
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:02:43,353 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0011830339306649696 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:02:48,365 - wandb.wandb_agent - INFO - Running runs: ['nlqcdgit']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160249-nlqcdgit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-305
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nlqcdgit
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4156989153078556 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.015279977727605 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1222151913500427 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.15982113315785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.370176500906068 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.996905867467802 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▇▆▆▆▇▇▆▇▆▆▇▇███▇▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇█████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁█▅▁█▁▁▁█▁▅█▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.959
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.041
wandb:  reward 1.0
wandb: 
wandb: Synced lucky-sweep-305: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nlqcdgit
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160249-nlqcdgit/logs
2022-09-02 16:04:11,268 - wandb.wandb_agent - INFO - Cleaning up finished run: nlqcdgit
2022-09-02 16:04:11,533 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:04:11,539 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002875897351964485
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:04:11,565 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002875897351964485 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:04:16,580 - wandb.wandb_agent - INFO - Running runs: ['b4tuoami']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160417-b4tuoami
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-319
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b4tuoami
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.457571780183837 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3352895168647994 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.51896087248025 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.345391604739781 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.221083431420143 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▅▆▇▇▇██████▇▇▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▆▇▇▇▇██▇█▇▇▇█▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇██▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▇██▁▁▁▁▁█▁▁▁▇▇▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced playful-sweep-319: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b4tuoami
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160417-b4tuoami/logs
2022-09-02 16:05:54,568 - wandb.wandb_agent - INFO - Cleaning up finished run: b4tuoami
2022-09-02 16:05:54,816 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:05:54,816 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004727977983050663
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:05:54,852 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004727977983050663 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:05:59,867 - wandb.wandb_agent - INFO - Running runs: ['uz0nx0bk']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160559-uz0nx0bk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-338
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uz0nx0bk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3663217753797374 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4508228974247723 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.785752152117582 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.236886921451249 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.642455652050912 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.225657482650136 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇████▇▇▇██▇████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▃▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced stellar-sweep-338: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uz0nx0bk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160559-uz0nx0bk/logs
2022-09-02 16:07:32,893 - wandb.wandb_agent - INFO - Cleaning up finished run: uz0nx0bk
2022-09-02 16:07:43,066 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:07:43,066 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.04160359823653522
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:07:43,072 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.04160359823653522 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:07:48,085 - wandb.wandb_agent - INFO - Running runs: ['vopxwfy5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160748-vopxwfy5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-357
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vopxwfy5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2660259385539114 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0071944469437675 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.334163810523192 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.159523084748462 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.919495224220035 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 █▆▇█▇█▇▆▇▇▇██▇████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▇▇▇▇▇▇▇████████▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████▇▇▇▇█▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▁▁▁▁█▁▁▆▁▁▁▁▃▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced deep-sweep-357: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vopxwfy5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160748-vopxwfy5/logs
2022-09-02 16:09:26,667 - wandb.wandb_agent - INFO - Cleaning up finished run: vopxwfy5
2022-09-02 16:09:26,922 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:09:26,922 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.012756001895729788
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:09:26,936 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.012756001895729788 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:09:31,951 - wandb.wandb_agent - INFO - Running runs: ['xeisw4mx']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160931-xeisw4mx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-372
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xeisw4mx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2761684594170246 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.791903326297719 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.244413439240592 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.661204451409523 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.420551989523675 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1095418338424583 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇▇▇█▇▇▇▇▇▇▇▆▆▆▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇████████▇▇▇██▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▁▁▇▁▁█▁▁▁▁▁▁▇▁▇▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced young-sweep-372: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xeisw4mx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160931-xeisw4mx/logs
2022-09-02 16:11:04,819 - wandb.wandb_agent - INFO - Cleaning up finished run: xeisw4mx
2022-09-02 16:11:06,804 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:11:06,805 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.02540170211208093
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:11:06,816 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.02540170211208093 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:11:11,830 - wandb.wandb_agent - INFO - Running runs: ['x9lid5v9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161111-x9lid5v9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-389
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x9lid5v9
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.425975939694766 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4952461166354167 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.455045981794889 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.231333887407052 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.460324186570736 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇████▇▇▇████▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▅▆▇▇███▇▆▆▆▆▆▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▂██▁▁█▁▁▁▅▁▁▁▇▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced unique-sweep-389: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x9lid5v9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161111-x9lid5v9/logs
2022-09-02 16:12:34,300 - wandb.wandb_agent - INFO - Cleaning up finished run: x9lid5v9
2022-09-02 16:12:34,576 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:12:34,577 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0006467250961321188
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:12:34,583 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0006467250961321188 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:12:39,600 - wandb.wandb_agent - INFO - Running runs: ['o3d5651q']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161238-o3d5651q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-403
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o3d5651q
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.027766846575698 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0608376891274736 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.689084887560429 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.167977338654744 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1817798021726045 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4213187362580646 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.971211686976245 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▇██▇▇▇▇▇▇▇▇█████▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▇▇██▇▇▇▇▇▇▇▇▇██▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████▇▇███▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▄▁▁▁██▁██▁▇█▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.991
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.009
wandb:  reward 1.0
wandb: 
wandb: Synced cosmic-sweep-403: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o3d5651q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161238-o3d5651q/logs
2022-09-02 16:14:14,796 - wandb.wandb_agent - INFO - Cleaning up finished run: o3d5651q
2022-09-02 16:14:15,049 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:14:15,050 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00020877067669159652
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:14:15,061 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00020877067669159652 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:14:20,075 - wandb.wandb_agent - INFO - Running runs: ['39u5i6lv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161419-39u5i6lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-418
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/39u5i6lv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.179118566443262 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.580636150866794 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.097855854925311 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.250939409592412 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.400442175280925 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇██▇██▇██▇█▇▇███▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇██▇▇▇▇█████▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██████▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▇▂▇▁▁▆▇▇▁▆█▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.999
wandb: prop_NA 0.001
wandb:  reward 0.92352
wandb: 
wandb: Synced dainty-sweep-418: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/39u5i6lv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161419-39u5i6lv/logs
2022-09-02 16:15:52,888 - wandb.wandb_agent - INFO - Cleaning up finished run: 39u5i6lv
2022-09-02 16:15:53,151 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:15:53,151 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.004444924284238107
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:15:53,164 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.004444924284238107 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:15:58,180 - wandb.wandb_agent - INFO - Running runs: ['wsfv9qyu']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161557-wsfv9qyu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-433
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wsfv9qyu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.138428809312465 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.841704901110358 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484520240555178 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.272945282331019 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1457411730750273 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇████▇▇▇▇▇▆▆▆▆▆▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇████▇▇███▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▂▂▁▁▁▁▂▂▂▂▂▂▂▄▆▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁█▁▁▄█▁▄██▅▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced restful-sweep-433: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wsfv9qyu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161557-wsfv9qyu/logs
2022-09-02 16:17:20,617 - wandb.wandb_agent - INFO - Cleaning up finished run: wsfv9qyu
2022-09-02 16:17:20,842 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:17:20,842 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.002818243479835649
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:17:20,847 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.002818243479835649 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:17:25,861 - wandb.wandb_agent - INFO - Running runs: ['di0ujmfv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161725-di0ujmfv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-446
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/di0ujmfv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.277776311515132 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.774011170851071 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1406518693738543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.238429287196781 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▇▇▇▇▆▆▆▆▇▇▇█▇▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇█████▇▇▇▆▇▇▆▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ▇▇█▇▇▇██████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁█▁▅▁▆▁▁▁▁██▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced ethereal-sweep-446: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/di0ujmfv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161725-di0ujmfv/logs
2022-09-02 16:18:48,299 - wandb.wandb_agent - INFO - Cleaning up finished run: di0ujmfv
2022-09-02 16:18:48,619 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:18:48,619 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0008055453265681047
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:18:48,625 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0008055453265681047 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:18:53,642 - wandb.wandb_agent - INFO - Running runs: ['agp5liwe']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161853-agp5liwe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-461
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/agp5liwe
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.140741988821175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.703037525076946 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1178559099073904 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.27921192231706 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.43658677892427 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▇███▇▇▇▇▇▇███▇▇▇█▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇██▇█▇▇▇▆▆▆▇▇▇▇▇▇▇▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇████▇▇▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇▁██▁▁██▁▁█▁▁▇▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced dashing-sweep-461: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/agp5liwe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161853-agp5liwe/logs
2022-09-02 16:20:21,225 - wandb.wandb_agent - INFO - Cleaning up finished run: agp5liwe
2022-09-02 16:20:21,528 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:20:21,528 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003159658357239233
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:20:21,539 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003159658357239233 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:20:26,558 - wandb.wandb_agent - INFO - Running runs: ['hgcior4g']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162025-hgcior4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-474
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hgcior4g
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.147444900958258 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9338737109238595 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4219030105245674 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2595017056441895 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4445648784064034 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇██▇▇███▇▇▆▆▆▇█▇▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▅▅▅▅▅▅▅▅▅▄▄▅▅▅▅▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅█
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇█████████████▇▇▆
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▁▁▁▁█▁▁▇▆▃▁▅▄▄▆█▅██████▇▆██▃▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.212
wandb:  prop_3 0.787
wandb: prop_NA 0.001
wandb:  reward 0.92352
wandb: 
wandb: Synced neat-sweep-474: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hgcior4g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162025-hgcior4g/logs
2022-09-02 16:21:55,099 - wandb.wandb_agent - INFO - Cleaning up finished run: hgcior4g
2022-09-02 16:21:55,349 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:21:55,350 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.011108601328286524
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:21:55,397 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.011108601328286524 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:22:00,413 - wandb.wandb_agent - INFO - Running runs: ['mbk2in09']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162159-mbk2in09
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-489
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mbk2in09
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3723142365755323 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.426610572389811 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.762683183045299 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4240567714954846 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▇▇██▇▇▇▇▇▇▆▆▆▆▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▁█▁▁▅▁▁█▁▁▁█▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced ethereal-sweep-489: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mbk2in09
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162159-mbk2in09/logs
2022-09-02 16:23:28,032 - wandb.wandb_agent - INFO - Cleaning up finished run: mbk2in09
2022-09-02 16:23:28,377 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:23:28,378 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001870392512864755
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:23:28,381 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001870392512864755 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:23:33,394 - wandb.wandb_agent - INFO - Running runs: ['95e8fvm8']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162333-95e8fvm8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-503
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/95e8fvm8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.482292044012085 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.445997143374515 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.055498094941958 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.34377325267201 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.183531314819493 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2988761253352834 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▆▆▆▇▆▆▆▆▆▆▆▇▆▆▇▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▆▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▅▁▁▁▁▁▁▁▁▁▄▁█▁▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced frosty-sweep-503: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/95e8fvm8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162333-95e8fvm8/logs
2022-09-02 16:25:03,671 - wandb.wandb_agent - INFO - Cleaning up finished run: 95e8fvm8
2022-09-02 16:25:03,922 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:25:03,922 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.002140879118164071
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:25:03,930 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.002140879118164071 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:25:08,942 - wandb.wandb_agent - INFO - Running runs: ['d26rsuga']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162508-d26rsuga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-517
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d26rsuga
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.212170225330172 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.333871029428057 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484459016695594 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0454214419785615 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.255677765349939 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.255162603394924 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▆▇▇▇█▇▇▇▆▆▇▇██▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▆▆▅▅▅▅▅▅▆▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁█▁▁▁▁▁▁▁▁▆██▇▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced vital-sweep-517: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/d26rsuga
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162508-d26rsuga/logs
2022-09-02 16:26:39,082 - wandb.wandb_agent - INFO - Cleaning up finished run: d26rsuga
2022-09-02 16:26:40,380 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:26:40,380 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.02581015411203235
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:26:40,389 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.02581015411203235 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:26:45,404 - wandb.wandb_agent - INFO - Running runs: ['cuykwyf9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162644-cuykwyf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-534
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cuykwyf9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2857659283881717 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3058661363978783 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.296578508984299 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.389498041727513 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.397003593918179 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇▇▇▇█▇▇▇▆▆▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▄▁▁▁▁█▁▁▆██▁▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced absurd-sweep-534: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cuykwyf9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162644-cuykwyf9/logs
2022-09-02 16:28:18,223 - wandb.wandb_agent - INFO - Cleaning up finished run: cuykwyf9
2022-09-02 16:28:18,505 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:28:18,505 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.008624431844816711
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:28:18,512 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.008624431844816711 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:28:23,527 - wandb.wandb_agent - INFO - Running runs: ['sg12c54o']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162822-sg12c54o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-549
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sg12c54o
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1241004278741373 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.418238897009405 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0000664891458806 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3691127695223075 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.494591418549549 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.987227142856268 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3586433112215492 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ██▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▅▅▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▆▇▇▇████▇█▇▇▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇███▇▇▇▇▇▇▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▃█▁▄▁▅▆▁▁▅▁▁▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced atomic-sweep-549: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sg12c54o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162822-sg12c54o/logs
2022-09-02 16:29:51,589 - wandb.wandb_agent - INFO - Cleaning up finished run: sg12c54o
2022-09-02 16:29:51,961 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:29:51,961 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001631553330606175
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:29:51,967 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001631553330606175 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:29:56,979 - wandb.wandb_agent - INFO - Running runs: ['ycydg4ir']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162956-ycydg4ir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-564
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ycydg4ir
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.303231974165707 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0726681879955513 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.690885302003812 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.429972756298576 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇██▇▇▇▇██▇▇▇▇█▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇█████▇▇▇▇▇▇▇▇█▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇███████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▅▁██▁▆▁▁▁▁▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced crimson-sweep-564: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ycydg4ir
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162956-ycydg4ir/logs
2022-09-02 16:31:29,813 - wandb.wandb_agent - INFO - Cleaning up finished run: ycydg4ir
2022-09-02 16:31:30,061 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:31:30,061 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0011452226929068072
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:31:30,064 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0011452226929068072 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:31:35,075 - wandb.wandb_agent - INFO - Running runs: ['urtgkpbz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163134-urtgkpbz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-579
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/urtgkpbz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.283496179622744 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.513045500482925 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4132364177135255 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.765567526860015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2828452783585105 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▅▆▇▇████▇▇▇██▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇▆▆▇▇▇█▇▇▇▆▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁█▁▁▅▁▆▁▁▁█▅█▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.994
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.006
wandb:  reward 1.0
wandb: 
wandb: Synced deep-sweep-579: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/urtgkpbz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163134-urtgkpbz/logs
2022-09-02 16:33:08,002 - wandb.wandb_agent - INFO - Cleaning up finished run: urtgkpbz
2022-09-02 16:33:08,240 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:33:08,240 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006981011031144783
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:33:08,252 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006981011031144783 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:33:13,266 - wandb.wandb_agent - INFO - Running runs: ['qrv1pkoo']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163313-qrv1pkoo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-595
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qrv1pkoo
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0391899036225043 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.437255966688045 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.118227824054813 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2512103400531873 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▇▇▇█▇██▇██▇▇▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▇▆▆▆▆▇▇▇▇▇▆▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ██████████▇▇████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▂█▁▁█▁▁▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced honest-sweep-595: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qrv1pkoo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163313-qrv1pkoo/logs
2022-09-02 16:34:35,818 - wandb.wandb_agent - INFO - Cleaning up finished run: qrv1pkoo
2022-09-02 16:34:36,052 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:34:36,053 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.032349635052170006
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:34:36,058 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.032349635052170006 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:34:41,070 - wandb.wandb_agent - INFO - Running runs: ['ojzmfwwg']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163440-ojzmfwwg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-608
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ojzmfwwg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.153348368356591 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.68611222709486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.384207451191679 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4855283982258505 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆██▇▇▆▆▆▆▇▇▇▇▇▆▆▆▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▆▆▆▆▇▇▆▆▆▅▆▆▆▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▄▁▂▁▁▁▁▇▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced apricot-sweep-608: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ojzmfwwg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163440-ojzmfwwg/logs
2022-09-02 16:36:13,927 - wandb.wandb_agent - INFO - Cleaning up finished run: ojzmfwwg
2022-09-02 16:36:14,189 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:36:14,189 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0006196210871656773
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:36:14,203 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0006196210871656773 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:36:19,218 - wandb.wandb_agent - INFO - Running runs: ['rc6pzl57']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163618-rc6pzl57
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-622
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rc6pzl57
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4363840360829454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4745815307967365 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.134545575443806 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.129731426563991 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.039256863255352 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▆▇▇▆▇▇▇▇▇▆▆▆▆▇██▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ███▇▇▇▆▆▇▆▇▇█▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁█▁▁▅▁▁▁▁▁██▁▁█▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced avid-sweep-622: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rc6pzl57
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163618-rc6pzl57/logs
2022-09-02 16:37:47,655 - wandb.wandb_agent - INFO - Cleaning up finished run: rc6pzl57
2022-09-02 16:37:47,885 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:37:47,886 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.002346877237238725
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:37:47,906 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.002346877237238725 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:37:52,919 - wandb.wandb_agent - INFO - Running runs: ['dvs91o08']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163752-dvs91o08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-638
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dvs91o08
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3243724350859103 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0582990175618097 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.92406218066682 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4435784222990247 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.758843024447805 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0037299938535362 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.400877309363567 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇██▇██▇▇▇▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▆▆▆▆▅▅▆▅▆▇▆▆▅▅▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇▇████████▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▇▂█▁█▆▁▁▁█▁▁▁▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.947
wandb: prop_NA 0.053
wandb:  reward 0.92352
wandb: 
wandb: Synced ethereal-sweep-638: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dvs91o08
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163752-dvs91o08/logs
2022-09-02 16:39:25,717 - wandb.wandb_agent - INFO - Cleaning up finished run: dvs91o08
2022-09-02 16:39:25,977 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:39:25,978 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0020884437216916853
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:39:25,984 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0020884437216916853 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:39:30,996 - wandb.wandb_agent - INFO - Running runs: ['rfiv3u8g']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163930-rfiv3u8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-653
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rfiv3u8g
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.329617417536464 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.118121860797466 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.197273015264193 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4326669045988005 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇█▇▇▇▇█▇▇▇▇█████▇▇█▆▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▁▃▁▁█▁▁█▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.999
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 1.0
wandb: 
wandb: Synced silvery-sweep-653: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rfiv3u8g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163930-rfiv3u8g/logs
2022-09-02 16:41:08,858 - wandb.wandb_agent - INFO - Cleaning up finished run: rfiv3u8g
2022-09-02 16:41:09,149 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:41:09,153 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.017191285463906
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:41:09,165 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.017191285463906 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:41:14,179 - wandb.wandb_agent - INFO - Running runs: ['g4nhcdkr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164114-g4nhcdkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-669
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g4nhcdkr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0036852035842942 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.120752047985024 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2787236416085825 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▆▆▆▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▂▁▁▁▁▁█▁▁▁▁█▁▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced polished-sweep-669: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g4nhcdkr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164114-g4nhcdkr/logs
2022-09-02 16:42:36,673 - wandb.wandb_agent - INFO - Cleaning up finished run: g4nhcdkr
2022-09-02 16:42:36,918 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:42:36,919 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00035428447072785395
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:42:36,939 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00035428447072785395 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:42:41,956 - wandb.wandb_agent - INFO - Running runs: ['qlyd6efi']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164242-qlyd6efi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-682
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qlyd6efi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.176722531933917 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1319349753709433 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4348422008218105 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4458282285356585 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▆▆▆▆▆▇▇█▇▇█████▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇████████▇▇▇▇▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁█▁▁█▁▄█▁▁▁▁▁▇▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced charmed-sweep-682: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qlyd6efi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164242-qlyd6efi/logs
2022-09-02 16:44:10,234 - wandb.wandb_agent - INFO - Cleaning up finished run: qlyd6efi
2022-09-02 16:44:10,584 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:44:10,584 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00016746024670952355
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:44:10,594 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00016746024670952355 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:44:15,607 - wandb.wandb_agent - INFO - Running runs: ['nj8biox7']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164415-nj8biox7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-699
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nj8biox7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.175140151562595 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0286520630076534 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.338060339808754 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.007086805236337 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3906187462968798 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇█▇██▇▇▆▆▇▇▇▇▇▇▇██▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▇▁▁▁▁█▁▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced glad-sweep-699: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nj8biox7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164415-nj8biox7/logs
2022-09-02 16:45:48,734 - wandb.wandb_agent - INFO - Cleaning up finished run: nj8biox7
2022-09-02 16:45:48,972 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:45:48,972 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0014736858934398746
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:45:48,990 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0014736858934398746 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:45:54,009 - wandb.wandb_agent - INFO - Running runs: ['szl58509']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164554-szl58509
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-714
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/szl58509
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1829643300721706 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1806501202862227 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3302836570813397 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0108791283239973 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇████▇▆▅▆▆▇▇▆▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇████▇██▇██▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▄▁█▁█▁▁█▁▄▇▆▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.999
wandb: prop_NA 0.001
wandb:  reward 0.92352
wandb: 
wandb: Synced electric-sweep-714: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/szl58509
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164554-szl58509/logs
2022-09-02 16:47:21,606 - wandb.wandb_agent - INFO - Cleaning up finished run: szl58509
2022-09-02 16:47:21,848 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:47:21,849 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005677089082898695
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:47:21,863 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005677089082898695 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:47:26,878 - wandb.wandb_agent - INFO - Running runs: ['o53bhpao']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164728-o53bhpao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-728
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o53bhpao
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3223004400453 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.806502927345971 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇▇▇▇▆▆▇▇██▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▆▆▆▇▇▇████▇▇▇▇▇▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.955
wandb: prop_NA 0.045
wandb:  reward 0.92352
wandb: 
wandb: Synced amber-sweep-728: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o53bhpao
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164728-o53bhpao/logs
2022-09-02 16:49:04,961 - wandb.wandb_agent - INFO - Cleaning up finished run: o53bhpao
2022-09-02 16:49:05,213 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:49:05,214 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.006263086757337752
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:49:05,225 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.006263086757337752 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:49:10,237 - wandb.wandb_agent - INFO - Running runs: ['v1wnsli5']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164910-v1wnsli5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-744
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v1wnsli5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.458727305734481 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.272855766712512 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.074231067119808 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.291473220899939 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3491599539482575 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▆▇▇▇▇▇▇▇▇▇▇████▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁█▁▁▁▁▅▁▁▇▁▁▁▁▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced lucky-sweep-744: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v1wnsli5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164910-v1wnsli5/logs
2022-09-02 16:50:53,905 - wandb.wandb_agent - INFO - Cleaning up finished run: v1wnsli5
2022-09-02 16:50:54,188 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:50:54,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.013243893862040576
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:50:54,202 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.013243893862040576 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:50:59,216 - wandb.wandb_agent - INFO - Running runs: ['y13zxv7v']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165101-y13zxv7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-760
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y13zxv7v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0945511752575823 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0619380978228765 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅█▇█▇▇▇▆▆▆▆▆▇▇▇▇▇█▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇█████▇██▇▇▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇██▇█▇████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▇▁▁▁▁▁▄▁▁█▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced devout-sweep-760: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/y13zxv7v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165101-y13zxv7v/logs
2022-09-02 16:52:37,105 - wandb.wandb_agent - INFO - Cleaning up finished run: y13zxv7v
2022-09-02 16:52:37,336 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:52:37,336 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00031880943409768876
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:52:37,354 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00031880943409768876 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:52:42,368 - wandb.wandb_agent - INFO - Running runs: ['5f2zgq4b']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165242-5f2zgq4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-776
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5f2zgq4b
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.250053101759891 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▇▆▆▆▆▆▇▆▆▇▆▆▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▆▇▇▇▇█▇▇█▇██▇█▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁█▁▁▁█▁█▁█▁█▄█▇▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced clear-sweep-776: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5f2zgq4b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165242-5f2zgq4b/logs
2022-09-02 16:54:25,436 - wandb.wandb_agent - INFO - Cleaning up finished run: 5f2zgq4b
2022-09-02 16:54:25,728 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:54:25,728 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01948114634648884
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:54:25,743 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01948114634648884 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:54:30,757 - wandb.wandb_agent - INFO - Running runs: ['lbsiozc5']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165433-lbsiozc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-791
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lbsiozc5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.189598358859882 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0950354905201385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.179390004005685 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ███▇▆▆▅▆▆▆▆▆▅▆▆▆▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▆▇▇▇███▇▇▇▇▇▇▆▇▇███▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▅█▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sandy-sweep-791: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lbsiozc5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165433-lbsiozc5/logs
2022-09-02 16:56:09,072 - wandb.wandb_agent - INFO - Cleaning up finished run: lbsiozc5
2022-09-02 16:56:09,345 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:56:09,345 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03238521511954961
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:56:09,352 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03238521511954961 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:56:14,365 - wandb.wandb_agent - INFO - Running runs: ['b2smd4kn']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165614-b2smd4kn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-808
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b2smd4kn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3225776068991317 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.257600410509836 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4784307929021554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.177183150316112 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▆▇▆▆▇▆▇▆▇▇▇█▇▇█▇███▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▅▁▁▁▅▄▁▁█▁▅▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced worthy-sweep-808: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b2smd4kn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165614-b2smd4kn/logs
2022-09-02 16:57:52,238 - wandb.wandb_agent - INFO - Cleaning up finished run: b2smd4kn
2022-09-02 16:57:52,518 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:57:52,519 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00031944361297509693
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:57:52,525 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00031944361297509693 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:57:57,538 - wandb.wandb_agent - INFO - Running runs: ['824b69fl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165757-824b69fl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-824
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/824b69fl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0103409684592273 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1087728736576796 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.944383227457503 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▄▄▄▄▄▄▄▃▃▃▃▄▄▄▄▄▄▄▄▆█▇▇▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████████████
wandb:  prop_3 ██▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▅▁▁▁▁█▁▁▁▆▇▁████▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.985
wandb:  prop_3 0.0
wandb: prop_NA 0.015
wandb:  reward 0.83716
wandb: 
wandb: Synced comfy-sweep-824: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/824b69fl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165757-824b69fl/logs
2022-09-02 16:59:20,667 - wandb.wandb_agent - INFO - Cleaning up finished run: 824b69fl
2022-09-02 16:59:20,975 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:59:20,975 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001272793339804551
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:59:20,988 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001272793339804551 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:59:26,003 - wandb.wandb_agent - INFO - Running runs: ['bptu5oi9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165925-bptu5oi9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-839
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bptu5oi9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.040620490559646 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3351459871019546 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇███▇▇▇▆▆▇▇▇▇▆▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▆▇▇▇█▇▇██▇▇▆▇███▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ██████▇▇▇▇▇█████▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁█▁▁▁▁▁▁▁█▆█▅▁▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.961
wandb: prop_NA 0.039
wandb:  reward 0.92352
wandb: 
wandb: Synced smooth-sweep-839: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bptu5oi9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165925-bptu5oi9/logs
2022-09-02 17:00:48,393 - wandb.wandb_agent - INFO - Cleaning up finished run: bptu5oi9
2022-09-02 17:00:48,698 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:00:48,698 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.017366651556290285
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:00:48,705 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.017366651556290285 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:00:53,718 - wandb.wandb_agent - INFO - Running runs: ['o8fpv91m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170054-o8fpv91m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-852
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o8fpv91m
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3890931992642344 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0320612949765033 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.216040703512097 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3480918260402395 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.267569939409977 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▇█████▇▇▇▇█▇▇▇▆▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄█▁▁▁▁▁▁▁▁▁▁█▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.969
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.031
wandb:  reward 1.0
wandb: 
wandb: Synced sweet-sweep-852: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o8fpv91m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170054-o8fpv91m/logs
2022-09-02 17:02:17,747 - wandb.wandb_agent - INFO - Cleaning up finished run: o8fpv91m
2022-09-02 17:02:18,033 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:02:18,033 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00025083732315589095
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:02:18,045 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00025083732315589095 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:02:23,057 - wandb.wandb_agent - INFO - Running runs: ['n3sao6lj']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170225-n3sao6lj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-866
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n3sao6lj
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4034180014920836 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2903210880545077 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.87880877955614 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1911767592026328 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▅▅▅▅▆▆▇▆▅▆▅▅▆▆▆▆▆▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁▁█▇▁▁▁▁▁█▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced rural-sweep-866: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n3sao6lj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170225-n3sao6lj/logs
2022-09-02 17:04:01,288 - wandb.wandb_agent - INFO - Cleaning up finished run: n3sao6lj
2022-09-02 17:04:01,672 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:04:01,679 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003255549099068231
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:04:01,694 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003255549099068231 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:04:06,706 - wandb.wandb_agent - INFO - Running runs: ['bytzzcpf']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170411-bytzzcpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-882
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bytzzcpf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.308843666471209 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.352742379497305 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.662577266182245 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3460493856980276 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▆▇▇▆▇▇▆▆▆▆▇▆▆▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▆▆▆▆▆▆▆▇▆▆▆▆▅▅▅▆▆█▇▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▅█▁█▁▁▁▁▁▁█▁▁▁█▁▁▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.983
wandb: prop_NA 0.017
wandb:  reward 0.92352
wandb: 
wandb: Synced rare-sweep-882: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bytzzcpf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170411-bytzzcpf/logs
2022-09-02 17:05:41,542 - wandb.wandb_agent - INFO - Cleaning up finished run: bytzzcpf
2022-09-02 17:05:41,874 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:05:41,874 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005298071282284864
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:05:41,884 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005298071282284864 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:05:46,896 - wandb.wandb_agent - INFO - Running runs: ['rsoe323r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170547-rsoe323r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-898
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rsoe323r
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2053679577027805 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2941527022573003 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.335501874841592 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.244342557135766 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.105343427164442 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.150745015731315 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.29230852499982 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▃▃▃▃▃▂▂▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▃▅▆▇██
wandb:  prop_2 ██▇▇▇▇▆▅▆▅▆▇▇▇▇▆▆▅▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████▇▇▇▇▆▅▄▄▄
wandb: prop_NA ▇▇▇▇▇▇█████▇▇▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁█▁▁▁▁▁▁▁▁▁▁▇█▁▄▅▄▄▆█▅██████▇▆██▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.518
wandb:  prop_2 0.0
wandb:  prop_3 0.47
wandb: prop_NA 0.012
wandb:  reward 1.0
wandb: 
wandb: Synced bright-sweep-898: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rsoe323r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170547-rsoe323r/logs
2022-09-02 17:07:15,585 - wandb.wandb_agent - INFO - Cleaning up finished run: rsoe323r
2022-09-02 17:07:15,933 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:07:15,934 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.002900694078398335
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:07:15,951 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.002900694078398335 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:07:20,966 - wandb.wandb_agent - INFO - Running runs: ['n65i8sou']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170720-n65i8sou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-913
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n65i8sou
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0716092558150656 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.151218774623863 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.539897395793172 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4265661320571903 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4339833694227044 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▆▆▇▇▇▇▆▇▇▇▇▆▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▇▇▆▆▆▆▆▇▆▆▆▆▆▆▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ▇████████▇▇█████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▁▃▁▆█▁▁▁▁▅▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dazzling-sweep-913: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n65i8sou
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170720-n65i8sou/logs
2022-09-02 17:08:43,429 - wandb.wandb_agent - INFO - Cleaning up finished run: n65i8sou
2022-09-02 17:08:43,720 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:08:43,721 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00041041332348845053
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:08:43,751 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00041041332348845053 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:08:48,770 - wandb.wandb_agent - INFO - Running runs: ['g1tvrjyk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170850-g1tvrjyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-927
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g1tvrjyk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.087710482357712 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.639828551858039 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0566469804190386 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▇▆▆▆▆▆▅▆▅▆▆▇▇▇▆▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▇█▁▁▁▁▁▁▁█▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced vital-sweep-927: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g1tvrjyk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170850-g1tvrjyk/logs
2022-09-02 17:10:15,703 - wandb.wandb_agent - INFO - Cleaning up finished run: g1tvrjyk
2022-09-02 17:10:15,975 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:10:15,976 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0004972411802488711
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:10:15,988 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0004972411802488711 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:10:21,001 - wandb.wandb_agent - INFO - Running runs: ['prl898zm']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171021-prl898zm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-939
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/prl898zm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3196321158323068 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.22892877972242 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1278652864329284 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.728024833878099 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▃▄▆▇███▇▇▇▇▇
wandb:  prop_2 ▇▇▇▇████▇▇▇▇▇▇▇▇▇▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███▇▇▆▅▄▃▃▃▃▄▄▄▄
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁█▁█▁▁▁▁▁▁▁▁▅▄▄▆█▅████▇█▇▆▇█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.53
wandb:  prop_2 0.0
wandb:  prop_3 0.464
wandb: prop_NA 0.006
wandb:  reward 1.0
wandb: 
wandb: Synced rural-sweep-939: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/prl898zm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171021-prl898zm/logs
2022-09-02 17:11:43,466 - wandb.wandb_agent - INFO - Cleaning up finished run: prl898zm
2022-09-02 17:11:43,766 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:11:43,766 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011050627987605444
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:11:43,779 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011050627987605444 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:11:48,791 - wandb.wandb_agent - INFO - Running runs: ['jv1rtdzg']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171150-jv1rtdzg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-954
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jv1rtdzg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.269931933953549 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.475429187158869 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▇▇▇▇▆▆▆▆▆▆▆▇▆▆▆▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▅▆▇██████████
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▇██▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▂▁▁▁▁▇▂█▁▅▅▁▁▁▁▅▄▄▆▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced blooming-sweep-954: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jv1rtdzg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171150-jv1rtdzg/logs
2022-09-02 17:13:21,686 - wandb.wandb_agent - INFO - Cleaning up finished run: jv1rtdzg
2022-09-02 17:13:21,971 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:13:21,972 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00018292727150413343
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:13:21,987 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00018292727150413343 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:13:27,003 - wandb.wandb_agent - INFO - Running runs: ['7zcoach6']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171329-7zcoach6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-968
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7zcoach6
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1592216115339866 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.066096351738909 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.437725787704244 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.306781596895877 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.014730187153897 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇██▇██████▇▇▇▇██▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▆▇▇▇▇█████▇▇▇▆▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▃▁▁▁▁▁▆██▄▁▅▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced spring-sweep-968: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7zcoach6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171329-7zcoach6/logs
2022-09-02 17:15:04,944 - wandb.wandb_agent - INFO - Cleaning up finished run: 7zcoach6
2022-09-02 17:15:05,245 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:15:05,246 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.03612830368524639
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:15:05,280 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.03612830368524639 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:15:10,297 - wandb.wandb_agent - INFO - Running runs: ['kwyq9bdv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171512-kwyq9bdv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-984
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kwyq9bdv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1503443052003886 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1791371974505167 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.671083576714357 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2152000132553806 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.44440961581096 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.231344683439459 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇█▇██▇▇▇▆▇▆▆▆▆▇▇▆▆▆▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▆▆▇▇▇▇▆▆▆▇▆▆▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇██████████▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁▂▁▁██▁▁▁▁▁▁▁▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced happy-sweep-984: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kwyq9bdv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171512-kwyq9bdv/logs
2022-09-02 17:16:48,243 - wandb.wandb_agent - INFO - Cleaning up finished run: kwyq9bdv
2022-09-02 17:16:48,518 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:16:48,518 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.009968290152652992
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:16:48,524 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.009968290152652992 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:16:53,539 - wandb.wandb_agent - INFO - Running runs: ['og3hwdbt']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171652-og3hwdbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-1001
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/og3hwdbt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1663159433886188 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.435215773076208 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.171342543253561 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.253490257591199 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.359646837954682 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5175025034085055 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▆▇▇▆▇▆▇▇▇▇▆▆▆▆▇▇██▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▆▆▆▆▇██▇▇▆▆▆▆▆▆▆▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██████▇▇▇▇▇█▇▇▇█▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▁▁▁▁▁▁▁▅▅▁▇▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced earthy-sweep-1001: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/og3hwdbt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171652-og3hwdbt/logs
2022-09-02 17:18:21,123 - wandb.wandb_agent - INFO - Cleaning up finished run: og3hwdbt
2022-09-02 17:18:21,395 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:18:21,395 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.03820072513160826
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:18:21,401 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.03820072513160826 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:18:26,420 - wandb.wandb_agent - INFO - Running runs: ['th9a3ure']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171825-th9a3ure
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-1016
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/th9a3ure
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.016970716346515 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.547961916266499 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441560263422136 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▆▆▆▆▇███▇▇▇▆▆▆▆▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇█▇▇▇▆▆▆▆▆▇███▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA █████████████▇██████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▅▁▁▅▁▆█▁▅█▁▄▁▁▇█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced splendid-sweep-1016: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/th9a3ure
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171825-th9a3ure/logs
2022-09-02 17:19:54,056 - wandb.wandb_agent - INFO - Cleaning up finished run: th9a3ure
2022-09-02 17:19:54,342 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:19:54,342 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.019577067002253288
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:19:54,350 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.019577067002253288 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:19:59,362 - wandb.wandb_agent - INFO - Running runs: ['w9p7k141']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171959-w9p7k141
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-1031
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w9p7k141
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2573394312084525 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4727985206479963 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4523790176721354 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.200678559605816 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.329610546407067 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▆▆▆▇▇▇▇█▇▇▇▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▆▇▇▇▇▇▆▆▆▇▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▃▅▁▁▁▁█▁█▁▁▁█▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced whole-sweep-1031: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w9p7k141
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171959-w9p7k141/logs
2022-09-02 17:21:37,498 - wandb.wandb_agent - INFO - Cleaning up finished run: w9p7k141
2022-09-02 17:21:37,795 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:21:37,796 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0022292538676961533
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:21:37,801 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0022292538676961533 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:21:42,815 - wandb.wandb_agent - INFO - Running runs: ['xzk0vqqy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172142-xzk0vqqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-1047
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xzk0vqqy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4201141758248865 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.237967138766668 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.000758608102707 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.531841729616338 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.451160806879677 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.639046918938531 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▇██▇▇▆▇▇▇▆▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▇▇▇██▇▇▇▇▇▇███▇▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ███████▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▂█▁▁▁▁█▁▁▅▁▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced smart-sweep-1047: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xzk0vqqy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172142-xzk0vqqy/logs
2022-09-02 17:23:05,273 - wandb.wandb_agent - INFO - Cleaning up finished run: xzk0vqqy
2022-09-02 17:23:05,538 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:23:05,538 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0108146485378721
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:23:05,544 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0108146485378721 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:23:10,558 - wandb.wandb_agent - INFO - Running runs: ['653gk391']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172310-653gk391
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-1062
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/653gk391
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.009040896522175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.541959349828464 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4871483807969743 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.224247899894099 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.771064321809107 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▆▆▇▇▇▇▇▇▇███▇▆▆▆▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇█▇▇▇▇▆▆▆▇▇▇▇▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █████████████▇█████▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁█▁▁▅█▁▁▁▁▁▁▁▁▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced comic-sweep-1062: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/653gk391
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172310-653gk391/logs
2022-09-02 17:24:38,212 - wandb.wandb_agent - INFO - Cleaning up finished run: 653gk391
2022-09-02 17:24:38,513 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:24:38,513 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.026586022032353544
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:24:38,519 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.026586022032353544 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:24:43,532 - wandb.wandb_agent - INFO - Running runs: ['h0dw9e49']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172442-h0dw9e49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-1076
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h0dw9e49
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0143585788310694 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0016981434624848 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4570229110923667 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇██▇█▇▇▇▆▆▆▆▇▇▇█▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▅▆▆▇█▇█████▇▇▇▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄▁▁▁▁▁▁▅▆▁▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dashing-sweep-1076: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h0dw9e49
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172442-h0dw9e49/logs
2022-09-02 17:26:03,621 - wandb.wandb_agent - INFO - Cleaning up finished run: h0dw9e49
2022-09-02 17:26:03,942 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:26:03,942 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00022770393302884036
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:26:03,958 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00022770393302884036 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:26:08,971 - wandb.wandb_agent - INFO - Running runs: ['v06b0k47']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172609-v06b0k47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-1089
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v06b0k47
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.278544008212017 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0677042554697564 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2765724779807988 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▆▆▇▇█████▇█▇▇▇▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced sandy-sweep-1089: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v06b0k47
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172609-v06b0k47/logs
2022-09-02 17:27:36,600 - wandb.wandb_agent - INFO - Cleaning up finished run: v06b0k47
2022-09-02 17:27:36,906 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:27:36,906 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0020722510487318877
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:27:36,928 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0020722510487318877 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:27:41,941 - wandb.wandb_agent - INFO - Running runs: ['f2lpohfm']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172744-f2lpohfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-1103
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f2lpohfm
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1998293199663816 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2706081822929347 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.164798464057579 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇█▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▇▇▆▆▇▇▇▇▇▇▇███▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇████████████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁█▁█▁▁▁▁▁▁▁█▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced generous-sweep-1103: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/f2lpohfm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172744-f2lpohfm/logs
2022-09-02 17:29:09,639 - wandb.wandb_agent - INFO - Cleaning up finished run: f2lpohfm
2022-09-02 17:29:09,918 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:29:09,918 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001736990330796343
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:29:09,931 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001736990330796343 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:29:14,946 - wandb.wandb_agent - INFO - Running runs: ['0dk6zwfy']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172917-0dk6zwfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-1118
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0dk6zwfy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2300193085532336 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3303383900553913 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0043327948820417 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███████▇▅▃▂▁▁▁▁▁
wandb:  prop_2 ▇▆▆▇▇██▇▇▇▆▇█▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▄▅▇█████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▂▁▁▁▁█▁▁█▁▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇█▇▆██▃▅▇█
wandb: 
wandb: Run summary:
wandb:  prop_1 0.093
wandb:  prop_2 0.0
wandb:  prop_3 0.907
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced quiet-sweep-1118: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0dk6zwfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172917-0dk6zwfy/logs
2022-09-02 17:30:42,541 - wandb.wandb_agent - INFO - Cleaning up finished run: 0dk6zwfy
2022-09-02 17:30:42,849 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:30:42,873 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.003626431789316879
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:30:42,887 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.003626431789316879 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:30:47,901 - wandb.wandb_agent - INFO - Running runs: ['6ralbc3k']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173048-6ralbc3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-1133
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6ralbc3k
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2180761170430134 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4865371131286267 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3209244155005124 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4154878108416633 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1683317515193044 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.491815578911233 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆████▇▇▆▆▇▇▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▇▇▇▇▇▇▇▇███▇▆▆▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇████████████▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁█▁▁▁▁▅█▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced warm-sweep-1133: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6ralbc3k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173048-6ralbc3k/logs
2022-09-02 17:32:15,343 - wandb.wandb_agent - INFO - Cleaning up finished run: 6ralbc3k
2022-09-02 17:32:15,660 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:32:15,661 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0003441822263103369
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:32:15,688 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0003441822263103369 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:32:20,703 - wandb.wandb_agent - INFO - Running runs: ['iy10dfen']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173222-iy10dfen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-1148
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iy10dfen
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4310107386682454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0307056812748385 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1940632641923505 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1890296011970216 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇█████████████▇▇▇
wandb:  prop_2 ▇█▇████▇▇▇█▇▇▇▆▇▇▇▇▆▆▄▃▁▁▁▁▁▁▁▁▂▃▄▄▄▄▄▅▅
wandb:  prop_3 █▇▆▆▆▆▆▇▆▆▆▆▆▆▆▆▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁█▁█▁▁▁▇▅█▁▄▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▄▂▄▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.912
wandb:  prop_2 0.082
wandb:  prop_3 0.0
wandb: prop_NA 0.006
wandb:  reward 1.0
wandb: 
wandb: Synced clean-sweep-1148: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iy10dfen
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173222-iy10dfen/logs
2022-09-02 17:33:58,956 - wandb.wandb_agent - INFO - Cleaning up finished run: iy10dfen
2022-09-02 17:33:59,245 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:33:59,245 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0004264960054298211
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:33:59,252 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0004264960054298211 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:34:04,263 - wandb.wandb_agent - INFO - Running runs: ['c2p3phkt']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173404-c2p3phkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-1164
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c2p3phkt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3417255610745307 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4098089013109623 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.32991772094052 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▆▅▅▆▅▅▆▅▆▆▆▆▆▆▆▅▆▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▆▆▆▆▆▆▆▇▇▆▆▆▆▆▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▁▁█▁▄▁▁▁▇▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.997
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.003
wandb:  reward 1.0
wandb: 
wandb: Synced logical-sweep-1164: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c2p3phkt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173404-c2p3phkt/logs
2022-09-02 17:35:31,959 - wandb.wandb_agent - INFO - Cleaning up finished run: c2p3phkt
2022-09-02 17:35:32,269 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:35:32,269 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.009003967713692062
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:35:32,294 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.009003967713692062 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:35:37,313 - wandb.wandb_agent - INFO - Running runs: ['pkxoj0ry']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173537-pkxoj0ry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-1177
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pkxoj0ry
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.432423097025323 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2025456607750518 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.637456124956069 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▆▆▆▆▇▇▇████▇▆▆▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▆▇▇▇▇▇▇▇▇▇█████▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▁▇▁▅▆▁▅▁▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced sweepy-sweep-1177: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pkxoj0ry
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173537-pkxoj0ry/logs
2022-09-02 17:37:04,958 - wandb.wandb_agent - INFO - Cleaning up finished run: pkxoj0ry
2022-09-02 17:37:05,288 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:37:05,289 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004295464432397136
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:37:05,329 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004295464432397136 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:37:10,344 - wandb.wandb_agent - INFO - Running runs: ['8rok37gd']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173712-8rok37gd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-1192
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8rok37gd
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3157719484578188 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.627865218646684 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3402601504527367 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.945716138465497 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆███▇▇▇▇███▇▇▇▇██▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▇▇▇▇▆▆▆▆▆▇▇▆▆▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▄▄▁▁▁▁▇▁▆▁▁█▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced different-sweep-1192: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8rok37gd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173712-8rok37gd/logs
2022-09-02 17:38:39,966 - wandb.wandb_agent - INFO - Cleaning up finished run: 8rok37gd
2022-09-02 17:38:40,250 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:38:40,250 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0007495784207578658
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:38:40,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0007495784207578658 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:38:45,270 - wandb.wandb_agent - INFO - Running runs: ['w2uacm9a']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173845-w2uacm9a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-1208
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w2uacm9a
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2422370776856813 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.405520966556173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4840903534800356 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇████▇▇▇▇▇█▇▇▇▆▇▆▆▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇████▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇███████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆██▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.998
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.002
wandb:  reward 1.0
wandb: 
wandb: Synced jolly-sweep-1208: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w2uacm9a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173845-w2uacm9a/logs
2022-09-02 17:40:12,942 - wandb.wandb_agent - INFO - Cleaning up finished run: w2uacm9a
2022-09-02 17:40:13,213 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:40:13,214 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.006623969017533241
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:40:13,219 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.006623969017533241 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:40:18,232 - wandb.wandb_agent - INFO - Running runs: ['znho5x76']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174019-znho5x76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-1222
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/znho5x76
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.489025420547213 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6925100767502546 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3382489177640102 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.170514537369215 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0014635113390935 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▆▆▆▇█▇▇▇▆▇▇▇▇▇███▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 █▇▆▇▇▇▇▇▇▆▇▇▆▇▇▇▇▆▆▆▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁██▁▁▁▁▂▁▆▁▁▁▁█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced northern-sweep-1222: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/znho5x76
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174019-znho5x76/logs
2022-09-02 17:41:46,362 - wandb.wandb_agent - INFO - Cleaning up finished run: znho5x76
2022-09-02 17:41:46,639 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:41:46,639 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0013194492445871512
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:41:46,667 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0013194492445871512 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:41:51,682 - wandb.wandb_agent - INFO - Running runs: ['kg56iivv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174153-kg56iivv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-1237
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kg56iivv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.257451448233323 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2071379054099522 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6581863994556505 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2479589794266976 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1301659227391814 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇██▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇█▁▆█▁█▁▁▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced firm-sweep-1237: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kg56iivv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174153-kg56iivv/logs
2022-09-02 17:43:25,221 - wandb.wandb_agent - INFO - Cleaning up finished run: kg56iivv
2022-09-02 17:43:25,523 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:43:25,523 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005246507120742213
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:43:25,530 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005246507120742213 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:43:30,543 - wandb.wandb_agent - INFO - Running runs: ['rz6f9qrb']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174330-rz6f9qrb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-1256
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rz6f9qrb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2033580477403185 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.593521577051383 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0420857767020846 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.568794664828302 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4943928359661447 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████▇▆▅▄▃▂▂▃▃▃▃▃
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▃▅▆███▇▇▆▆▆
wandb:  prop_3 █▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃
wandb:  reward ▁▁▁▁▇▁▁▁▁▁▁▇▁▁▅▁▁▇▁▁█▃▅▅▆▂▇▂▅▆▁▄██▁█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.321
wandb:  prop_2 0.458
wandb:  prop_3 0.0
wandb: prop_NA 0.221
wandb:  reward 0.83716
wandb: 
wandb: Synced young-sweep-1256: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rz6f9qrb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174330-rz6f9qrb/logs
2022-09-02 17:45:03,324 - wandb.wandb_agent - INFO - Cleaning up finished run: rz6f9qrb
2022-09-02 17:45:03,616 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:45:03,617 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04168199283252906
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:45:03,622 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04168199283252906 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:45:08,634 - wandb.wandb_agent - INFO - Running runs: ['p0x2c63k']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174510-p0x2c63k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-1271
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/p0x2c63k
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.402858275884636 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.621014704431031 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.037776917434955 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.542668092932477 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3422104567428375 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.443626891900423 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▇▇▇████▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ███████▇▇▇▇█████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁▅▁▁▁▁▁█▁▁█▁▅▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced sparkling-sweep-1271: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/p0x2c63k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174510-p0x2c63k/logs
2022-09-02 17:46:36,321 - wandb.wandb_agent - INFO - Cleaning up finished run: p0x2c63k
2022-09-02 17:46:36,638 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:46:36,639 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00010378043114213286
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:46:36,645 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00010378043114213286 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:46:41,658 - wandb.wandb_agent - INFO - Running runs: ['3ldmnmsq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174642-3ldmnmsq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-1283
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3ldmnmsq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.274717873218912 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.403663988603777 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.521885592716911 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3589769820356623 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.926625877330967 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.351363155513844 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.652124534068311 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▇▇████▇▇▇█████▇▇▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇██▇▇▆▆▇▇▇▇███▇▇▇▆▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▁▃▁█▇█▄▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced splendid-sweep-1283: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/3ldmnmsq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174642-3ldmnmsq/logs
2022-09-02 17:48:09,428 - wandb.wandb_agent - INFO - Cleaning up finished run: 3ldmnmsq
2022-09-02 17:48:09,711 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:48:09,711 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.02437115143084546
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:48:09,735 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.02437115143084546 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:48:14,750 - wandb.wandb_agent - INFO - Running runs: ['kacg4fcx']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174814-kacg4fcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-1299
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kacg4fcx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.038464384908505 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.782547798109947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0352731061789013 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.731410111099768 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0358391801472564 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.380954587569642 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █████▇▇▆▆▆▆▇▆▆▆▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇▇▇▇███████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁█▅▁▄▇█▄█▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dutiful-sweep-1299: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kacg4fcx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174814-kacg4fcx/logs
2022-09-02 17:49:52,776 - wandb.wandb_agent - INFO - Cleaning up finished run: kacg4fcx
2022-09-02 17:49:53,079 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:49:53,079 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.010823874357800536
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:49:53,090 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.010823874357800536 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:49:58,103 - wandb.wandb_agent - INFO - Running runs: ['sejxwlkh']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174957-sejxwlkh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-1321
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sejxwlkh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0711854599398207 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1585860371022765 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.368969162337409 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3537164235471675 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3711259751964127 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.368068305503334 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▇██▇▇▇▇▇▇▇███▇▇▇▇█▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▅▁▁▁█▁▁▁▁▁▅▅▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced lemon-sweep-1321: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sejxwlkh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174957-sejxwlkh/logs
2022-09-02 17:51:31,843 - wandb.wandb_agent - INFO - Cleaning up finished run: sejxwlkh
2022-09-02 17:51:32,163 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:51:32,163 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.015682871964563305
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:51:32,180 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.015682871964563305 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:51:37,194 - wandb.wandb_agent - INFO - Running runs: ['bailak12']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175137-bailak12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-1336
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bailak12
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0010699888559547 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.983971377941451 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.068291740243029 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0033545974512394 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.150961884743994 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.868073965040916 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▅▅▅▅▅▆▅▅▆▅▆▆▆▆▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▇▇▇██▇▇▆▆▆▆▆▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▇▁▁▁▁▁▁█▁▁▁▁▇▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced grateful-sweep-1336: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bailak12
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175137-bailak12/logs
2022-09-02 17:53:10,033 - wandb.wandb_agent - INFO - Cleaning up finished run: bailak12
2022-09-02 17:53:10,655 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:53:10,655 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0024253164166117883
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:53:10,663 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0024253164166117883 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:53:15,675 - wandb.wandb_agent - INFO - Running runs: ['b7886e4d']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175315-b7886e4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1351
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b7886e4d
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0922475917229004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.347595038954608 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇█▇▇▇▆▇▇▇▇▇▇▇█▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆████▇▇▇▇▇█████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▃█▁▁▂▄▆█▁▁▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced copper-sweep-1351: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b7886e4d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175315-b7886e4d/logs
2022-09-02 17:54:38,268 - wandb.wandb_agent - INFO - Cleaning up finished run: b7886e4d
2022-09-02 17:54:38,585 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:54:38,585 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.003328751025800828
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:54:38,591 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.003328751025800828 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:54:43,605 - wandb.wandb_agent - INFO - Running runs: ['l0bf9tiw']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175444-l0bf9tiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-1366
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l0bf9tiw
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.067461403112791 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.213219175224408 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4123404268084876 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▆▇▇██▇▇▆▆▇▇▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆██▇█▇▇███▇▇▇▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ███▇██████▇▇▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▁▃▁▁▁▁▁▁▁▁▁▆▅█▇▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fragrant-sweep-1366: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/l0bf9tiw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175444-l0bf9tiw/logs
2022-09-02 17:56:06,283 - wandb.wandb_agent - INFO - Cleaning up finished run: l0bf9tiw
2022-09-02 17:56:06,588 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:56:06,588 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.002000693994645454
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:56:06,609 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.002000693994645454 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:56:11,625 - wandb.wandb_agent - INFO - Running runs: ['xvlcr938']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175610-xvlcr938
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-1381
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xvlcr938
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.23625416111516 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.387481828628742 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.996695643680504 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.355856009461282 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.141478945315384 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4972715816778357 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇▇▇▇██▇▆▆▆▆▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████▇███████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁█▁▄▁▁▄▁▁▁▁▁▁▁▁▃█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.959
wandb: prop_NA 0.041
wandb:  reward 0.92352
wandb: 
wandb: Synced vibrant-sweep-1381: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xvlcr938
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175610-xvlcr938/logs
2022-09-02 17:57:34,208 - wandb.wandb_agent - INFO - Cleaning up finished run: xvlcr938
2022-09-02 17:57:34,512 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:57:34,512 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.005208798152648607
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:57:34,523 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.005208798152648607 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:57:39,537 - wandb.wandb_agent - INFO - Running runs: ['i00swar4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175739-i00swar4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-1394
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i00swar4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.477568803293387 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.996073732805212 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.35341185523245 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2447279029357006 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.223177850850418 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 █▇▇▇▆▆▆▆▅▅▅▆▆▆▆▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▆▆▆▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁█▇▁█▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced lyric-sweep-1394: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i00swar4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175739-i00swar4/logs
2022-09-02 17:59:12,729 - wandb.wandb_agent - INFO - Cleaning up finished run: i00swar4
2022-09-02 17:59:13,275 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:59:13,275 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0003794818575338735
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:59:13,278 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0003794818575338735 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:59:18,292 - wandb.wandb_agent - INFO - Running runs: ['g2u0k6cl']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175918-g2u0k6cl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-1410
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g2u0k6cl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.029724869029751 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.154412655484078 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.066917463678336 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.998762396841422 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.204239614051615 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.460016121978744 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▆▇▇▇██▇▇▇▇▇█▇▇▇▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▇▇▇▇▇▇▇████▇█▇▆▆▆█▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇█▁█▁▁▅▁▁▁█▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.959
wandb: prop_NA 0.041
wandb:  reward 0.92352
wandb: 
wandb: Synced lunar-sweep-1410: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g2u0k6cl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175918-g2u0k6cl/logs
2022-09-02 18:00:40,921 - wandb.wandb_agent - INFO - Cleaning up finished run: g2u0k6cl
2022-09-02 18:00:41,223 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:00:41,224 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.011134047366847928
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:00:41,229 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.011134047366847928 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:00:46,248 - wandb.wandb_agent - INFO - Running runs: ['wyahk8p8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180046-wyahk8p8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-1424
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wyahk8p8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4551220103443225 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.426240235423597 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0874355553860138 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1601742143537015 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ███▇▇▇▇▇▇▇▇▇█▇▆▇▇██▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁█▁▁▁▁▁▁█▁▁▁▁▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced eager-sweep-1424: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wyahk8p8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180046-wyahk8p8/logs
2022-09-02 18:02:24,331 - wandb.wandb_agent - INFO - Cleaning up finished run: wyahk8p8
2022-09-02 18:02:24,654 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:02:24,655 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04383362279771386
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:02:24,660 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04383362279771386 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:02:29,677 - wandb.wandb_agent - INFO - Running runs: ['dtthc7n1']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180229-dtthc7n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-1439
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dtthc7n1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.350424142971074 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▆▆▇▆▇▇▆▇▆▆▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇██████████████▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁█▁▇▁▁▁▁▁▁█▁▁▅▁▇▇█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced graceful-sweep-1439: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dtthc7n1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180229-dtthc7n1/logs
2022-09-02 18:03:58,415 - wandb.wandb_agent - INFO - Cleaning up finished run: dtthc7n1
2022-09-02 18:03:59,461 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:03:59,461 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.04174124802513118
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:03:59,467 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.04174124802513118 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:04:04,505 - wandb.wandb_agent - INFO - Running runs: ['x9rshxlk']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180406-x9rshxlk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-1453
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x9rshxlk
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3992773752474457 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2683793559622747 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇███▇▆▆▇▇█████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆▇▇▇▇▇▇▇▇██▇▇▇▇█▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▇▁▁▁▇▁██▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced divine-sweep-1453: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/x9rshxlk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180406-x9rshxlk/logs
2022-09-02 18:05:37,541 - wandb.wandb_agent - INFO - Cleaning up finished run: x9rshxlk
2022-09-02 18:05:37,826 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:05:37,826 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0007119898593021092
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:05:37,832 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0007119898593021092 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:05:42,848 - wandb.wandb_agent - INFO - Running runs: ['tg1jngs4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180542-tg1jngs4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-1470
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tg1jngs4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.421774374737548 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▇▇████▇▇▇▆▆▇▇▇█▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▇▇▇██▇▇█▇██▇▇▆▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▁▇▁▅▆█▁▁▁█▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced silvery-sweep-1470: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tg1jngs4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180542-tg1jngs4/logs
2022-09-02 18:07:15,763 - wandb.wandb_agent - INFO - Cleaning up finished run: tg1jngs4
2022-09-02 18:07:16,076 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:07:16,076 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0002142231821145953
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:07:16,082 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0002142231821145953 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:07:21,096 - wandb.wandb_agent - INFO - Running runs: ['hex8v1wq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180722-hex8v1wq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-1484
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hex8v1wq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.396524778267752 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.026730851613211 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4554398537822433 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.328048486526062 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████▇▇▆▅▅▄▄▄
wandb:  prop_2 ▅▆▇▇▇▇▇▆▇▇▇▇███▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▃▄▅▆▇██
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▄▁▅▁▁▇▁▁█▁▅▁▆▃██▃▅▅▆▂▇▂▅▁▇█▇▆▇█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.441
wandb:  prop_2 0.0
wandb:  prop_3 0.555
wandb: prop_NA 0.004
wandb:  reward 1.0
wandb: 
wandb: Synced morning-sweep-1484: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hex8v1wq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180722-hex8v1wq/logs
2022-09-02 18:08:44,566 - wandb.wandb_agent - INFO - Cleaning up finished run: hex8v1wq
2022-09-02 18:08:44,867 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:08:44,867 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0015012817530965577
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:08:44,907 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0015012817530965577 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:08:49,925 - wandb.wandb_agent - INFO - Running runs: ['huzy46qu']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180852-huzy46qu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-1498
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/huzy46qu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3744477576875185 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0739671519051113 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.41707158025379 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.393328843551412 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.699980067980663 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▇▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇███████▇▇▇▇▇▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▃▅▁▁▁▁▁▁▁▁█▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced comic-sweep-1498: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/huzy46qu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180852-huzy46qu/logs
2022-09-02 18:10:28,589 - wandb.wandb_agent - INFO - Cleaning up finished run: huzy46qu
2022-09-02 18:10:28,947 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:10:28,948 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.011915979640942985
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:10:28,953 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.011915979640942985 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:10:33,968 - wandb.wandb_agent - INFO - Running runs: ['6h9as0w0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181034-6h9as0w0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-1515
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6h9as0w0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1908119276944005 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.068992119386025 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.081412456078457 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4577784174953887 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.990756752191647 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▆▇▇▇▇▇▇▇▇▆▆▆▆▇▇█▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇████▇▇▆▆▆▆▆▆▆▆▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▇▁▇▁▁▁▇▁▁▆▁▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced amber-sweep-1515: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6h9as0w0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181034-6h9as0w0/logs
2022-09-02 18:11:56,581 - wandb.wandb_agent - INFO - Cleaning up finished run: 6h9as0w0
2022-09-02 18:11:56,898 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:11:56,898 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00028698013672543
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:11:56,909 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00028698013672543 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:12:01,925 - wandb.wandb_agent - INFO - Running runs: ['wfo0dt6s']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181203-wfo0dt6s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-1528
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wfo0dt6s
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4648684480830454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2886267820933175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.338741721814108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0584382577027784 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.714940555120976 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2813402893818893 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▇▇▇▆▆▇▇▇█▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▁▁▄▁▁▁▁█▁▇▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced crimson-sweep-1528: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wfo0dt6s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181203-wfo0dt6s/logs
2022-09-02 18:13:29,992 - wandb.wandb_agent - INFO - Cleaning up finished run: wfo0dt6s
2022-09-02 18:13:30,264 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:13:30,264 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0021360484971589093
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:13:30,280 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0021360484971589093 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:13:35,297 - wandb.wandb_agent - INFO - Running runs: ['hy6cgsab']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181337-hy6cgsab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-1543
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hy6cgsab
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.013630525369037 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.452052725465559 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3555903033287056 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1383027482154486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6043005300024324 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▇▇▇▆▆▅▅▆▅▅▅▅▅▅▆▆▆▆▅▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▁▁▇▁█▁▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced polar-sweep-1543: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hy6cgsab
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181337-hy6cgsab/logs
2022-09-02 18:15:03,819 - wandb.wandb_agent - INFO - Cleaning up finished run: hy6cgsab
2022-09-02 18:15:04,153 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:15:04,157 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00029652736584527735
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:15:04,165 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00029652736584527735 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:15:09,181 - wandb.wandb_agent - INFO - Running runs: ['vef8uqgu']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181510-vef8uqgu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-1561
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vef8uqgu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1495150481990324 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.826431534409531 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4890478093931163 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1862851168184747 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3836491986483597 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.697464305794643 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▆▆▆▆▆▆▆▆▇▇▇████▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▇▆▇▇▇████▇▇▇▇▆▆▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▄▁▁▄▁▁▁▁▁▄▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.979
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.021
wandb:  reward 1.0
wandb: 
wandb: Synced warm-sweep-1561: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vef8uqgu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181510-vef8uqgu/logs
2022-09-02 18:16:42,100 - wandb.wandb_agent - INFO - Cleaning up finished run: vef8uqgu
2022-09-02 18:16:42,491 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:16:42,578 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006783631908793853
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:16:42,797 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006783631908793853 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:16:47,857 - wandb.wandb_agent - INFO - Running runs: ['ypla5g7v']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181647-ypla5g7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-1579
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ypla5g7v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0123241346423884 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.915219410458395 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1654413875466467 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.044201574758523 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇███▇▇▇▇█▇█▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▃▃▃▃▂▂▃▃▃▃▃▂▃▃▃▃▂▃▃▂▂▁▁▁▁▂▃▄▆▇██▇▇▇████
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇███▇▆▅▄▄▃▃▄▄▄▄▄▃
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂
wandb:  reward ▁▁▁▁▁▁▁▃▁▁▁▂▁▁▁▁█▁█▇▁▄▄▆█▅████████▁██▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.516
wandb:  prop_3 0.391
wandb: prop_NA 0.093
wandb:  reward 0.92352
wandb: 
wandb: Synced cerulean-sweep-1579: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ypla5g7v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181647-ypla5g7v/logs
2022-09-02 18:18:10,433 - wandb.wandb_agent - INFO - Cleaning up finished run: ypla5g7v
2022-09-02 18:18:10,736 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:18:10,737 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00022041769844886855
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:18:10,882 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00022041769844886855 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:18:15,901 - wandb.wandb_agent - INFO - Running runs: ['egx13gdt']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181816-egx13gdt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-1592
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/egx13gdt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.030111838819119 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.439913607632779 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.017535531979355 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.411016002308591 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.254991463966357 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.819241826288604 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ████▇▇▇▇█▇▇▆▆▅▆▆▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▆▆▇▇█▇▇▆▆▆▆▆▆▆▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ▇▇▇▇▇▇▇▇▇▇██████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▁▁▁▄▁▁▁▇▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced misunderstood-sweep-1592: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/egx13gdt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181816-egx13gdt/logs
2022-09-02 18:19:48,833 - wandb.wandb_agent - INFO - Cleaning up finished run: egx13gdt
2022-09-02 18:19:49,126 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:19:49,127 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0055038785267930435
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:19:49,133 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0055038785267930435 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:19:54,149 - wandb.wandb_agent - INFO - Running runs: ['plutelh4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181952-plutelh4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-1608
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/plutelh4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2462707159322806 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.351505056238497 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.460923710502714 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.383900947069867 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.881698134912881 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▆▆▆▇▇▇▇▇▇█▇▆▆▆▆▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▆▇▇██▇▇▆▇▆▇▇▆▇▇███▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▅▁█▁▁▁▁▁▁▁▁▁▅▄▁▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced magic-sweep-1608: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/plutelh4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181952-plutelh4/logs
2022-09-02 18:21:16,759 - wandb.wandb_agent - INFO - Cleaning up finished run: plutelh4
2022-09-02 18:21:18,970 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:21:18,971 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0009262568872548908
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:21:18,978 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0009262568872548908 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:21:23,992 - wandb.wandb_agent - INFO - Running runs: ['2dguovec']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182123-2dguovec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-1623
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2dguovec
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0369130178464485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2914125781299313 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2974279823738195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.326206880046777 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.613478317936667 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇██▇▇▇▆▇▇█▇▆▇▇▇▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▅▅▆▇▇▇▇▇▇▇███▇█▇████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇██████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇▁▁▅▁▁▁▇▁▆▁▁▁▁█▇▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced blooming-sweep-1623: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2dguovec
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182123-2dguovec/logs
2022-09-02 18:22:56,940 - wandb.wandb_agent - INFO - Cleaning up finished run: 2dguovec
2022-09-02 18:22:57,226 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:22:57,226 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0007162412320182582
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:22:57,235 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0007162412320182582 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:23:02,248 - wandb.wandb_agent - INFO - Running runs: ['ouw4jx0m']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182302-ouw4jx0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-1638
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ouw4jx0m
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.073044823781823 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1047648859461425 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.541436872660677 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4711467585813867 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▆▇▇▇▇▇▇▇███▇▇▆▇▇█▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▅▆▆▆▆▆▇▇▇▇▇▇███▇▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁█▁▁▃▁▁▁▁▁██▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced distinctive-sweep-1638: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ouw4jx0m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182302-ouw4jx0m/logs
2022-09-02 18:24:35,189 - wandb.wandb_agent - INFO - Cleaning up finished run: ouw4jx0m
2022-09-02 18:24:35,527 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:24:35,527 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0015280308831157202
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:24:35,537 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0015280308831157202 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:24:40,551 - wandb.wandb_agent - INFO - Running runs: ['7voc5aqh']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182441-7voc5aqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-1652
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7voc5aqh
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.238763047253929 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2307042252674685 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.673113284065617 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.339010439343201 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▇▇▇▇▆▆▆▇▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 █████▇▇▇▇█▇██▇▇▇███▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁▁▁▇▁██▁▁▁▇▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced rosy-sweep-1652: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7voc5aqh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182441-7voc5aqh/logs
2022-09-02 18:26:08,298 - wandb.wandb_agent - INFO - Cleaning up finished run: 7voc5aqh
2022-09-02 18:26:08,563 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:26:08,564 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0341890453634262
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:26:08,572 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0341890453634262 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:26:13,587 - wandb.wandb_agent - INFO - Running runs: ['p45gbtuj']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182615-p45gbtuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-1667
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/p45gbtuj
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2444619535113937 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.013066140819116 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▇▇▇▆▇▇▇█▇▇▇████▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆█▇▇█▇█▇▇▇▇▇▇█▇▇▇▆▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇██████████▇▇████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▅▁▁▃█▁▁▁▁▁▁▁▁█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced lemon-sweep-1667: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/p45gbtuj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182615-p45gbtuj/logs
2022-09-02 18:27:51,936 - wandb.wandb_agent - INFO - Cleaning up finished run: p45gbtuj
2022-09-02 18:27:52,285 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:27:52,285 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.03397029891987108
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:27:52,296 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.03397029891987108 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:27:57,312 - wandb.wandb_agent - INFO - Running runs: ['2q4irx7d']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182757-2q4irx7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-1682
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2q4irx7d
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1337089047523468 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.292919245040352 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.314666577703285 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▅▆▆▆▇▇▇▇███▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇▄▄▁▁▁▁▁▁▁▁▁█▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.962
wandb: prop_NA 0.038
wandb:  reward 0.92352
wandb: 
wandb: Synced atomic-sweep-1682: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2q4irx7d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182757-2q4irx7d/logs
2022-09-02 18:29:25,039 - wandb.wandb_agent - INFO - Cleaning up finished run: 2q4irx7d
2022-09-02 18:29:25,352 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:29:25,352 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.002440214010148504
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:29:25,361 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.002440214010148504 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:29:30,376 - wandb.wandb_agent - INFO - Running runs: ['6d887it0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182932-6d887it0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-1697
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6d887it0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.390070153749224 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6459879050804815 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇█▇▇▇▆▆▇▇▇▇▆▇▇████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁█▁▁▁█▁▁██▁█▁▁▇▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced stoic-sweep-1697: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6d887it0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182932-6d887it0/logs
2022-09-02 18:31:03,319 - wandb.wandb_agent - INFO - Cleaning up finished run: 6d887it0
2022-09-02 18:31:03,644 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:31:03,645 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.021634518323010644
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:31:03,659 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.021634518323010644 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:31:08,675 - wandb.wandb_agent - INFO - Running runs: ['6ceq7bst']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183108-6ceq7bst
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-1713
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6ceq7bst
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.393328321951314 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.97189996376469 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇██▇▇▇▇▇█▇██▇█▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ███▇▇▆▆▆▆▇▆▆▇▆▆▆▆▆▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▄▁▁▁▁▁▂▁▁▁▁▁▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced devoted-sweep-1713: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6ceq7bst
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183108-6ceq7bst/logs
2022-09-02 18:32:36,200 - wandb.wandb_agent - INFO - Cleaning up finished run: 6ceq7bst
2022-09-02 18:32:36,476 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:32:36,476 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.002365076917259893
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:32:36,488 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.002365076917259893 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:32:41,503 - wandb.wandb_agent - INFO - Running runs: ['2o9t9l4w']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183241-2o9t9l4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-1728
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2o9t9l4w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4688860075635364 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.942039219982894 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4402662784824667 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.110414572998875 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇████▇▇▇▇▇▇▆▆▇▇▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▆▆▆▇▇▇▇▇██████▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁█▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced swept-sweep-1728: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2o9t9l4w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183241-2o9t9l4w/logs
2022-09-02 18:34:09,176 - wandb.wandb_agent - INFO - Cleaning up finished run: 2o9t9l4w
2022-09-02 18:34:09,462 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:34:09,462 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0017049505966423217
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:34:09,484 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0017049505966423217 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:34:14,499 - wandb.wandb_agent - INFO - Running runs: ['tqob5c30']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183414-tqob5c30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-1743
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tqob5c30
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2303573941933945 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3131424328699217 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4698764182503234 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇██▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▇▇▇▇▇▇██▇█▇▇▇▇█▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▇█▄▁▁▅▇▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced silver-sweep-1743: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tqob5c30
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183414-tqob5c30/logs
2022-09-02 18:35:42,125 - wandb.wandb_agent - INFO - Cleaning up finished run: tqob5c30
2022-09-02 18:35:42,447 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:35:42,448 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.010522921866022827
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:35:42,466 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.010522921866022827 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:35:47,483 - wandb.wandb_agent - INFO - Running runs: ['8ylp8ue0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183548-8ylp8ue0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-1758
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8ylp8ue0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3819720626289858 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1963832603914666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.760688904534665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3441160990353285 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▆▆▆▆▆▆▇▇▇▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▇▇████▇█████▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▅▁▁▁▅▁█▁█▁▁▁▁▁▇█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced bumbling-sweep-1758: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8ylp8ue0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183548-8ylp8ue0/logs
2022-09-02 18:37:15,227 - wandb.wandb_agent - INFO - Cleaning up finished run: 8ylp8ue0
2022-09-02 18:37:15,512 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:37:15,512 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005386187014382534
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:37:15,519 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005386187014382534 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:37:20,535 - wandb.wandb_agent - INFO - Running runs: ['yj2nblnb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183720-yj2nblnb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-1773
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yj2nblnb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.328850929201631 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.499915896318013 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.351321251943649 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████▇▇████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▅▂▄▁▁▁█▁▁▁▁▁█▇▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.971
wandb: prop_NA 0.029
wandb:  reward 0.92352
wandb: 
wandb: Synced glad-sweep-1773: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yj2nblnb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183720-yj2nblnb/logs
2022-09-02 18:38:48,329 - wandb.wandb_agent - INFO - Cleaning up finished run: yj2nblnb
2022-09-02 18:38:48,657 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:38:48,658 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00018638245734486813
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:38:48,677 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00018638245734486813 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:38:53,692 - wandb.wandb_agent - INFO - Running runs: ['hojhjaha']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183854-hojhjaha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-1787
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hojhjaha
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.473195809462582 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1853186153533515 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.368534305037396 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇███▇▇▇▇▇▇███▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇████▇▇▇▇▇▇▇▇▇▇██████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇█▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▁▁█▁▄▁▂▁▁▁▁█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.997
wandb:  prop_3 0.0
wandb: prop_NA 0.003
wandb:  reward 0.83716
wandb: 
wandb: Synced legendary-sweep-1787: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hojhjaha
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183854-hojhjaha/logs
2022-09-02 18:40:21,318 - wandb.wandb_agent - INFO - Cleaning up finished run: hojhjaha
2022-09-02 18:40:21,609 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:40:21,609 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.037358836645081606
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:40:21,620 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.037358836645081606 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:40:26,648 - wandb.wandb_agent - INFO - Running runs: ['r6j31a2k']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184027-r6j31a2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-1802
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r6j31a2k
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2802160156648887 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3061608735767907 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.361612377799907 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.935902040945477 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▇▇███████▇▇▇▇▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▆▇▇▇▇▇▇▇▇████▇▇▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████▇▇▇▇▇▇██████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▅▁▁▅▁▁█▁▁▆▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced woven-sweep-1802: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r6j31a2k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184027-r6j31a2k/logs
2022-09-02 18:41:59,432 - wandb.wandb_agent - INFO - Cleaning up finished run: r6j31a2k
2022-09-02 18:41:59,726 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:41:59,727 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0008805610142245627
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:41:59,736 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0008805610142245627 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:42:04,750 - wandb.wandb_agent - INFO - Running runs: ['vy7y9zc5']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184204-vy7y9zc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-1821
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vy7y9zc5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.166981674678772 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3258767411492345 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2880752777652367 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.627461386045446 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.454793744816942 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.308525231215268 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▆▆▆▇▆▆▇▆▇▆▆▆▆▆▅▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▆▆▇▇▇▇▇▆▆▆▆▆▆▆▆▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇█████████████████▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▆██▁▆█▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.996
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.004
wandb:  reward 1.0
wandb: 
wandb: Synced sweepy-sweep-1821: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vy7y9zc5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184204-vy7y9zc5/logs
2022-09-02 18:43:37,548 - wandb.wandb_agent - INFO - Cleaning up finished run: vy7y9zc5
2022-09-02 18:43:37,845 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:43:37,845 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0004965167494327661
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:43:37,852 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0004965167494327661 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:43:42,868 - wandb.wandb_agent - INFO - Running runs: ['praxt361']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184341-praxt361
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-1839
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/praxt361
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.153216876663602 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0671830708396093 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0291810160053267 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆▅▆▆▇▇▇▇▇▇████▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇█▇█▇▇▇▇▇▇▇█▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▂▁▃▁▁▁▇█▁▁▁█▆▁▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced charmed-sweep-1839: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/praxt361
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184341-praxt361/logs
2022-09-02 18:45:10,567 - wandb.wandb_agent - INFO - Cleaning up finished run: praxt361
2022-09-02 18:45:10,849 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:45:10,849 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001150571919129278
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:45:10,865 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001150571919129278 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:45:15,881 - wandb.wandb_agent - INFO - Running runs: ['7vleeafv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184514-7vleeafv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-1853
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7vleeafv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3900477395862505 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.420540994349927 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1765606599216154 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.519700606594141 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2835711984264107 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▃▃▂▂▂▂▂▂▂▂▂▃▃▃▃▂▂▂▂▂▁▁▁▁▂▄▆▇█▇▇█████▇█
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██▇▆▅▄▄▄▄▄▄▄▄▄▄▄
wandb:  prop_3 ▅▆▇▇▇█▇▇▇▇▇▇▆▆▇▇▇▇▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▇▂███▇█▇▆▅▆▇▄██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.477
wandb:  prop_2 0.519
wandb:  prop_3 0.0
wandb: prop_NA 0.004
wandb:  reward 1.0
wandb: 
wandb: Synced summer-sweep-1853: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7vleeafv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184514-7vleeafv/logs
2022-09-02 18:46:38,502 - wandb.wandb_agent - INFO - Cleaning up finished run: 7vleeafv
2022-09-02 18:46:38,925 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:46:38,925 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001915582395064031
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:46:38,942 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001915582395064031 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:46:43,957 - wandb.wandb_agent - INFO - Running runs: ['uo40u5rx']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184643-uo40u5rx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-1868
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uo40u5rx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1313161882575615 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.903094271182315 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3399841658162837 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3267459157372885 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.34359643487965 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 █▇▇▇▆▆▆▆▇▇██▇▆▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▄▆▆▆▆▆▇▆▆▆▆▆▆▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▅▁█▁▁▆▁▁█▁▁▁█▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.954
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.046
wandb:  reward 1.0
wandb: 
wandb: Synced icy-sweep-1868: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uo40u5rx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184643-uo40u5rx/logs
2022-09-02 18:48:06,995 - wandb.wandb_agent - INFO - Cleaning up finished run: uo40u5rx
2022-09-02 18:48:07,299 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:48:07,299 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.007052838104888764
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:48:07,306 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.007052838104888764 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:48:12,321 - wandb.wandb_agent - INFO - Running runs: ['h2aqsc7s']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184811-h2aqsc7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-1881
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h2aqsc7s
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.32023924684932 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.221889110244145 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4730532250994934 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.078594046918912 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▆▆▇▇██▇█████▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁█▁▁▁▁▁▁█▁█▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.965
wandb: prop_NA 0.035
wandb:  reward 0.92352
wandb: 
wandb: Synced flowing-sweep-1881: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h2aqsc7s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184811-h2aqsc7s/logs
2022-09-02 18:49:35,032 - wandb.wandb_agent - INFO - Cleaning up finished run: h2aqsc7s
2022-09-02 18:49:35,390 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:49:35,391 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00695135408389237
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:49:35,404 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00695135408389237 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:49:40,419 - wandb.wandb_agent - INFO - Running runs: ['w1gn36qy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184939-w1gn36qy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-1895
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w1gn36qy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.425654633964253 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.280390980369755 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.137866960132342 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.297788572411891 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0608687047588043 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇██▇▇▇███▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▅▆▇███▇▇▇▇██▇██▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇▇▇█▇██▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▅▁█▁█▁▁▁▅█▁▁█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced resilient-sweep-1895: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w1gn36qy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184939-w1gn36qy/logs
2022-09-02 18:51:08,061 - wandb.wandb_agent - INFO - Cleaning up finished run: w1gn36qy
2022-09-02 18:51:08,381 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:51:08,382 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.002420709821516135
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:51:08,392 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.002420709821516135 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:51:13,415 - wandb.wandb_agent - INFO - Running runs: ['23kxk1dt']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185112-23kxk1dt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-1910
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/23kxk1dt
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.030573456995077 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5407642994709825 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3044921560378837 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5021212570639655 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1101852184090104 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.160441666005287 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▇▇█▇▇█▇▇▇▆▇▇██▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▅▇▆▆▆▆▆▆▇▇███▇▇▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ████▇▇█▇█▇▇▇█▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁█▁▂▁█▁█▇▁▁▁▅▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced rose-sweep-1910: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/23kxk1dt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185112-23kxk1dt/logs
2022-09-02 18:52:35,981 - wandb.wandb_agent - INFO - Cleaning up finished run: 23kxk1dt
2022-09-02 18:52:36,297 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:52:36,297 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.041228767837187194
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:52:36,311 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.041228767837187194 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:52:41,327 - wandb.wandb_agent - INFO - Running runs: ['lnn1x2cd']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185240-lnn1x2cd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-1924
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lnn1x2cd
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.193660272817667 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.721074342570578 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4306894084233814 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.472269966009927 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.358802932570843 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.817742149516892 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▆▆▆▆▆▇▇▇▇▇▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▇███████▇▇▇▇█▇██▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▁█▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced stoic-sweep-1924: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lnn1x2cd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185240-lnn1x2cd/logs
2022-09-02 18:54:14,124 - wandb.wandb_agent - INFO - Cleaning up finished run: lnn1x2cd
2022-09-02 18:54:14,457 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:54:14,457 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.021098065719587097
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:54:14,469 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.021098065719587097 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:54:19,485 - wandb.wandb_agent - INFO - Running runs: ['tjaaxc0j']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185419-tjaaxc0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-1939
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tjaaxc0j
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.061576024625025 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0897731612409056 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.160414189240727 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3551812979355655 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.574228226301996 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▇▇▇▇▇▇▇█▇██▇▇▇▇▇▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇▇▇████▇▇▇▇▇▆▆▆▆▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇▇█████████▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced logical-sweep-1939: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tjaaxc0j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185419-tjaaxc0j/logs
2022-09-02 18:55:52,298 - wandb.wandb_agent - INFO - Cleaning up finished run: tjaaxc0j
2022-09-02 18:55:52,587 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:55:52,588 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.000109606206762192
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:55:52,615 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.000109606206762192 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:55:57,630 - wandb.wandb_agent - INFO - Running runs: ['21kz665o']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185557-21kz665o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-1957
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/21kz665o
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2381527795565406 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.254975277550111 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3226231978050427 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.716036630091838 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▅▅▅▆▆▆▆▆▆▅▅▅▅▅▅▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▄▆██▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▁▁▂▂▂▂▂▂▂▁▁▁▁▂▁▂▂▂▂▁▁▁▁▂▃▄▅▆▇█████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇█▄▁▁▁▁▁▁█▅▁▁▆▇▁▂███▇▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced playful-sweep-1957: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/21kz665o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185557-21kz665o/logs
2022-09-02 18:57:20,086 - wandb.wandb_agent - INFO - Cleaning up finished run: 21kz665o
2022-09-02 18:57:20,402 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:57:20,403 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005777702570927721
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:57:20,415 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005777702570927721 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:57:25,430 - wandb.wandb_agent - INFO - Running runs: ['w1o67t6g']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185724-w1o67t6g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-1971
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w1o67t6g
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4501834769163087 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.081824574660133 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1629569063447116 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.589609151464999 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████▇▆▅▃
wandb:  prop_2 ▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆█
wandb:  prop_3 ▄▅▆▇▇▆▆▆▆▇███▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:  reward █▁▁▁▅▁▁▃█▁▁▁█▁▁▁▁█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.396
wandb:  prop_2 0.54
wandb:  prop_3 0.0
wandb: prop_NA 0.064
wandb:  reward 0.83716
wandb: 
wandb: Synced exalted-sweep-1971: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w1o67t6g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185724-w1o67t6g/logs
2022-09-02 18:58:58,188 - wandb.wandb_agent - INFO - Cleaning up finished run: w1o67t6g
2022-09-02 18:58:58,467 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:58:58,467 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.026530095203708408
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:58:58,477 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.026530095203708408 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:59:03,494 - wandb.wandb_agent - INFO - Running runs: ['uqg0wuv2']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185904-uqg0wuv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-1986
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/uqg0wuv2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.147605776967317 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8894263314258986 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.459191058326708 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.46297660890983 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2021919098252876 seconds), retrying request
slurmstepd: error: *** JOB 2474897 ON arc-c308 CANCELLED AT 2022-09-02T19:00:08 ***
