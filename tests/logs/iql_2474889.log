wandb: Starting wandb agent 🕵️
2022-09-02 15:32:10,202 - wandb.wandb_agent - INFO - Running runs: []
2022-09-02 15:32:11,975 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:32:11,987 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005989096079189546
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:32:12,004 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005989096079189546 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:32:17,020 - wandb.wandb_agent - INFO - Running runs: ['nuusnd0k']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153217-nuusnd0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-14
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nuusnd0k
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4310249893724194 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0550693812607217 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.205520866925888 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.119474216113203 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.073885082388877 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.013920461463363 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.723270032570947 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
2022-09-02 15:33:44,955 - wandb.wandb_agent - INFO - Cleaning up finished run: nuusnd0k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅██▇▇▇▇██▇▇███▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁▁▁▅▁▁▁▁█▁▅▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced whole-sweep-14: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nuusnd0k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153217-nuusnd0k/logs
2022-09-02 15:33:51,840 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:33:51,850 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004776802141898362
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:33:51,870 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004776802141898362 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:33:56,888 - wandb.wandb_agent - INFO - Running runs: ['7yjc8uu4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153356-7yjc8uu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-36
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7yjc8uu4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0126619746362713 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4341046019490973 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.108180571752215 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1394829936894326 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.014380278552921 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4101658440380165 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▄▆▆▇▇▇▇▇▇▇▇███▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▆▆▇▇███▇▇▇▇▇▇██▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▃▁█▁█▅▁▁▁██▁█▁▆▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced different-sweep-36: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7yjc8uu4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153356-7yjc8uu4/logs
2022-09-02 15:35:24,569 - wandb.wandb_agent - INFO - Cleaning up finished run: 7yjc8uu4
2022-09-02 15:35:24,966 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:35:24,966 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0491931961528216
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:35:24,990 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0491931961528216 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:35:30,005 - wandb.wandb_agent - INFO - Running runs: ['v5lzvkdy']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153528-v5lzvkdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-50
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v5lzvkdy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3838386923608796 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.383213092700296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.499657092898079 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.713771673658439 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1129336375357246 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4011918377572385 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▇▇▇████▇▇▇▇▇▇▆▆▇▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▇██▇█▇▇▆▇▇▇█▇▇▇▇▇▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████▇▇▇▇▇████▇██▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▅▁▇▁█▁▁▆▇▁▄▁▅▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced smooth-sweep-50: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v5lzvkdy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153528-v5lzvkdy/logs
2022-09-02 15:36:52,621 - wandb.wandb_agent - INFO - Cleaning up finished run: v5lzvkdy
2022-09-02 15:36:59,346 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:36:59,358 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005773782792610669
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:36:59,387 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005773782792610669 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:37:04,403 - wandb.wandb_agent - INFO - Running runs: ['rm3bu6ml']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153704-rm3bu6ml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-65
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rm3bu6ml
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.391163138715166 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.150368561036406 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.027965612281804 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.510768962175846 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2147463223349155 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.496052258617402 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▇▆▇▇▇▇▇▇▇▆▆▆▆▆▆▇███▇▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇▇▇▇▇█▇█▇▇▇███▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.964
wandb:  prop_2 0.0
wandb:  prop_3 0.004
wandb: prop_NA 0.032
wandb:  reward 1.0
wandb: 
wandb: Synced treasured-sweep-65: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rm3bu6ml
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153704-rm3bu6ml/logs
2022-09-02 15:38:26,768 - wandb.wandb_agent - INFO - Cleaning up finished run: rm3bu6ml
2022-09-02 15:38:27,027 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:38:27,027 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00012419797627948254
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:38:27,039 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00012419797627948254 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:38:32,056 - wandb.wandb_agent - INFO - Running runs: ['dr2ta2ob']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153831-dr2ta2ob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-79
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dr2ta2ob
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.158048533798003 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.076058722306313 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1693651872266204 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7587252080195785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.017390663152238 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.033282147057033 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▆▇██████████████
wandb:  prop_2 ▃▃▄▃▄▄▄▄▄▄▄▄▃▃▃▃▃▃▄▄▆███▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb:  prop_3 ▇▇▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▅▁▇▁▁▅▅▁▁▁▁█▁█▇▇▁▁▂▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.963
wandb:  prop_2 0.034
wandb:  prop_3 0.0
wandb: prop_NA 0.003
wandb:  reward 1.0
wandb: 
wandb: Synced fearless-sweep-79: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dr2ta2ob
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153831-dr2ta2ob/logs
2022-09-02 15:39:54,569 - wandb.wandb_agent - INFO - Cleaning up finished run: dr2ta2ob
2022-09-02 15:39:54,819 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:39:54,823 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.012674643639154388
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:39:54,875 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.012674643639154388 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:39:59,891 - wandb.wandb_agent - INFO - Running runs: ['gwfyn41v']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_153959-gwfyn41v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-92
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gwfyn41v
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3882385666321304 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9018907962772795 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.229312207481191 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.163796484263508 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3396017134699933 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.663051982896762 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▅▆▆▆▆▆▆▆▅▆▆▇▇██▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇█▇▇▆▆▆▆▇▇▇▇▇▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▃▅▁▄▁▁▁█▁▁█▁▁▁▇▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced balmy-sweep-92: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gwfyn41v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_153959-gwfyn41v/logs
2022-09-02 15:41:27,521 - wandb.wandb_agent - INFO - Cleaning up finished run: gwfyn41v
2022-09-02 15:41:27,785 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:41:27,786 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0005475711780089916
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:41:27,803 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0005475711780089916 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:41:32,818 - wandb.wandb_agent - INFO - Running runs: ['7loj65jc']
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154137-7loj65jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-106
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7loj65jc
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1001952219620543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.127685221610547 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6699534581765665 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1174061593578393 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.227888610605543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2327541689189174 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.053126105634238 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▆▆▆▆▇▇▇▇▆▆▇█▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▁▁▁▁█▁▁▁▁▅▁▁▆▇▁▁█▅▇▇▁█▅██▁▂▄▂▄▂▃▇▁▆▅
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.61678
wandb: 
wandb: Synced winter-sweep-106: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7loj65jc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154137-7loj65jc/logs
2022-09-02 15:43:00,394 - wandb.wandb_agent - INFO - Cleaning up finished run: 7loj65jc
2022-09-02 15:43:00,621 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:43:00,622 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.016477647054731658
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:43:00,632 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.016477647054731658 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:43:05,652 - wandb.wandb_agent - INFO - Running runs: ['vy65i1la']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154305-vy65i1la
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-121
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vy65i1la
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.287375895040438 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.293411836061534 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0548446572672994 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3105707769023685 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0659921607784804 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆██████▇▇▇████▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅███▇█▇▇▆▆▆▆▆▆▇▇▇▆▇▆▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █▇▇▇▇▇▇▇███▇█▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁█▁█▁▁▁▄▁▁█▆▁▄▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced neat-sweep-121: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vy65i1la
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154305-vy65i1la/logs
2022-09-02 15:44:38,535 - wandb.wandb_agent - INFO - Cleaning up finished run: vy65i1la
2022-09-02 15:44:38,771 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:44:38,771 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001308917918795288
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:44:38,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001308917918795288 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:44:43,800 - wandb.wandb_agent - INFO - Running runs: ['hh6inyp4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154444-hh6inyp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-136
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hh6inyp4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0604043621546535 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.337289807049583 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8289997531932 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.067987072424949 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▆▆▇▇▇▇▆▆▆▆▇▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▇▇▇█▇██████▇▇▇█▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ██▇██▇██████████▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▁▁▅█▁▁▁▁▁▁█▁█▁▁▇▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced decent-sweep-136: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hh6inyp4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154444-hh6inyp4/logs
2022-09-02 15:46:12,560 - wandb.wandb_agent - INFO - Cleaning up finished run: hh6inyp4
2022-09-02 15:46:12,815 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:46:12,821 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0024227593947448627
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:46:12,848 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0024227593947448627 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:46:17,864 - wandb.wandb_agent - INFO - Running runs: ['kl9useek']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154617-kl9useek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-151
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kl9useek
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2357253679008577 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2057655495388815 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.477687429248475 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.066629763772033 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.059794771322742 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇██████▇▇▇▇▇▇▇▇▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁█▇▃▁▁▇▁█▆█▄▇▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced likely-sweep-151: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kl9useek
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154617-kl9useek/logs
2022-09-02 15:47:35,224 - wandb.wandb_agent - INFO - Cleaning up finished run: kl9useek
2022-09-02 15:47:35,464 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:47:35,464 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.043138691073270286
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:47:35,508 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.043138691073270286 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:47:40,524 - wandb.wandb_agent - INFO - Running runs: ['2yv4fjnv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154739-2yv4fjnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-165
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2yv4fjnv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.020125878370009 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.934197943719162 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3380627239508867 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.31099178307812 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4876284710249736 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3950165258477965 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇▇▇▇▇▇▇▇█████▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▇▇▇█▇▇▇▆▇▇▇▇▇▇██▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇████████████████▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁█▂▄▅▁█▁▁▁██▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced earnest-sweep-165: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2yv4fjnv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154739-2yv4fjnv/logs
2022-09-02 15:49:03,536 - wandb.wandb_agent - INFO - Cleaning up finished run: 2yv4fjnv
2022-09-02 15:49:04,297 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:49:04,297 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.012078837332932049
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:49:04,304 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.012078837332932049 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:49:09,315 - wandb.wandb_agent - INFO - Running runs: ['wgkhzaol']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_154908-wgkhzaol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-176
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wgkhzaol
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3972469070950737 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.441842198096304 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0459257009420084 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.024506917506601 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.280841376200377 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▇▇▇███▇▇▇▇▇▇▆▇▆▆▆▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▆▆▇▆▇▆▆▆▆▆▆▆▆▆▇▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄██▁▁▁▁▁▆▁▁▁█▁▄▁▁▇▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced honest-sweep-176: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wgkhzaol
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_154908-wgkhzaol/logs
2022-09-02 15:50:32,633 - wandb.wandb_agent - INFO - Cleaning up finished run: wgkhzaol
2022-09-02 15:50:32,916 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:50:32,917 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.017180266007323787
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:50:32,957 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.017180266007323787 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:50:37,972 - wandb.wandb_agent - INFO - Running runs: ['02oa3nm0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155040-02oa3nm0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-189
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/02oa3nm0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.098180943708274 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.938851780410013 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4323719881662234 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.589387405659134 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.356978787333774 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▆▆▆▇▇▇▇▆▆▆▇▇▇██▇▇███▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▅▇▇██▇▆▇▇▇▇▇▇▇█▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇▇▇▇████▇█▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂█▅▅▁▇▁▁▁▁▁▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced giddy-sweep-189: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/02oa3nm0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155040-02oa3nm0/logs
2022-09-02 15:52:05,674 - wandb.wandb_agent - INFO - Cleaning up finished run: 02oa3nm0
2022-09-02 15:52:05,922 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:52:05,922 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0021959402526454167
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:52:05,942 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0021959402526454167 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:52:10,957 - wandb.wandb_agent - INFO - Running runs: ['g1emwmlz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155210-g1emwmlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-206
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g1emwmlz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.372977339178168 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3871157071234568 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.200339994773296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3389235721242265 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb:  prop_2 ██▇▇▇▇▇▇███▇▇▇▇▇▇█▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▃▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇█▇██▇██▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▁▅▄▁▃▁▁▁▁█▁▁█▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced eager-sweep-206: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/g1emwmlz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155210-g1emwmlz/logs
2022-09-02 15:53:35,611 - wandb.wandb_agent - INFO - Cleaning up finished run: g1emwmlz
2022-09-02 15:53:35,855 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:53:35,909 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001056082671036824
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:53:35,930 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001056082671036824 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:53:40,946 - wandb.wandb_agent - INFO - Running runs: ['n7a3waze']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155340-n7a3waze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-219
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n7a3waze
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1280781910068267 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.220296639028908 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.047128081613807 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.197788732155687 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.034342989272669 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▆▇▇▇▇▆▆▇▆▆▇▇███▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ███▇▇▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇████████████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆██▁▅▂▁▁▁▁▁▁▁▁▁▅▁▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.998
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.002
wandb:  reward 1.0
wandb: 
wandb: Synced winter-sweep-219: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n7a3waze
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155340-n7a3waze/logs
2022-09-02 15:55:08,859 - wandb.wandb_agent - INFO - Cleaning up finished run: n7a3waze
2022-09-02 15:55:09,203 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:55:09,208 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00011216563277780106
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:55:09,223 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00011216563277780106 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:55:14,238 - wandb.wandb_agent - INFO - Running runs: ['c08ce71n']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155514-c08ce71n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-234
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c08ce71n
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.145523087995406 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.683534441802108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.187443119470746 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.629139610357398 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3514074707275245 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.499629884579218 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3633513976069582 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.309154957015434 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆████████████████
wandb:  prop_2 █▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▅▅▅▅▅▅▅▄▄▄▅▅▅▄▄▄▄▄▇█▇▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇▇▇▇▇▇▇█▇█▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆█▅▃▇▁▁▁▁▁█▇▁▁▁▁▇▁▇█▅▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced robust-sweep-234: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c08ce71n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155514-c08ce71n/logs
2022-09-02 15:56:44,720 - wandb.wandb_agent - INFO - Cleaning up finished run: c08ce71n
2022-09-02 15:56:45,396 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:56:45,406 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.026579063936299625
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:56:45,420 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.026579063936299625 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 15:56:50,435 - wandb.wandb_agent - INFO - Running runs: ['yqqx4qw4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155649-yqqx4qw4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-248
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yqqx4qw4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.184042122884026 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.261671998050688 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.449081876903994 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4633128294539537 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆█▇▇▆▆▆▇▇▇▇▇▇████▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▇▇▇▇▇▇▇▇▇█▇▇████▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████▇▇▇▇▇▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▁▁▁█▁▁▆▅▄▇▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced effortless-sweep-248: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yqqx4qw4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155649-yqqx4qw4/logs
2022-09-02 15:58:13,049 - wandb.wandb_agent - INFO - Cleaning up finished run: yqqx4qw4
2022-09-02 15:58:13,291 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:58:13,291 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0004301619805680721
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:58:13,300 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0004301619805680721 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:58:18,312 - wandb.wandb_agent - INFO - Running runs: ['7rwkgt9w']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155818-7rwkgt9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-264
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7rwkgt9w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.490936094788855 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.405823404899036 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.406910878166661 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.436364797976867 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.801161866042048 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇▇▇▆▆▆▆▆▆▆▇▇▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇███▇▆▅▅▄▄▃▃▃▃▃▃▃
wandb:  prop_3 ▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▃▅▆▇▇███████
wandb: prop_NA ▇▇▇▇████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁██▁▁▁▁▄▁█▁▁▆▁▁▂███▇██▆█▆███████▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.421
wandb:  prop_3 0.559
wandb: prop_NA 0.02
wandb:  reward 0.92352
wandb: 
wandb: Synced cerulean-sweep-264: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7rwkgt9w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155818-7rwkgt9w/logs
2022-09-02 15:59:40,815 - wandb.wandb_agent - INFO - Cleaning up finished run: 7rwkgt9w
2022-09-02 15:59:41,073 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 15:59:41,073 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004582468421654945
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 15:59:41,097 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004582468421654945 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 15:59:46,111 - wandb.wandb_agent - INFO - Running runs: ['7jnp7ntn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_155948-7jnp7ntn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-277
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7jnp7ntn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1880937353987666 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4757499563261396 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1205564676910553 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.907249673783543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3895136501010925 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆██▇█▇▇▇▇█▇█████▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▆▇▇▇▇▇▇██▇▇▇▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇█████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▇▁▇▁▁▁▁▁█▁▁▄█▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced gentle-sweep-277: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7jnp7ntn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_155948-7jnp7ntn/logs
2022-09-02 16:01:19,283 - wandb.wandb_agent - INFO - Cleaning up finished run: 7jnp7ntn
2022-09-02 16:01:21,023 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:01:21,024 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008756262972531556
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:01:21,054 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008756262972531556 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:01:26,070 - wandb.wandb_agent - INFO - Running runs: ['vzn7fori']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160125-vzn7fori
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-296
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vzn7fori
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4218748514636443 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.069027783247823 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2427412716803543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.323429778651191 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.461017812410105 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▆▇▆▇█▇▇▇▆▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▇▆▆▆▆▆▆▆▆▆▇▇███▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄█▁▅█▁▁▁▁▇▁▁▆▅▁▁█▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced fresh-sweep-296: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vzn7fori
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160125-vzn7fori/logs
2022-09-02 16:02:43,361 - wandb.wandb_agent - INFO - Cleaning up finished run: vzn7fori
2022-09-02 16:02:43,607 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:02:43,607 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0008404167469342204
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:02:43,640 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0008404167469342204 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:02:48,656 - wandb.wandb_agent - INFO - Running runs: ['zfexd4wp']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160251-zfexd4wp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-306
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zfexd4wp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4362802033327173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.81059871850519 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.003474268851905 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2722772939126292 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.392114567491786 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1025914397961802 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▆▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▃▄▆██
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇███████████▇▅▄▃▃
wandb: prop_NA ██▇██████▇▇█████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▁▁▁▄▇▁▄▁▁▁█▇▃▁▅▄▄▆█▅██████▇▆███▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.614
wandb:  prop_3 0.326
wandb: prop_NA 0.06
wandb:  reward 0.92352
wandb: 
wandb: Synced sleek-sweep-306: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/zfexd4wp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160251-zfexd4wp/logs
2022-09-02 16:04:11,391 - wandb.wandb_agent - INFO - Cleaning up finished run: zfexd4wp
2022-09-02 16:04:11,658 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:04:11,667 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0016114983246457411
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:04:11,694 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0016114983246457411 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:04:16,711 - wandb.wandb_agent - INFO - Running runs: ['832n43fh']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160417-832n43fh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-320
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/832n43fh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.467142120702885 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3171607143495647 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.28408452707787 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.377060040637964 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇▇▆▆▆▆▆▇▇▇▇▇▇▇▆▆▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅████▇▇▆▆▆▆▆▆▆▆▆▆▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███▇████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁█▁█▁▁█▁▄▁▁▁▁▁▄▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.965
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.035
wandb:  reward 1.0
wandb: 
wandb: Synced balmy-sweep-320: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/832n43fh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160417-832n43fh/logs
2022-09-02 16:05:49,583 - wandb.wandb_agent - INFO - Cleaning up finished run: 832n43fh
2022-09-02 16:05:49,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:05:49,878 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006816112382222552
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:05:49,886 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006816112382222552 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:05:54,897 - wandb.wandb_agent - INFO - Running runs: ['nfuytxep']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160556-nfuytxep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-336
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nfuytxep
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.333811680164229 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.100953997951632 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.396285331835982 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0674035971206752 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.267720165561065 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▇▇▇▇▇▇▇▆▆▅▆▆▇▇██▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ███▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▂▂▃▃▃▄▄▄▄
wandb: prop_NA ████████████████▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▁▂▁▁▁▁█▁▁▁▁▁▁▆██▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.944
wandb:  prop_3 0.053
wandb: prop_NA 0.003
wandb:  reward 0.83716
wandb: 
wandb: Synced pretty-sweep-336: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nfuytxep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160556-nfuytxep/logs
2022-09-02 16:07:17,482 - wandb.wandb_agent - INFO - Cleaning up finished run: nfuytxep
2022-09-02 16:07:17,763 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:07:17,764 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005794425551298087
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:07:17,795 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005794425551298087 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:07:22,810 - wandb.wandb_agent - INFO - Running runs: ['gg60m8qf']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160724-gg60m8qf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-349
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gg60m8qf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.096583952813128 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0128423125359785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7002864516321665 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇█▇████▇▇▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇████▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▅▅▁▁▁▁█▁▁█▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced generous-sweep-349: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gg60m8qf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160724-gg60m8qf/logs
2022-09-02 16:08:55,805 - wandb.wandb_agent - INFO - Cleaning up finished run: gg60m8qf
2022-09-02 16:08:56,112 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:08:56,126 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0006887626427418905
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:08:56,169 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0006887626427418905 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:09:01,204 - wandb.wandb_agent - INFO - Running runs: ['w5cbq8bq']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_160902-w5cbq8bq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-363
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w5cbq8bq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3754545950630774 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.80799563739208 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3613648476335416 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▆▇▇▇█▇▇▇▆▇████▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇███▇▇▇▇▇▇▇▇▇▆▆▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇█████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▁▁▁▁▁▅█▁▁▁█▇██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced balmy-sweep-363: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/w5cbq8bq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_160902-w5cbq8bq/logs
2022-09-02 16:10:23,848 - wandb.wandb_agent - INFO - Cleaning up finished run: w5cbq8bq
2022-09-02 16:10:50,118 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:10:50,134 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0058134800699461
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:10:50,162 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0058134800699461 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:10:55,189 - wandb.wandb_agent - INFO - Running runs: ['1ds0t598']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161057-1ds0t598
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-377
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1ds0t598
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1234519092993764 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.466257510542983 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.5034348654498055 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.324525745715033 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.502660301720802 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.328957824077238 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.627491926831415 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_2 ▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▇▆▆▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁▁▁▁█▇▁▁▁▁▇▆█▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced dulcet-sweep-377: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/1ds0t598
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161057-1ds0t598/logs
2022-09-02 16:12:27,914 - wandb.wandb_agent - INFO - Cleaning up finished run: 1ds0t598
2022-09-02 16:12:28,210 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:12:28,221 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0009889649909875944
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:12:28,250 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0009889649909875944 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:12:33,266 - wandb.wandb_agent - INFO - Running runs: ['yxck8d1e']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161232-yxck8d1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-398
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yxck8d1e
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.445868815651208 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2965843712162064 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.487140000132472 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.465705345274928 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.713672208986931 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.287960901646536 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.596336745494059 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▆▆▇▇▇▇▇▇▇████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▇▇▇▆▆▆▆▆▆▆▆▅▅▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▁▁▁█▁▁▁▁▁▁█▁▇█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced misunderstood-sweep-398: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yxck8d1e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161232-yxck8d1e/logs
2022-09-02 16:13:55,750 - wandb.wandb_agent - INFO - Cleaning up finished run: yxck8d1e
2022-09-02 16:13:55,985 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:13:55,996 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0002944440662115719
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:13:56,027 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0002944440662115719 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:14:01,043 - wandb.wandb_agent - INFO - Running runs: ['4o0k41ci']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161403-4o0k41ci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-409
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4o0k41ci
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1033276485378556 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.158489278146758 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0200981246456284 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8740203171497605 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.321814530789459 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▃▃▃▃▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▆██▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇██████████████
wandb:  prop_3 ▅▆▇▇▇▇▆▇▇▇▇▇▇█████▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████████▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▇▁▄▁▁▁▇▇▁█▁▁▁▁▁▁█▃██▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced sweepy-sweep-409: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4o0k41ci
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161403-4o0k41ci/logs
2022-09-02 16:15:23,531 - wandb.wandb_agent - INFO - Cleaning up finished run: 4o0k41ci
2022-09-02 16:15:23,807 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:15:23,807 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.02528542391245394
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:15:23,826 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.02528542391245394 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:15:28,841 - wandb.wandb_agent - INFO - Running runs: ['i4vk5it3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161531-i4vk5it3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-422
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i4vk5it3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1679569305345283 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.253223300714296 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1394485346433507 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.84252178179446 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.435827146172408 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.204889008958919 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▇▇▇▇▆▆▆▆▆▇▆▆▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▆▆▆▆▆▆▆▅▅▅▅▅▆▆▆▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇████████████████▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▅▁▁▁▁▁▁▅▅▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced pious-sweep-422: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/i4vk5it3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161531-i4vk5it3/logs
2022-09-02 16:16:51,290 - wandb.wandb_agent - INFO - Cleaning up finished run: i4vk5it3
2022-09-02 16:16:51,690 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:16:51,690 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.019799207193956107
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:16:51,731 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.019799207193956107 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:16:56,748 - wandb.wandb_agent - INFO - Running runs: ['8tg277fg']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161658-8tg277fg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-436
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8tg277fg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.250204793516748 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7404863295631285 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.007621608019631 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.230089446371147 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇▇▇▇▇███████▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▆▅▆▆▅▅▅▅▅▆▅▅▅▅▅▆▅▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁█▁▁▇▁▅▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced stilted-sweep-436: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8tg277fg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161658-8tg277fg/logs
2022-09-02 16:18:24,807 - wandb.wandb_agent - INFO - Cleaning up finished run: 8tg277fg
2022-09-02 16:18:25,038 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:18:25,038 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0005871905725737196
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:18:25,044 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0005871905725737196 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:18:30,057 - wandb.wandb_agent - INFO - Running runs: ['0ho93ffe']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161830-0ho93ffe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-452
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0ho93ffe
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2630742446915355 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2900910021047696 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.553468017385423 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.351857254638368 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.915984078218487 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▃▄▆▇████▇▇▇▇▇▇
wandb:  prop_2 ▄▆▇▇▇█▇▇████▇▇▇▇▇▇███▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇██▇▆▅▄▃▃▃▃▃▃▃▃▃▃
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂
wandb:  reward ▁█▅▃▁▁▁▁█▁▁▁▁▁▁▁██▁▇▅▄▄▆█▅██████▇▁▁█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.532
wandb:  prop_2 0.0
wandb:  prop_3 0.403
wandb: prop_NA 0.065
wandb:  reward 1.0
wandb: 
wandb: Synced logical-sweep-452: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/0ho93ffe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161830-0ho93ffe/logs
2022-09-02 16:19:52,573 - wandb.wandb_agent - INFO - Cleaning up finished run: 0ho93ffe
2022-09-02 16:19:52,859 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:19:52,860 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.007860805331336828
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:19:52,872 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.007860805331336828 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:19:57,886 - wandb.wandb_agent - INFO - Running runs: ['5twljq71']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_161959-5twljq71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-466
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5twljq71
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2555909871802333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.186958203460947 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.23080987683697 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.802123973843628 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▇▇▇▇▇▇▇███▇▇▇▇▆▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▅▆▇▇██▇▇▇▇▇████▇▇▇▆▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ███████████▇▇▇██████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁█▁█▁▁▁▁▄▇▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced copper-sweep-466: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5twljq71
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_161959-5twljq71/logs
2022-09-02 16:21:25,490 - wandb.wandb_agent - INFO - Cleaning up finished run: 5twljq71
2022-09-02 16:21:25,735 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:21:25,736 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00033697318760329045
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:21:25,807 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00033697318760329045 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:21:30,821 - wandb.wandb_agent - INFO - Running runs: ['39evl4ey']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162133-39evl4ey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-481
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/39evl4ey
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.264835919872063 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4142451201292046 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.182204720738954 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▃▄▆██████▇▇▆▅▅▅
wandb:  prop_2 ▁▂▂▂▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▄▆██▇▅▃▁▁▁▁▁▁▂▂▃▃▄▃
wandb:  prop_3 █▇▇▇▇█████▇▇▇▇▇▇▇██▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂
wandb:  reward ▆█▁▃▅▁█▁█▁▁▁▁█▁▅█▆█▁▂███▇▂▇▂▅▆▇▄▂▄▁▁█▁██
wandb: 
wandb: Run summary:
wandb:  prop_1 0.575
wandb:  prop_2 0.355
wandb:  prop_3 0.0
wandb: prop_NA 0.07
wandb:  reward 1.0
wandb: 
wandb: Synced hearty-sweep-481: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/39evl4ey
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162133-39evl4ey/logs
2022-09-02 16:22:58,367 - wandb.wandb_agent - INFO - Cleaning up finished run: 39evl4ey
2022-09-02 16:22:58,655 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:22:58,655 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00031908610563866416
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:22:58,672 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00031908610563866416 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:23:03,688 - wandb.wandb_agent - INFO - Running runs: ['r26gqerx']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162306-r26gqerx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-495
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r26gqerx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.081277855652566 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.345375910888912 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.782174644205069 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ███▇█████▇█▇▇███▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▇█▇▇▇▆▇▇▇▇████▇▆▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇██▇▇▇▇▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▄▄▁▁▁▁▇█▁▁▁▁▁▃█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced mild-sweep-495: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r26gqerx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162306-r26gqerx/logs
2022-09-02 16:24:31,340 - wandb.wandb_agent - INFO - Cleaning up finished run: r26gqerx
2022-09-02 16:24:31,606 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:24:31,607 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.025755358739585375
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:24:31,621 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.025755358739585375 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:24:36,635 - wandb.wandb_agent - INFO - Running runs: ['r97ynpu7']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162438-r97ynpu7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-510
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r97ynpu7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.082251044588622 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.737293492809939 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▇▇▇▇█▇█████▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ▇▇▇▇████▇▇▇█████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▄▁██▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced golden-sweep-510: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r97ynpu7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162438-r97ynpu7/logs
2022-09-02 16:26:04,164 - wandb.wandb_agent - INFO - Cleaning up finished run: r97ynpu7
2022-09-02 16:26:04,426 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:26:04,427 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004364376398421698
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:26:04,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004364376398421698 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:26:09,467 - wandb.wandb_agent - INFO - Running runs: ['owrpcyyr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162610-owrpcyyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-525
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/owrpcyyr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3610174656673855 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.701266505006241 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.099919816840538 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.753042617932429 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▆▆▆▆▆▆▆▇███▇▇▆▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇█████▇▇▇▇▇█▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████▇▇▇▇█████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁██▁▁▁▆█▁▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced vocal-sweep-525: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/owrpcyyr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162610-owrpcyyr/logs
2022-09-02 16:27:35,184 - wandb.wandb_agent - INFO - Cleaning up finished run: owrpcyyr
2022-09-02 16:27:35,442 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:27:35,443 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004848567749579261
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:27:35,493 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004848567749579261 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:27:40,513 - wandb.wandb_agent - INFO - Running runs: ['atjuyex1']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162743-atjuyex1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-539
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/atjuyex1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.361377562980191 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0451231175894167 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.037369275146567 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.484298864078013 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▇▇█▇▇▇▇▇▇▇▆▆▆▆▇▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆█▇████▇▇▇▇▇█▇▇▇▆▆▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▅▁█▁▁▁▁██▁▁▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.981
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.019
wandb:  reward 1.0
wandb: 
wandb: Synced dulcet-sweep-539: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/atjuyex1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162743-atjuyex1/logs
2022-09-02 16:29:09,753 - wandb.wandb_agent - INFO - Cleaning up finished run: atjuyex1
2022-09-02 16:29:10,002 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:29:10,002 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005990591798355682
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:29:10,046 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005990591798355682 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:29:15,068 - wandb.wandb_agent - INFO - Running runs: ['jjlg3wyn']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_162918-jjlg3wyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-553
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jjlg3wyn
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1722445720714347 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6390282055399465 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇█████▇▇█▇▇███▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇███▇▇▆▇▇▇█▇▇██▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████▇▇▇▇████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂
wandb:  reward ▁▁▅▁▅▂██▁▆▁▁▁▆▅▁▁▁█▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.935
wandb: prop_NA 0.065
wandb:  reward 0.92352
wandb: 
wandb: Synced whole-sweep-553: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jjlg3wyn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_162918-jjlg3wyn/logs
2022-09-02 16:30:42,751 - wandb.wandb_agent - INFO - Cleaning up finished run: jjlg3wyn
2022-09-02 16:30:43,009 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:30:43,010 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.004083198033909141
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:30:43,072 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.004083198033909141 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:30:48,087 - wandb.wandb_agent - INFO - Running runs: ['m4fjf29r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163050-m4fjf29r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-568
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m4fjf29r
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.093536468578104 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇█▇█▇▇▇▇▇▇██▇▇▆▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▂▁▁▁▄▇▁▁▁▅▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced usual-sweep-568: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m4fjf29r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163050-m4fjf29r/logs
2022-09-02 16:32:10,885 - wandb.wandb_agent - INFO - Cleaning up finished run: m4fjf29r
2022-09-02 16:32:11,166 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:32:11,167 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0023844439133229125
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:32:11,180 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0023844439133229125 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:32:16,193 - wandb.wandb_agent - INFO - Running runs: ['tdnd2isf']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163218-tdnd2isf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-583
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tdnd2isf
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0061883465286092 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.584044293655433 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2413956929966132 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▇▇██▇▇▆▆▆▆▆▆▆▆▆▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇████▇▇▇▇▇▆▆▆▆▆▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇█▇▇██████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁██▁▁▄▁▁▁▁█▅▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dutiful-sweep-583: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/tdnd2isf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163218-tdnd2isf/logs
2022-09-02 16:33:44,189 - wandb.wandb_agent - INFO - Cleaning up finished run: tdnd2isf
2022-09-02 16:33:44,474 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:33:44,475 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001491021685852523
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:33:44,511 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001491021685852523 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:33:49,527 - wandb.wandb_agent - INFO - Running runs: ['mfucozln']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163352-mfucozln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-598
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mfucozln
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.287047953602519 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4155997912832734 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4342743654156958 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▃▄▆█▇▇▇▇▇▇███████
wandb:  prop_2 ▇█▇▇▇▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅▇██▆▅▆▆▆▆▆▆▆▆▆▅▆▆▅
wandb: prop_NA ▇███████████▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▁▁▁▁█▁▁▁▁▆▁▁▅▄▅▆█▅██████▇▆██▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.517
wandb:  prop_2 0.0
wandb:  prop_3 0.471
wandb: prop_NA 0.012
wandb:  reward 1.0
wandb: 
wandb: Synced good-sweep-598: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mfucozln
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163352-mfucozln/logs
2022-09-02 16:35:12,709 - wandb.wandb_agent - INFO - Cleaning up finished run: mfucozln
2022-09-02 16:35:13,015 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:35:13,015 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00020282059626054627
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:35:13,046 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00020282059626054627 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:35:18,067 - wandb.wandb_agent - INFO - Running runs: ['6b8zongi']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163520-6b8zongi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-613
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6b8zongi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.378277717931668 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4239537879261666 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇██████▇▇▇▇██▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▂▁▁▁▄▁▂▁▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fearless-sweep-613: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6b8zongi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163520-6b8zongi/logs
2022-09-02 16:36:51,917 - wandb.wandb_agent - INFO - Cleaning up finished run: 6b8zongi
2022-09-02 16:36:52,163 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:36:52,164 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001616652104572444
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:36:52,175 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001616652104572444 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:36:57,188 - wandb.wandb_agent - INFO - Running runs: ['hqn8z2ln']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163656-hqn8z2ln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-629
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hqn8z2ln
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2436309222353996 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4901941229334175 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇█▇██▇▇▇▇▇▇▇▆▇▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄▆▆▆▆▆▆▆▇▇████████
wandb:  prop_3 ▆▆▆▆▆▅▅▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇███▇▇▆▄▃▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁█▁▅▁▄▁█▁▁▁▁▁▁▁▁▂███▇█▂▆▄▁▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced clear-sweep-629: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hqn8z2ln
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163656-hqn8z2ln/logs
2022-09-02 16:38:19,680 - wandb.wandb_agent - INFO - Cleaning up finished run: hqn8z2ln
2022-09-02 16:38:19,962 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:38:19,972 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0017354838154396686
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:38:20,007 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0017354838154396686 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:38:25,023 - wandb.wandb_agent - INFO - Running runs: ['9z7pvklm']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_163826-9z7pvklm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-643
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9z7pvklm
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.245873712173776 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0094780584135616 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9495913283973705 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▆▆▇▇▇▇▆▆▇▇▇██▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▃▅▇▆▇▇▇▇▇▆▆▆▇▇▇▇███▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▇▁▇▁▁▆▁▁▁▁█▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.979
wandb:  prop_3 0.0
wandb: prop_NA 0.021
wandb:  reward 0.83716
wandb: 
wandb: Synced ancient-sweep-643: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9z7pvklm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_163826-9z7pvklm/logs
2022-09-02 16:39:57,835 - wandb.wandb_agent - INFO - Cleaning up finished run: 9z7pvklm
2022-09-02 16:39:58,107 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:39:58,108 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.004846815203809992
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:39:58,121 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.004846815203809992 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:40:03,134 - wandb.wandb_agent - INFO - Running runs: ['59yeqi0h']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164002-59yeqi0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-657
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59yeqi0h
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.022755338285222 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2700257025240695 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.666212399192611 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4846066928913104 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.286304817323525 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▇▇█▇▇▇▇████▇▇▇█▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆████████████████
wandb: prop_NA █████████████████████▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▇▁▄█▁▁▁▁▁█▁▅▁▆▃▁█▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced cosmic-sweep-657: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/59yeqi0h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164002-59yeqi0h/logs
2022-09-02 16:41:30,800 - wandb.wandb_agent - INFO - Cleaning up finished run: 59yeqi0h
2022-09-02 16:41:31,070 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:41:31,076 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0002021882920462831
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:41:31,111 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0002021882920462831 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:41:36,127 - wandb.wandb_agent - INFO - Running runs: ['bnq5cokp']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164135-bnq5cokp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-672
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bnq5cokp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4725451744563687 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1024872242675734 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.384529761843829 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4469517816991777 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▇██▇▇▇▇███▇█▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇████▇██▇▇▇▇▇▇▇█▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▅▁▁▃▁█▁▁▅█▁▅▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sleek-sweep-672: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bnq5cokp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164135-bnq5cokp/logs
2022-09-02 16:43:08,845 - wandb.wandb_agent - INFO - Cleaning up finished run: bnq5cokp
2022-09-02 16:43:09,137 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:43:09,137 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001286112996285938
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:43:09,168 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001286112996285938 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:43:14,183 - wandb.wandb_agent - INFO - Running runs: ['lt0y5pq3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164314-lt0y5pq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-687
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lt0y5pq3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2364406016737046 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3099606771568726 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.409554089106715 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▆▇▇████▇▇▆▆▇▇▇▇▆▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▅▆▇▇▇▇▇▇▇▇▇████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb: prop_NA ▇████████████████████▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁█▄▁█▁▁█▂███▅█▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced distinctive-sweep-687: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/lt0y5pq3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164314-lt0y5pq3/logs
2022-09-02 16:44:36,570 - wandb.wandb_agent - INFO - Cleaning up finished run: lt0y5pq3
2022-09-02 16:44:36,836 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:44:36,836 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005163605391478622
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:44:36,851 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005163605391478622 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:44:41,865 - wandb.wandb_agent - INFO - Running runs: ['hv6kckz3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164442-hv6kckz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-701
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hv6kckz3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0986371988124315 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.279205926213464 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0937766975287335 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8713968916085175 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁█▁▁▁██▁▄▁█▄▁▇▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced eternal-sweep-701: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hv6kckz3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164442-hv6kckz3/logs
2022-09-02 16:46:04,323 - wandb.wandb_agent - INFO - Cleaning up finished run: hv6kckz3
2022-09-02 16:46:04,603 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:46:04,603 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00029576348941993063
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:46:04,632 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00029576348941993063 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:46:09,648 - wandb.wandb_agent - INFO - Running runs: ['n7kacbz3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164609-n7kacbz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-715
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n7kacbz3
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1212850657074647 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.146865776545507 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.495400755029257 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0821304231307094 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▇▇▇▆▆▇▆▆▆▆▇▇▇▇██▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇█▇▇█▇▇█▇██▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▁▁▅▆▁█▁▁▁▁▁▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.997
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.003
wandb:  reward 1.0
wandb: 
wandb: Synced chocolate-sweep-715: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/n7kacbz3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164609-n7kacbz3/logs
2022-09-02 16:47:32,465 - wandb.wandb_agent - INFO - Cleaning up finished run: n7kacbz3
2022-09-02 16:47:32,735 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:47:32,735 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0003453788053203771
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:47:32,761 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0003453788053203771 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:47:37,777 - wandb.wandb_agent - INFO - Running runs: ['fdg6vi3s']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164737-fdg6vi3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-730
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fdg6vi3s
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.377591096609365 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.334660311699691 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.28654585510749 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▅▅▅▅▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇███▇▇▇▆▇▆▆▇▇▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁█▁▁▁▇▅▁▁▁▇▁▇▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.958
wandb: prop_NA 0.042
wandb:  reward 0.92352
wandb: 
wandb: Synced lemon-sweep-730: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/fdg6vi3s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164737-fdg6vi3s/logs
2022-09-02 16:49:00,290 - wandb.wandb_agent - INFO - Cleaning up finished run: fdg6vi3s
2022-09-02 16:49:00,554 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:49:00,555 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001153430682778593
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:49:00,571 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001153430682778593 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:49:05,586 - wandb.wandb_agent - INFO - Running runs: ['52yq49ma']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_164906-52yq49ma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-743
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/52yq49ma
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0760579515730644 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.258260371074435 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.167989515600723 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.013846930909876 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.041415914680703 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇████▇▇▇▆▆▆▆▆▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▆▆▆▇▇▇████▇▇▇▇▇▆▇▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁██▁▇▁█▁▁▁█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced comfy-sweep-743: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/52yq49ma
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_164906-52yq49ma/logs
2022-09-02 16:50:28,085 - wandb.wandb_agent - INFO - Cleaning up finished run: 52yq49ma
2022-09-02 16:50:28,370 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:50:28,371 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00011159119299200973
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:50:28,389 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00011159119299200973 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:50:33,403 - wandb.wandb_agent - INFO - Running runs: ['totabcjh']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165033-totabcjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-758
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/totabcjh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.438949860906107 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.702623604239523 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1645047879131614 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2108220071706133 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.686262065819053 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆██▇█▇▇▇██▇▇▇▇▇▇███▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▃▁▁▁▁▅███▇█▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced sunny-sweep-758: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/totabcjh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165033-totabcjh/logs
2022-09-02 16:52:00,995 - wandb.wandb_agent - INFO - Cleaning up finished run: totabcjh
2022-09-02 16:52:01,302 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:52:01,302 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.020228296951055245
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:52:01,317 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.020228296951055245 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:52:06,330 - wandb.wandb_agent - INFO - Running runs: ['gqcs228t']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165205-gqcs228t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-772
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gqcs228t
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1972007015822554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.244026816499836 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.420036769752135 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4711596602013377 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.936572749888798 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4128774545971763 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▇█████▇▇▇▇███▇▇▆▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▆▆▆▆▇▇▇▆▆▆▆▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▅▂▁▁▁▁▁▂▁█▁▁▁▆▇▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fearless-sweep-772: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gqcs228t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165205-gqcs228t/logs
2022-09-02 16:53:28,940 - wandb.wandb_agent - INFO - Cleaning up finished run: gqcs228t
2022-09-02 16:53:29,233 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:53:29,233 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.001543843936468765
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:53:29,262 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.001543843936468765 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:53:34,278 - wandb.wandb_agent - INFO - Running runs: ['a5z6zycd']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165336-a5z6zycd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-784
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a5z6zycd
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.355170267318639 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.076706924473275 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.822249488644054 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.373237016127115 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▁▁▁▁▁▁▂▂▂▃▃▃▄▄▅▆█
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██████▇▇▇▇▇▆▆▅▅▄
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂
wandb:  reward ▁█▁▁▁▁█▅▁▄▁▂▄▁▁█▁▁▁▁▅▄▄▆█▅██████▇▆███▁▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.378
wandb:  prop_3 0.506
wandb: prop_NA 0.116
wandb:  reward 0.83716
wandb: 
wandb: Synced lyric-sweep-784: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/a5z6zycd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165336-a5z6zycd/logs
2022-09-02 16:55:01,935 - wandb.wandb_agent - INFO - Cleaning up finished run: a5z6zycd
2022-09-02 16:55:02,190 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:55:02,195 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03738490217868928
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:55:02,208 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03738490217868928 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 16:55:07,227 - wandb.wandb_agent - INFO - Running runs: ['gzx36ogi']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165507-gzx36ogi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-799
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gzx36ogi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.100602639674679 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3956294624876864 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.072400616182998 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.1429937173799996 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3038823296560795 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▆▆▆▇▇██▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▅▆▆▆▆▇▇▆▇▇▆▆▆▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▁▁▁▁▄▇▁▁█▁▄▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced lunar-sweep-799: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gzx36ogi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165507-gzx36ogi/logs
2022-09-02 16:56:29,732 - wandb.wandb_agent - INFO - Cleaning up finished run: gzx36ogi
2022-09-02 16:56:30,043 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:56:30,043 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.01077530361823871
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:56:30,066 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.01077530361823871 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:56:35,081 - wandb.wandb_agent - INFO - Running runs: ['mn29opp8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165636-mn29opp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-813
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mn29opp8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.177209699061488 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4212663664896454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.637295218088928 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4284566418411733 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ██▇▇▇▆▆▆▇█▇▇▆▆▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▇▇▇▇▇▆▇▇▇▇▇███▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁▁▃▁█▁█▄█▁▅▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.974
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.026
wandb:  reward 1.0
wandb: 
wandb: Synced rose-sweep-813: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mn29opp8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165636-mn29opp8/logs
2022-09-02 16:57:57,691 - wandb.wandb_agent - INFO - Cleaning up finished run: mn29opp8
2022-09-02 16:57:57,957 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:57:57,965 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.01412223895380185
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:57:57,984 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.01412223895380185 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:58:02,999 - wandb.wandb_agent - INFO - Running runs: ['r23daref']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165803-r23daref
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-825
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r23daref
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.06706225421997 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4368223834304117 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.309338453705719 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.333287105652289 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆█▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▇▇▇▇▇▇▆▇▇██▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇▇▇██████▇▇▇██████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▅▁█▁▁▁▁█▅▆▁▁█▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced peachy-sweep-825: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r23daref
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165803-r23daref/logs
2022-09-02 16:59:30,785 - wandb.wandb_agent - INFO - Cleaning up finished run: r23daref
2022-09-02 16:59:31,064 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 16:59:31,077 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.010178956431701892
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 16:59:31,115 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.010178956431701892 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 16:59:36,142 - wandb.wandb_agent - INFO - Running runs: ['bkjbu5n9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_165936-bkjbu5n9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-841
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bkjbu5n9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.482447048463834 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.343230835400209 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.891569258824936 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3725767361727073 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇████▇▇▇▇▇▇▆▇▇▆▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▇▇▇▇▇▇█████▇▇▇███▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced worldly-sweep-841: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bkjbu5n9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_165936-bkjbu5n9/logs
2022-09-02 17:01:03,936 - wandb.wandb_agent - INFO - Cleaning up finished run: bkjbu5n9
2022-09-02 17:01:04,234 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:01:04,234 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00045537695490366657
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:01:04,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00045537695490366657 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:01:09,271 - wandb.wandb_agent - INFO - Running runs: ['2cftetw8']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170108-2cftetw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-856
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2cftetw8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1447038557774123 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2378515020542107 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.6915970452750555 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.170098706414164 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.813542887736683 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▄▆▇███
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████▇▇▆▅▄▃▃▃
wandb:  prop_3 ▇▇▇█████▇▇▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇█▇▇▇▇█████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂
wandb:  reward █▁▅▃▁▁▁▁▁████▁▁▄▁▁▇▁▂███▇█▂▆▄▆▄▄██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.578
wandb:  prop_2 0.36
wandb:  prop_3 0.0
wandb: prop_NA 0.062
wandb:  reward 1.0
wandb: 
wandb: Synced firm-sweep-856: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2cftetw8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170108-2cftetw8/logs
2022-09-02 17:02:28,026 - wandb.wandb_agent - INFO - Cleaning up finished run: 2cftetw8
2022-09-02 17:02:28,400 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:02:28,400 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0049596045715218735
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:02:28,424 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0049596045715218735 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:02:33,439 - wandb.wandb_agent - INFO - Running runs: ['gmmkwpe1']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170233-gmmkwpe1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-868
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gmmkwpe1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.467837432519281 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.262974235357699 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2752850932706883 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▇▇▇█▇▇▇▇█▇▇▆▇▇███▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇█▇▇█▇▇▇████▇▇▇▇███▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▁▃▁█▁▂▁▆▅█▁▆▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dandy-sweep-868: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gmmkwpe1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170233-gmmkwpe1/logs
2022-09-02 17:04:01,281 - wandb.wandb_agent - INFO - Cleaning up finished run: gmmkwpe1
2022-09-02 17:04:01,577 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:04:01,587 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.041802146330860254
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:04:01,614 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.041802146330860254 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:04:06,634 - wandb.wandb_agent - INFO - Running runs: ['z3q53tnb']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170406-z3q53tnb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-881
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z3q53tnb
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0809754591648515 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2621703428386195 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.288790633069864 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇▇▇▆▆▆▇█▇▇▇▇▇█▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇██▇▇▇▇▆▆▆▇▇▇▇▇▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇█████████▇▇▇▇██▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▄▁▁▁▆█▁▁▆▁█▇█▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced bright-sweep-881: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z3q53tnb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170406-z3q53tnb/logs
2022-09-02 17:05:24,982 - wandb.wandb_agent - INFO - Cleaning up finished run: z3q53tnb
2022-09-02 17:05:25,230 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:05:25,230 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.018928160276563653
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:05:25,243 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.018928160276563653 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:05:30,260 - wandb.wandb_agent - INFO - Running runs: ['u30t3kdz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170529-u30t3kdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-894
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u30t3kdz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1859801753774826 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.73174342884914 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1019907233067405 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▇▇▇▇▇█▇▇▇▇▆▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▅▃▇█▁▁█▆█▁▁▁▁▁▁█▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced swept-sweep-894: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/u30t3kdz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170529-u30t3kdz/logs
2022-09-02 17:06:54,273 - wandb.wandb_agent - INFO - Cleaning up finished run: u30t3kdz
2022-09-02 17:06:54,718 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:06:54,718 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.018394445689655616
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:06:54,735 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.018394445689655616 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:06:59,749 - wandb.wandb_agent - INFO - Running runs: ['ze5sznlp']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170659-ze5sznlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-909
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ze5sznlp
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3557721239592713 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3736874933562504 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.860867563242789 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ██▆▆▆▆▇▇▇▇▇█▇▇▇▇▇▇█▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▇▆▆▆▆▆▆▆▆▆▇▇▇▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▅▁▁▁▁▁▁▅▄█▁▃▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced daily-sweep-909: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ze5sznlp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170659-ze5sznlp/logs
2022-09-02 17:08:27,484 - wandb.wandb_agent - INFO - Cleaning up finished run: ze5sznlp
2022-09-02 17:08:27,805 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:08:27,805 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.003870882275806851
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:08:27,811 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.003870882275806851 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:08:32,825 - wandb.wandb_agent - INFO - Running runs: ['9xiuv2uv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_170832-9xiuv2uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-923
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9xiuv2uv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2997888614549393 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3190736775977645 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.341500323784002 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇████▇▇▇▇▇▇▆▆▆▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▇▇▆▇▇▇██▇▇▆▆▇▇█▇▇▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ███▇▇▇▇▇▇▇█▇▇███▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▇▁▁▆▁▁▁▁█▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fast-sweep-923: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/9xiuv2uv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_170832-9xiuv2uv/logs
2022-09-02 17:10:02,442 - wandb.wandb_agent - INFO - Cleaning up finished run: 9xiuv2uv
2022-09-02 17:10:02,747 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:10:02,748 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0027362585868580605
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:10:02,753 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0027362585868580605 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:10:07,767 - wandb.wandb_agent - INFO - Running runs: ['phsbutsd']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171007-phsbutsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-938
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/phsbutsd
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.365570963802526 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0856421421168143 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9426023425155865 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▆▇▆▆▇▆▆▆▆▇▇▇▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▆▇█▇█▇▆▇▇▇█████▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▂▁▁█▆▇█▁▁▁▄▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced ruby-sweep-938: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/phsbutsd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171007-phsbutsd/logs
2022-09-02 17:11:30,315 - wandb.wandb_agent - INFO - Cleaning up finished run: phsbutsd
2022-09-02 17:11:30,644 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:11:30,644 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.01640657484809803
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:11:30,650 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.01640657484809803 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:11:35,663 - wandb.wandb_agent - INFO - Running runs: ['c02eh8bx']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171135-c02eh8bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-953
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c02eh8bx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.067582222396098 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▄▅▆▇▇▇██▇▇▇▇████▇█▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇████▇▇▇▇██▇▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▃▅▁▁█▁▁▁▇▁▁▁▅▇▁▃██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced hearty-sweep-953: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/c02eh8bx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171135-c02eh8bx/logs
2022-09-02 17:12:58,075 - wandb.wandb_agent - INFO - Cleaning up finished run: c02eh8bx
2022-09-02 17:12:58,357 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:12:58,357 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00040001623060807506
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:12:58,365 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00040001623060807506 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:13:03,378 - wandb.wandb_agent - INFO - Running runs: ['cil02817']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171302-cil02817
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-967
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cil02817
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4350536062034465 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.394662355833637 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4062797347977414 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3498436174451642 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.0445596529717225 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▆▇▆▇▇▇▇▇▇▆▆▆▆▇▇▆▇▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▁▁▁▁▁▂▁█▁▁▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced upbeat-sweep-967: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/cil02817
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171302-cil02817/logs
2022-09-02 17:14:36,517 - wandb.wandb_agent - INFO - Cleaning up finished run: cil02817
2022-09-02 17:14:36,842 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:14:36,843 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.020225227419583117
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:14:36,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.020225227419583117 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:14:41,862 - wandb.wandb_agent - INFO - Running runs: ['gx0zek39']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171441-gx0zek39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-982
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gx0zek39
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4338968460503545 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3141979014032494 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1280094598837485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.123241012316024 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆█▇▇▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ██▇▇▇▇▇██▇▇▇▇▇▇▇▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁███▅▁▁▇█▅▁▁▁▁▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced wild-sweep-982: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gx0zek39
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171441-gx0zek39/logs
2022-09-02 17:16:09,438 - wandb.wandb_agent - INFO - Cleaning up finished run: gx0zek39
2022-09-02 17:16:09,714 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:16:09,714 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0001911742090801281
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:16:09,720 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0001911742090801281 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:16:14,734 - wandb.wandb_agent - INFO - Running runs: ['artn15x3']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171615-artn15x3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-997
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/artn15x3
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.308531664281439 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▇▆▆▇▇▇▇▇▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 █▇▇▇▇▇▇▇█████▇▇▇██▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▇▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.999
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 0.83716
wandb: 
wandb: Synced lunar-sweep-997: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/artn15x3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171615-artn15x3/logs
2022-09-02 17:17:42,672 - wandb.wandb_agent - INFO - Cleaning up finished run: artn15x3
2022-09-02 17:17:42,950 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:17:42,951 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.003664847878413438
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:17:42,965 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.003664847878413438 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:17:47,985 - wandb.wandb_agent - INFO - Running runs: ['jntkvd1p']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171746-jntkvd1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-1012
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jntkvd1p
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3189911267056145 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▅▆▇▇▇▇████▇▇▇▇████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▇▇▇▇▆▇▇██▇▇▇▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▇▅▁█▁▇▁▆█▁▁▆▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.997
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.003
wandb:  reward 1.0
wandb: 
wandb: Synced celestial-sweep-1012: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jntkvd1p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171746-jntkvd1p/logs
2022-09-02 17:19:11,133 - wandb.wandb_agent - INFO - Cleaning up finished run: jntkvd1p
2022-09-02 17:19:11,453 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:19:11,454 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0003655474269845759
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:19:11,477 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0003655474269845759 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:19:16,490 - wandb.wandb_agent - INFO - Running runs: ['la423voe']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_171917-la423voe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-1027
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/la423voe
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2099213930057786 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.532427992569879 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▅▆▇▇████▇▇▇▇███▇▇▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▆▇▇▇▇▆▆▇▇███▇█▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇████▇▇▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▆▁▇▅█▅▁▁▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced sweet-sweep-1027: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/la423voe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_171917-la423voe/logs
2022-09-02 17:20:54,364 - wandb.wandb_agent - INFO - Cleaning up finished run: la423voe
2022-09-02 17:20:54,669 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:20:54,669 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0380351735048652
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:20:54,681 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0380351735048652 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:20:59,695 - wandb.wandb_agent - INFO - Running runs: ['r223bxfl']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172100-r223bxfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-1043
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r223bxfl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3319804573819116 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.488408508571609 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▇▇█████▇▇▇▆▇▇▇▇▇▇▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆▆▆▇▇███▇▆▆▆▆▆▆▆▆▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇████▇▇▇▇▇▇████████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▅▁▆▁▁▁█▁▁▁█▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced gallant-sweep-1043: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/r223bxfl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172100-r223bxfl/logs
2022-09-02 17:22:22,131 - wandb.wandb_agent - INFO - Cleaning up finished run: r223bxfl
2022-09-02 17:22:22,414 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:22:22,414 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0001564659766219411
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:22:22,426 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0001564659766219411 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:22:27,436 - wandb.wandb_agent - INFO - Running runs: ['popfnknb']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172227-popfnknb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-1057
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/popfnknb
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4622884465117516 seconds), retrying request
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1461536565621713 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.877900575871911 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▆▆▆▅▆▆▆▇▇▆▆▆▆▅▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▆▆▇▇▆▆▆▆▆▇▇▇███▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▂██▅▁▁▇▄▁▁▄▁▁▇▄▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.999
wandb:  prop_3 0.0
wandb: prop_NA 0.001
wandb:  reward 0.83716
wandb: 
wandb: Synced true-sweep-1057: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/popfnknb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172227-popfnknb/logs
2022-09-02 17:23:50,318 - wandb.wandb_agent - INFO - Cleaning up finished run: popfnknb
2022-09-02 17:23:50,621 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:23:50,622 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00014500630899629338
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:23:50,647 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00014500630899629338 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:23:55,660 - wandb.wandb_agent - INFO - Running runs: ['5o166nhz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172356-5o166nhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-1070
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5o166nhz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2569103998163937 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0992054673818417 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.953037748813922 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.453146872718549 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▆▇▇▇███▇▇▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▇█▇███████▇▇▇▇▇▇▇█▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇▇▇▇▇█████▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▃▁▁█▇▁▁▁█▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced denim-sweep-1070: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/5o166nhz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172356-5o166nhz/logs
2022-09-02 17:25:28,420 - wandb.wandb_agent - INFO - Cleaning up finished run: 5o166nhz
2022-09-02 17:25:28,733 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:25:28,733 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00036011314997888555
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:25:28,741 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00036011314997888555 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:25:33,755 - wandb.wandb_agent - INFO - Running runs: ['aiauxc3i']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172533-aiauxc3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-1087
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/aiauxc3i
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1439407268340602 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.801228552189836 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.275939146147437 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▂▃▅▆▇█████▇▇▇
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇███▇▆▅▅▄▄▄▄▄▄▄▄▄
wandb:  prop_3 ▇▇▆▇▇▇▇▇▇██▇▇█▇█▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████▇██████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▁▇▁▁██▁▁▁▁▄▁▆▁█▂███▇█▇▆▅▆▇▄██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.486
wandb:  prop_2 0.508
wandb:  prop_3 0.0
wandb: prop_NA 0.006
wandb:  reward 1.0
wandb: 
wandb: Synced rose-sweep-1087: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/aiauxc3i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172533-aiauxc3i/logs
2022-09-02 17:26:56,485 - wandb.wandb_agent - INFO - Cleaning up finished run: aiauxc3i
2022-09-02 17:26:56,789 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:26:56,789 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.04920641614121674
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:26:56,802 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.04920641614121674 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:27:01,816 - wandb.wandb_agent - INFO - Running runs: ['wrr64gj0']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172702-wrr64gj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-1099
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wrr64gj0
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.173456738451798 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.904125067002424 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▆▆▇▇▇▇▇███▇▇▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▇▆▇▆▆▆▆▆▇▇▇▇█▇▇▇▇▆▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇███████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced revived-sweep-1099: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/wrr64gj0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172702-wrr64gj0/logs
2022-09-02 17:28:29,479 - wandb.wandb_agent - INFO - Cleaning up finished run: wrr64gj0
2022-09-02 17:28:29,766 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:28:29,766 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00015108910169055626
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:28:29,781 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00015108910169055626 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:28:34,804 - wandb.wandb_agent - INFO - Running runs: ['ity803zu']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_172837-ity803zu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-1113
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ity803zu
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4072437189988904 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.068386613502177 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.167911622933853 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2712471892385167 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇██▇▇▆▅▅▄▅▅▅▅▅
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▃▃▄▄▆▇███▇▇▇▇
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▇█▇▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇▇▇▇▇██▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▅▄▁▁▁▆▁▁▁▁█▅▁▇▁▄▅▄▄▅▆█▇▂▅▆▇▄██▇█████
wandb: 
wandb: Run summary:
wandb:  prop_1 0.489
wandb:  prop_2 0.495
wandb:  prop_3 0.0
wandb: prop_NA 0.016
wandb:  reward 1.0
wandb: 
wandb: Synced helpful-sweep-1113: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ity803zu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_172837-ity803zu/logs
2022-09-02 17:29:57,822 - wandb.wandb_agent - INFO - Cleaning up finished run: ity803zu
2022-09-02 17:29:58,135 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:29:58,136 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.04975278452857824
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:29:58,164 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.04975278452857824 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:30:03,180 - wandb.wandb_agent - INFO - Running runs: ['gzetcit1']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173006-gzetcit1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-1127
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gzetcit1
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.022024544832494 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2132805111295473 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.749598350249042 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.15713324982113 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.005796649463445 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.236121095505842 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▅▆▆▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇██▇▇▇████▇▇▇▆▆▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▄▁▁▁█▁▁▁█▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced sage-sweep-1127: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gzetcit1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173006-gzetcit1/logs
2022-09-02 17:31:36,102 - wandb.wandb_agent - INFO - Cleaning up finished run: gzetcit1
2022-09-02 17:31:36,425 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:31:36,432 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0004260607419586084
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:31:36,439 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0004260607419586084 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:31:41,453 - wandb.wandb_agent - INFO - Running runs: ['m73yar2p']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173142-m73yar2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-1143
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m73yar2p
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1366897468382255 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.43839913708838 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2313725538124998 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1731992223786682 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.102233725711168 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▅▆██▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▄▆▇████████████
wandb:  prop_3 ▆▅▆▆▆▆▇▇▇████▇▇▇▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████▇███████▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▇▁▁▁▁▁██▅▁▁▁▁▁█▃▅▅▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.051
wandb:  prop_2 0.949
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced upbeat-sweep-1143: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/m73yar2p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173142-m73yar2p/logs
2022-09-02 17:33:07,157 - wandb.wandb_agent - INFO - Cleaning up finished run: m73yar2p
2022-09-02 17:33:07,463 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:33:07,469 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005250443364236777
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:33:07,482 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005250443364236777 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:33:12,496 - wandb.wandb_agent - INFO - Running runs: ['dguoeuls']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173314-dguoeuls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-1158
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dguoeuls
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.266644580408238 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.691212410472801 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.388147831769013 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▇▇▇█▇▇▇▇▆▇▇▇▇██▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇█▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▄█▁▁▁█▁▄▁▁▄█▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced expert-sweep-1158: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/dguoeuls
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173314-dguoeuls/logs
2022-09-02 17:34:34,991 - wandb.wandb_agent - INFO - Cleaning up finished run: dguoeuls
2022-09-02 17:34:35,284 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:34:35,284 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.021932847687027593
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:34:35,300 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.021932847687027593 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:34:40,313 - wandb.wandb_agent - INFO - Running runs: ['qm2klr45']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173442-qm2klr45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-1170
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qm2klr45
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.074785901554353 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2897845815712667 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3161229235495915 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.29090337527956 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▆▆▇▇▇▇▇▇▇██████▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▆▆▆▆▇▇▇▇▆▆▆▆▆▆▆▆▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████▇█▇▇████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▇▁▁▅▁▁▁▂█▆▁▁█▇▁▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced vital-sweep-1170: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qm2klr45
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173442-qm2klr45/logs
2022-09-02 17:36:08,022 - wandb.wandb_agent - INFO - Cleaning up finished run: qm2klr45
2022-09-02 17:36:08,358 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:36:08,364 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0027175854637525782
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:36:08,373 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0027175854637525782 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:36:13,386 - wandb.wandb_agent - INFO - Running runs: ['pekl9gzl']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173612-pekl9gzl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-1189
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pekl9gzl
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2912556050498543 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.651114543429623 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.454849853337871 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.145075228334245 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▇▇▇█▇▇▆▆▆▆▇███▇▇▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▆▆▆▆▇▇▆▇▆▆▇▇▆▆▆▅▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████▇▇█████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃█▁▁▅▁▄▁▂▁▁▁▅██▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced summer-sweep-1189: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/pekl9gzl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173612-pekl9gzl/logs
2022-09-02 17:37:41,171 - wandb.wandb_agent - INFO - Cleaning up finished run: pekl9gzl
2022-09-02 17:37:41,486 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:37:41,486 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.03874805219825372
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:37:41,496 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.03874805219825372 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:37:46,508 - wandb.wandb_agent - INFO - Running runs: ['rys50edr']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173746-rys50edr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-1203
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rys50edr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2340822453499327 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.99648787361111 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.403321193786229 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.080286350686162 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.411809326727772 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▆▆▇▇█▇▇▇▇▇▆▆▆▇▇█▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA █▇██████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▄▁▁▁▁▁▁▁▁▇▁█▆█▁▇▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced celestial-sweep-1203: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/rys50edr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173746-rys50edr/logs
2022-09-02 17:39:08,918 - wandb.wandb_agent - INFO - Cleaning up finished run: rys50edr
2022-09-02 17:39:09,195 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:39:09,195 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00011141501964641927
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:39:09,202 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00011141501964641927 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:39:14,215 - wandb.wandb_agent - INFO - Running runs: ['mu1qcej4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_173913-mu1qcej4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-1216
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mu1qcej4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.216648191504061 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8798869468138 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1123829795861906 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8770628935516305 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.391077129147794 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.006 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▆▇▇▇████▆▆▆▆▇█▇█▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▇▇▇▇▆▆▇▇████▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▇█▁▁█▁▅▁▁▅▁▁▇█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced stellar-sweep-1216: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mu1qcej4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_173913-mu1qcej4/logs
2022-09-02 17:40:41,813 - wandb.wandb_agent - INFO - Cleaning up finished run: mu1qcej4
2022-09-02 17:40:42,120 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:40:42,125 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004672952551645231
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:40:42,132 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004672952551645231 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:40:47,148 - wandb.wandb_agent - INFO - Running runs: ['jb78qc7x']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174046-jb78qc7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-1233
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jb78qc7x
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3390839993593553 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.688060250860061 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.326261019028461 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.807593401508708 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.367299213426854 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▇▇▇████▇▆▆▆▆▆▇▇▇▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▇▇▇▇▇▇▇████▇▇▇▇▇▇█▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁▄▁█▅▁█▂▁▁▁▁▇▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced bright-sweep-1233: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jb78qc7x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174046-jb78qc7x/logs
2022-09-02 17:42:14,712 - wandb.wandb_agent - INFO - Cleaning up finished run: jb78qc7x
2022-09-02 17:42:15,009 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:42:15,009 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.049190299522791504
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:42:15,017 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.049190299522791504 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:42:20,037 - wandb.wandb_agent - INFO - Running runs: ['ryuls46l']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174219-ryuls46l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-1249
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ryuls46l
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0914084551579695 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0023578653532295 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.580557271738311 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.385628097670381 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▇▇█▇▇▇▇████▇█▇▇▇▇▇▇▇▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▅▆▆▆▆▇███▇█▇▇▇▇▇█▇▇▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▇▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced fearless-sweep-1249: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ryuls46l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174219-ryuls46l/logs
2022-09-02 17:43:52,855 - wandb.wandb_agent - INFO - Cleaning up finished run: ryuls46l
2022-09-02 17:43:53,117 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:43:53,118 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03302515241605147
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:43:53,125 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03302515241605147 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:43:58,139 - wandb.wandb_agent - INFO - Running runs: ['ed97isz4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174357-ed97isz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-1264
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ed97isz4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3728060314208554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.558553661917041 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3818038808948785 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.432654621076397 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▆▇▇███▇▇████▇▇▇▇▆▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb:  prop_3 ███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁▃▁▁▇▁█▁▁▁█▆█▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced rare-sweep-1264: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ed97isz4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174357-ed97isz4/logs
2022-09-02 17:45:15,435 - wandb.wandb_agent - INFO - Cleaning up finished run: ed97isz4
2022-09-02 17:45:15,764 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:45:15,764 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04239601121791722
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:45:15,777 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04239601121791722 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:45:20,795 - wandb.wandb_agent - INFO - Running runs: ['nktwb10b']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174520-nktwb10b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-1276
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nktwb10b
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1524572443035312 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.524801751798346 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.392917165305486 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.070367174982796 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4291996253793418 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.862213988164585 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4841251784083105 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▇▇▇▆▆▆▆▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▅▁▄▁▅▁▁▁▁▁▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced zesty-sweep-1276: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/nktwb10b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174520-nktwb10b/logs
2022-09-02 17:46:43,320 - wandb.wandb_agent - INFO - Cleaning up finished run: nktwb10b
2022-09-02 17:46:43,647 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:46:43,651 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0017600998122289404
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:46:43,665 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0017600998122289404 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:46:48,682 - wandb.wandb_agent - INFO - Running runs: ['j9eux1lx']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174650-j9eux1lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-1289
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j9eux1lx
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.384246643727552 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4075013472684206 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.325606253576943 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4483044354578825 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.402606773807037 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4370718816465873 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▆▆▆▆▆▇▇▇▇▇▇▆▆▆▆▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▇████▇▇▇▆▇▇▆▇▇▇█▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA █▇▇█████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▁▁▁▁▁▁▁▁▅▁▁▁▇▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced stilted-sweep-1289: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/j9eux1lx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174650-j9eux1lx/logs
2022-09-02 17:48:16,297 - wandb.wandb_agent - INFO - Cleaning up finished run: j9eux1lx
2022-09-02 17:48:16,625 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:48:16,630 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.007416276239998076
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:48:16,640 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.007416276239998076 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:48:21,653 - wandb.wandb_agent - INFO - Running runs: ['b9fp38gr']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174821-b9fp38gr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-1304
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b9fp38gr
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1594427855720335 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.918277696778342 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.153073429862023 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.636223140463283 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.274696924474953 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▆▆▆▆▆▆▇▇▆▇▇█▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▆▇▆▇▇▇█▇██▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇██████████▇▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced drawn-sweep-1304: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b9fp38gr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174821-b9fp38gr/logs
2022-09-02 17:49:44,098 - wandb.wandb_agent - INFO - Cleaning up finished run: b9fp38gr
2022-09-02 17:49:44,387 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:49:44,392 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.04203634549185205
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:49:44,401 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.04203634549185205 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:49:49,416 - wandb.wandb_agent - INFO - Running runs: ['ivy5yr1g']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_174949-ivy5yr1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-1317
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ivy5yr1g
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.315390577472699 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8298615326318 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.292682184476958 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.415183177663462 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1103108746247314 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.633262685918005 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▇▇▇▇▇▇▆▆▆▆▆▇▇██▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ███▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇▇█████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▁▁▁▄█▁▁▁▁▅▁▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced vibrant-sweep-1317: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ivy5yr1g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_174949-ivy5yr1g/logs
2022-09-02 17:51:12,257 - wandb.wandb_agent - INFO - Cleaning up finished run: ivy5yr1g
2022-09-02 17:51:12,535 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:51:12,540 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.005430227704263533
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:51:12,551 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.005430227704263533 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:51:17,565 - wandb.wandb_agent - INFO - Running runs: ['kni97vva']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175118-kni97vva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-1330
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kni97vva
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1586319173647652 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.578022235736835 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1731633157821197 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1056396466198333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.467599563666356 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇█▇▇▇▆▆▆▆▇▇▆▆▆▆▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▅▆▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ███████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂▁▁▁██▁▁█▁▁▁██▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced fiery-sweep-1330: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kni97vva
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175118-kni97vva/logs
2022-09-02 17:52:40,033 - wandb.wandb_agent - INFO - Cleaning up finished run: kni97vva
2022-09-02 17:52:40,340 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:52:40,346 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.002634424499133801
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:52:40,356 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.002634424499133801 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:52:45,371 - wandb.wandb_agent - INFO - Running runs: ['o9f227ui']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175246-o9f227ui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-1344
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o9f227ui
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0359724912851798 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.34217073891552 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441299829099081 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.347333449305838 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8293373302469815 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▄▇▇▇▇▇▇█▇▇▇▇▇██▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▇▆▇████▇▇▇▇▇▇█▇▇█▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▃▅▄▁▅▁▁▁▁▁██▁█▆▃▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced neat-sweep-1344: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/o9f227ui
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175246-o9f227ui/logs
2022-09-02 17:54:12,968 - wandb.wandb_agent - INFO - Cleaning up finished run: o9f227ui
2022-09-02 17:54:13,268 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:54:13,268 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0006005672728660372
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:54:13,278 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0006005672728660372 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:54:18,291 - wandb.wandb_agent - INFO - Running runs: ['gfok1bde']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175417-gfok1bde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-1361
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gfok1bde
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.031066830399236 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4855818706501216 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2716408072568495 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3807176381701733 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.330846854879907 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.28035939782992 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.669761112523819 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▇▇▇███▇▇▇▇██▇▇▇▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▆▅▅▅▅▅▅▅▅▅▅▆▅▅▅▄▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇▇██▇▇██████▇██████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▁▂▇█▁▁█▁▁█▁▁▁▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced woven-sweep-1361: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/gfok1bde
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175417-gfok1bde/logs
2022-09-02 17:55:40,785 - wandb.wandb_agent - INFO - Cleaning up finished run: gfok1bde
2022-09-02 17:55:41,264 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:55:41,269 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0011704797646439945
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:55:41,283 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0011704797646439945 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:55:46,299 - wandb.wandb_agent - INFO - Running runs: ['iq81jho7']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175545-iq81jho7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-1374
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iq81jho7
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0341206679934873 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.411313243269166 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1602369525349454 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.338402248234886 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4370028303429643 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.908581189043073 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇███▇▆▆▆▇▇▇▇▇▇█▇█▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇▇▆▆▇▆▆▇▇▆▇▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ██▇▇▇███████████▇███▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▇▁▁▁▁▁▁▇▁█▁▁▁▆█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced visionary-sweep-1374: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/iq81jho7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175545-iq81jho7/logs
2022-09-02 17:57:08,696 - wandb.wandb_agent - INFO - Cleaning up finished run: iq81jho7
2022-09-02 17:57:09,061 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:57:09,068 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0011330360131242825
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:57:09,078 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0011330360131242825 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 17:57:14,091 - wandb.wandb_agent - INFO - Running runs: ['7y93ixev']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175713-7y93ixev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-1389
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7y93ixev
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4908696632992173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1247339297530767 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4955850656823304 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.284093219827583 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3422459514967033 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.747511683961572 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▇████████████████
wandb:  prop_2 ▆▆▇▇▇▇▇██▇▇▇▆▆▇▇▇████▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▇▇▇▇▇█▇▇███▇▇▇▇▇▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇▇█▇▇▇▇▇██▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▇▄▁▁▄▇▇▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.971
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.029
wandb:  reward 1.0
wandb: 
wandb: Synced jolly-sweep-1389: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7y93ixev
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175713-7y93ixev/logs
2022-09-02 17:58:36,507 - wandb.wandb_agent - INFO - Cleaning up finished run: 7y93ixev
2022-09-02 17:58:36,782 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 17:58:36,787 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.007150787062176624
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 17:58:36,795 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.007150787062176624 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 17:58:41,810 - wandb.wandb_agent - INFO - Running runs: ['7t63rkev']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_175842-7t63rkev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-1401
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7t63rkev
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.149270766727485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2393974286086022 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0433598293367026 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.505358678256545 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▆▅▅▅▅▅▅▅▅▅▅▅▅▄▄▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▄▅▅▅▆▆▆▆▆▆▇▇▇█▇▇▇▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▇▁▁▃▅▁▁▇▁▁▁▁▁▁▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced morning-sweep-1401: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/7t63rkev
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_175842-7t63rkev/logs
2022-09-02 18:00:04,303 - wandb.wandb_agent - INFO - Cleaning up finished run: 7t63rkev
2022-09-02 18:00:04,651 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:00:04,651 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00206543881228418
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:00:04,659 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00206543881228418 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:00:09,670 - wandb.wandb_agent - INFO - Running runs: ['aj0w4goi']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180011-aj0w4goi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-1415
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/aj0w4goi
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.178090385817151 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2813445990533388 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.145142718297161 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.462161075307793 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.185012640452186 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.3718802470298606 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▅▆▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▇▆▇▆▆▇▆▇▇███▇▇▇▇▇▇▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁▇▅▁█▁▁▁█▁▁▇▇▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced glowing-sweep-1415: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/aj0w4goi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180011-aj0w4goi/logs
2022-09-02 18:01:32,444 - wandb.wandb_agent - INFO - Cleaning up finished run: aj0w4goi
2022-09-02 18:01:32,716 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:01:32,717 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.03587386320270598
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:01:32,735 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.03587386320270598 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:01:37,748 - wandb.wandb_agent - INFO - Running runs: ['4z57rxyh']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180138-4z57rxyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-1428
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4z57rxyh
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2462798631226173 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.17456090723101 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.460738089676304 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇██▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁█▁▇▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.969
wandb:  prop_3 0.0
wandb: prop_NA 0.031
wandb:  reward 0.83716
wandb: 
wandb: Synced trim-sweep-1428: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4z57rxyh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180138-4z57rxyh/logs
2022-09-02 18:03:00,245 - wandb.wandb_agent - INFO - Cleaning up finished run: 4z57rxyh
2022-09-02 18:03:00,500 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:03:00,505 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.013096663877558734
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:03:00,512 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.013096663877558734 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:03:05,525 - wandb.wandb_agent - INFO - Running runs: ['regnjwla']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180307-regnjwla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-1443
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/regnjwla
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1116028186619333 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1665913331637077 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.029448255122031 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0652026918423454 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▆▆▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ██▇▇▇▆▆▆▆▇▇█▇▇▇▇▇▇▆▆▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▁▁▁▁▅▆▅▁█▆▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced zesty-sweep-1443: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/regnjwla
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180307-regnjwla/logs
2022-09-02 18:04:33,200 - wandb.wandb_agent - INFO - Cleaning up finished run: regnjwla
2022-09-02 18:04:33,492 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:04:33,492 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0005688374694779335
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:04:33,500 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0005688374694779335 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:04:38,513 - wandb.wandb_agent - INFO - Running runs: ['kbdss95r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180439-kbdss95r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-1459
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kbdss95r
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3949541820497284 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.884946985502065 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1165942221632923 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.187064203993893 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2418020230732796 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▆▆▆▅▅▅▆▆▆▆▆▇▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▃▅▆▆▆▇█▇██▇█▇▇█▇▇▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁█▁▁▁▁▅▁▁▁▁▁▁▄█▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.998
wandb: prop_NA 0.002
wandb:  reward 0.92352
wandb: 
wandb: Synced sparkling-sweep-1459: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kbdss95r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180439-kbdss95r/logs
2022-09-02 18:06:06,250 - wandb.wandb_agent - INFO - Cleaning up finished run: kbdss95r
2022-09-02 18:06:12,203 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:06:12,208 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.004872360647169263
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:06:12,216 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.004872360647169263 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:06:17,230 - wandb.wandb_agent - INFO - Running runs: ['8dvv79v9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180616-8dvv79v9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-1476
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8dvv79v9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.469315988828411 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2448797209271656 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.433968312272676 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.337316191263919 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1687225537471373 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.65639543795673 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅█▇▇▇▆▇▆▆▆▆▇▇▇▆▆▇▆▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▇▆▆▆▆▆▇▇▆▆▇███▇███▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇███████████████▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▁▁█▁▁▇▁▁▅█▇▆▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced iconic-sweep-1476: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/8dvv79v9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180616-8dvv79v9/logs
2022-09-02 18:07:39,768 - wandb.wandb_agent - INFO - Cleaning up finished run: 8dvv79v9
2022-09-02 18:07:40,060 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:07:40,061 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00015431327074606047
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:07:40,068 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00015431327074606047 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:07:45,080 - wandb.wandb_agent - INFO - Running runs: ['qbdtqnmq']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180744-qbdtqnmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-1491
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qbdtqnmq
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.376467112311577 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.480630763871882 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.301553062315347 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.162156627863693 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4687963088845315 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▆▇▇▇▇██▇▇▇▆▇▇▇▇▇███▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃
wandb:  prop_3 ▅▅▆▆▆▇▇▇███▇▇▆▇▇▇▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████████████▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▄▁▁█▁███▁▄▇▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.967
wandb:  prop_2 0.029
wandb:  prop_3 0.0
wandb: prop_NA 0.004
wandb:  reward 1.0
wandb: 
wandb: Synced super-sweep-1491: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qbdtqnmq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180744-qbdtqnmq/logs
2022-09-02 18:09:07,619 - wandb.wandb_agent - INFO - Cleaning up finished run: qbdtqnmq
2022-09-02 18:09:07,953 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:09:07,953 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.001861570402832936
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:09:07,965 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.001861570402832936 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:09:12,980 - wandb.wandb_agent - INFO - Running runs: ['jast7mpy']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_180913-jast7mpy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-1505
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jast7mpy
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.02622622680032 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.689309412332154 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3554371104676557 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.266370611663345 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.313128490455766 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.198463809812646 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▇▇███▇▇▇▇▇▇▇▇▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇▆▆▆▇▇▇▇▇▇█▇▇▇▇███▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██████████▇█████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁█▅▁▁▁▁▁▅▁▇▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced upbeat-sweep-1505: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jast7mpy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_180913-jast7mpy/logs
2022-09-02 18:10:35,712 - wandb.wandb_agent - INFO - Cleaning up finished run: jast7mpy
2022-09-02 18:10:37,864 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:10:37,870 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.009702280379708356
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:10:37,878 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.009702280379708356 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:10:42,893 - wandb.wandb_agent - INFO - Running runs: ['detmqrxv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181043-detmqrxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1521
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/detmqrxv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.133769424927812 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.529786778395621 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0389465279066883 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1883596834424135 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.589698089561661 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.008 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▇▇▇▇▇▇▆▇▇▇█████▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▇▇▇▆▆▆▇████▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇█▇███████▇▇▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁██▁▁▁▁▁▁▇▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced copper-sweep-1521: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/detmqrxv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181043-detmqrxv/logs
2022-09-02 18:12:05,458 - wandb.wandb_agent - INFO - Cleaning up finished run: detmqrxv
2022-09-02 18:12:05,767 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:12:05,772 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0002608433667147732
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:12:05,834 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0002608433667147732 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:12:10,850 - wandb.wandb_agent - INFO - Running runs: ['ks5n8dci']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181212-ks5n8dci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-1533
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ks5n8dci
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4826777886762357 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.431233762850417 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.39869588135715 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2343512930465774 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.071760023291473 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████▇▇▇▆▅▄▄▃
wandb:  prop_2 ▅▆▇▇▇▇▆▆▆▆▇▇▇▇██▇▇▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▃▄▅▇██
wandb: prop_NA ██████████████▇▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▃▁▁█▁▁▄▁▁▄▁▁▁▁▁▇▁█▃▅▅▆▂▇▂▅▁▇█▇▄▇█▃███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.403
wandb:  prop_2 0.0
wandb:  prop_3 0.593
wandb: prop_NA 0.004
wandb:  reward 0.0
wandb: 
wandb: Synced volcanic-sweep-1533: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ks5n8dci
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181212-ks5n8dci/logs
2022-09-02 18:13:34,075 - wandb.wandb_agent - INFO - Cleaning up finished run: ks5n8dci
2022-09-02 18:13:34,373 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:13:34,374 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.00010702610094914846
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:13:34,390 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.00010702610094914846 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:13:39,405 - wandb.wandb_agent - INFO - Running runs: ['z1m8wifw']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181340-z1m8wifw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-1546
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z1m8wifw
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.00222793625798 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.077703921303917 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.268839309364182 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2051765003615507 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.972009630251287 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▇▇████████▇▇▇▇▇▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▆▆▆▇▇▇▇▇▇▇▇██████▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▃▅▄█▇▁▁▁▁▁█▇▇█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced stellar-sweep-1546: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z1m8wifw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181340-z1m8wifw/logs
2022-09-02 18:15:01,936 - wandb.wandb_agent - INFO - Cleaning up finished run: z1m8wifw
2022-09-02 18:15:02,241 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:15:02,241 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0003341213489392529
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:15:02,258 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0003341213489392529 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:15:07,272 - wandb.wandb_agent - INFO - Running runs: ['qe5un83r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181511-qe5un83r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-1560
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qe5un83r
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1959273668722448 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2915094632979143 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.150667326957139 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.557832807060958 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.367823956839318 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.895895240015433 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇██▇▇▇▇▇▇██▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▆▆▇▆▇▇▇▇▇▆▇███▇▇▆▇▆▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄██▁▁▁▅▁█▇▁▄▁▁▅▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced pretty-sweep-1560: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/qe5un83r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181511-qe5un83r/logs
2022-09-02 18:16:40,141 - wandb.wandb_agent - INFO - Cleaning up finished run: qe5un83r
2022-09-02 18:16:40,801 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:16:40,801 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.012544643056930496
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:16:40,810 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.012544643056930496 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:16:45,824 - wandb.wandb_agent - INFO - Running runs: ['v3eq4por']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181645-v3eq4por
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1578
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v3eq4por
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2296134876619766 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.260929712319881 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.163438309558866 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4654007419644515 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇▇▇▇▇▇▇▇▆▆▆▇▇██▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▅▆▅▆▆▆▇▆▇▇▇█▇▆▇▆▆▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████████▇██████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▃▁█▁▁▁▁█▁▇▁▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced copper-sweep-1578: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/v3eq4por
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181645-v3eq4por/logs
2022-09-02 18:18:08,293 - wandb.wandb_agent - INFO - Cleaning up finished run: v3eq4por
2022-09-02 18:18:08,593 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:18:08,594 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0004322373429726965
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:18:08,602 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0004322373429726965 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:18:13,614 - wandb.wandb_agent - INFO - Running runs: ['6tud0jz2']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181812-6tud0jz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-1591
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6tud0jz2
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1479076394246883 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4498815028982985 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.203413216874439 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.337163032796204 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.202363524016318 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.550261896204502 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2101042789620386 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▆▇▆▆▇▇███▇▇▆▆▆▅▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▄▅▅▅▄▄▄▄▅▅▅▅▄▅▅▅▅▅▄▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▂▂▃▄▅█
wandb:  prop_3 ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████▇▇▇▆
wandb: prop_NA ▇▇▇█████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.216
wandb:  prop_3 0.752
wandb: prop_NA 0.032
wandb:  reward 0.83716
wandb: 
wandb: Synced daily-sweep-1591: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6tud0jz2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181812-6tud0jz2/logs
2022-09-02 18:19:41,182 - wandb.wandb_agent - INFO - Cleaning up finished run: 6tud0jz2
2022-09-02 18:19:41,504 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:19:41,504 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0011768274438388004
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:19:41,513 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0011768274438388004 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:19:46,526 - wandb.wandb_agent - INFO - Running runs: ['b9bmcdtz']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_181946-b9bmcdtz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-1606
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b9bmcdtz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.19579085901343 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.178369552682933 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.271664315633289 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.161746800629344 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0140868483531844 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4469899925138545 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇██▇█▇▇▇▇▇▇▆▆▆▇▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇██▇▇▆▇▇▇▆▆▆▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ▇▇▇█▇▇▇▇▇███▇███████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▅▁▇▂▁▃▅▁▇▁▁██▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 0.967
wandb: prop_NA 0.033
wandb:  reward 0.92352
wandb: 
wandb: Synced frosty-sweep-1606: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b9bmcdtz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_181946-b9bmcdtz/logs
2022-09-02 18:21:14,091 - wandb.wandb_agent - INFO - Cleaning up finished run: b9bmcdtz
2022-09-02 18:21:14,400 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:21:14,401 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0116619763703564
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:21:14,410 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0116619763703564 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:21:19,422 - wandb.wandb_agent - INFO - Running runs: ['2r0d741f']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182118-2r0d741f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-1621
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2r0d741f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.29404377979869 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2470376751830354 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4507276771967286 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1213123140840526 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.488601076768775 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇█▇▇▇▇▇▇▇▇▇▇█▇▆▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▂▄▄▄▃▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇█████████▇▇▇▇███
wandb:  prop_3 ██▇▇▇▆▆▇▆▇▇▇▇▇▇▇▇▇██▇▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █▇██████████████████▇▅▄▂▁▁▁▁▂▁▁▁▁▁▁▂▂▂▂▁
wandb:  reward ▁▁▅▁▁▄▁▁▁▆▁▁▄▁▅▄▁█▇▁▂███▇█▂▆▄▆▄▄██▆▁█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.951
wandb:  prop_3 0.0
wandb: prop_NA 0.049
wandb:  reward 0.83716
wandb: 
wandb: Synced dark-sweep-1621: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2r0d741f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182118-2r0d741f/logs
2022-09-02 18:22:41,798 - wandb.wandb_agent - INFO - Cleaning up finished run: 2r0d741f
2022-09-02 18:22:42,094 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:22:42,095 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.006928373114563285
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:22:42,102 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.006928373114563285 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:22:47,115 - wandb.wandb_agent - INFO - Running runs: ['b7ddkqpv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182247-b7ddkqpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-1635
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b7ddkqpv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.403271142686063 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.409359938304432 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.159706370231422 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0808080604083297 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.585193438110521 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.131695910938272 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇████▇▇▇█▇▇▇▆▆▇▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▅▆▅▅▅▅▅▅▆▆▆▆▅▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ▇▇▇████████████████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁█▁▇▁▁▁▁▂▁▁▁▁▁▁▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced ethereal-sweep-1635: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/b7ddkqpv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182247-b7ddkqpv/logs
2022-09-02 18:24:09,589 - wandb.wandb_agent - INFO - Cleaning up finished run: b7ddkqpv
2022-09-02 18:24:09,891 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:24:09,892 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0061718769328149535
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:24:09,900 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0061718769328149535 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:24:14,913 - wandb.wandb_agent - INFO - Running runs: ['aa4qvbr8']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182415-aa4qvbr8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-1649
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/aa4qvbr8
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3303442913820547 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.244951556017766 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3371827093449578 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2410637323348315 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 ▇█▇██▇█▇▇▇▇██▇▇▇▇▇▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████▇▇▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▃█▁▄▅▁▁▁▇▁▁▁▁▁▁▁██▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced atomic-sweep-1649: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/aa4qvbr8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182415-aa4qvbr8/logs
2022-09-02 18:25:42,648 - wandb.wandb_agent - INFO - Cleaning up finished run: aa4qvbr8
2022-09-02 18:25:42,982 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:25:42,982 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.008930786401838316
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:25:42,989 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.008930786401838316 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:25:48,003 - wandb.wandb_agent - INFO - Running runs: ['leczht9w']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182547-leczht9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-1664
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/leczht9w
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.023967897785342 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.474703165435663 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.154894504617684 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.215108206756116 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇████▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇█▇▇▇▆▇▇▇▇▆▆▆▇▇▇▇▇▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward █▁▁▃▁▁▄▃▁▁█▂▁██▁▇▁▃▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced colorful-sweep-1664: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/leczht9w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182547-leczht9w/logs
2022-09-02 18:27:05,346 - wandb.wandb_agent - INFO - Cleaning up finished run: leczht9w
2022-09-02 18:27:05,627 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:27:05,628 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0017525306700194264
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:27:05,637 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0017525306700194264 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:27:10,651 - wandb.wandb_agent - INFO - Running runs: ['sgen5dyv']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182710-sgen5dyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-1678
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sgen5dyv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3777772928982532 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.825215068241759 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.128998250354314 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.583903325874371 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3948016120614346 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ██████████▇▇▇▇█▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁█▁▅█▄▁▁▅▁█▄▁██▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced decent-sweep-1678: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/sgen5dyv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182710-sgen5dyv/logs
2022-09-02 18:28:33,121 - wandb.wandb_agent - INFO - Cleaning up finished run: sgen5dyv
2022-09-02 18:28:33,432 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:28:33,432 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00012949711612962115
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:28:33,442 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00012949711612962115 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:28:38,454 - wandb.wandb_agent - INFO - Running runs: ['z9tnn4r9']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_182838-z9tnn4r9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-1692
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z9tnn4r9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2771961331389403 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0880400900513485 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.942942878776905 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.047071085923819 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.189881890116539 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.280209043715709 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇█▇▇█▇▇█▇▇▆▆▆▆▇▆▇▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ██▇▇▇▇▇▇▇▇▇███████▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁▁▁▃▁▄▁▇█▁▁▁▁▁▃▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced vital-sweep-1692: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/z9tnn4r9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_182838-z9tnn4r9/logs
2022-09-02 18:30:06,116 - wandb.wandb_agent - INFO - Cleaning up finished run: z9tnn4r9
2022-09-02 18:30:06,459 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:30:06,459 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00043753165843481607
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:30:06,469 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00043753165843481607 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:30:11,482 - wandb.wandb_agent - INFO - Running runs: ['q8moqo16']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183012-q8moqo16
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-1708
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q8moqo16
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2253402489080285 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2509438627218925 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0047138065138648 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.718554368090874 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.342220631594392 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▇▇▇██▇▇▆▆▆▆▇▇▆▆▅▅▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇▅▆▆▆▇▇▇████▇▇▇▇▇█▇█▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇▇▇██▇█▇▇█████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁█▁█▁▁▁▄▁▂▁█▁▄▇▁▁█▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced northern-sweep-1708: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/q8moqo16
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183012-q8moqo16/logs
2022-09-02 18:31:34,403 - wandb.wandb_agent - INFO - Cleaning up finished run: q8moqo16
2022-09-02 18:31:34,711 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:31:34,711 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0014178138937711174
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:31:34,731 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0014178138937711174 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:31:39,745 - wandb.wandb_agent - INFO - Running runs: ['vpeedgk4']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183139-vpeedgk4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-1722
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vpeedgk4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3008368949321163 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0247446098127013 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1192196035428053 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▃▅▇███████████
wandb:  prop_2 ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▄▆▇██▆▄▂▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ██████████▇▇▇█▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▂▂▂▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▇▁▁▁▁▇▁▁▁▂███▇█▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 0.961
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.039
wandb:  reward 1.0
wandb: 
wandb: Synced fragrant-sweep-1722: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/vpeedgk4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183139-vpeedgk4/logs
2022-09-02 18:33:02,216 - wandb.wandb_agent - INFO - Cleaning up finished run: vpeedgk4
2022-09-02 18:33:02,528 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:33:02,528 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.04469259539232002
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:33:02,556 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.04469259539232002 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:33:07,572 - wandb.wandb_agent - INFO - Running runs: ['ryjryyan']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183307-ryjryyan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-1734
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ryjryyan
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3612493377139554 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.482757508018027 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.117320211835644 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.742740984657816 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.24478323548008 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.978223227333286 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇█▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 █▇▆▆▅▅▆▆▇▇███▇▇▇▆▆▆▆▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁█▁▁▁▄▁▁▄▇▆█▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced twilight-sweep-1734: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ryjryyan
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183307-ryjryyan/logs
2022-09-02 18:34:25,011 - wandb.wandb_agent - INFO - Cleaning up finished run: ryjryyan
2022-09-02 18:34:25,806 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:34:25,806 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0032122582901476814
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:34:25,833 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0032122582901476814 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:34:30,849 - wandb.wandb_agent - INFO - Running runs: ['bf7jnjx4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183432-bf7jnjx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-1744
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bf7jnjx4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3658332150787857 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.19574575844924 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.83736806287103 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.456359548569573 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.668141788690695 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ██▇▇▇▇▇▇▆▆▆▇▇▆▇▇▇▇▆▆▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▄▁▁▁█▄▁▁▁▇██▁█▁▁█▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced drawn-sweep-1744: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/bf7jnjx4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183432-bf7jnjx4/logs
2022-09-02 18:35:53,439 - wandb.wandb_agent - INFO - Cleaning up finished run: bf7jnjx4
2022-09-02 18:35:53,739 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:35:53,739 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.001098288278119732
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:35:53,754 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.001098288278119732 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:35:58,776 - wandb.wandb_agent - INFO - Running runs: ['ngqjka8f']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183600-ngqjka8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-1760
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ngqjka8f
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.131492620312694 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.029301445680462 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.715957455585789 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4576254309739882 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.043261911882957 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 █▆▆▇███▇▆▇▇▇▇▇███▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▆▅▅▆▇▇██▇▇▆▆▇███▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇█████▇███████▇████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▇▅▁▁▁▁███▁▁▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced clean-sweep-1760: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ngqjka8f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183600-ngqjka8f/logs
2022-09-02 18:37:26,607 - wandb.wandb_agent - INFO - Cleaning up finished run: ngqjka8f
2022-09-02 18:37:26,918 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:37:26,922 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.017271947712098463
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:37:26,931 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.017271947712098463 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:37:31,943 - wandb.wandb_agent - INFO - Running runs: ['kpk9il4i']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183733-kpk9il4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-1776
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kpk9il4i
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4317757187122964 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2934331530571983 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2026080418196248 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.809170689543778 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0680229640061087 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▇▇▆▆▆▇▇▇▆▆▆▆▆▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▆▇▇█▇▆▆▆▆▇▇▇▇▆▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁██▁▁▁▁▁▁▁█▁▁▁██▁▆▁▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced comfy-sweep-1776: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/kpk9il4i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183733-kpk9il4i/logs
2022-09-02 18:38:54,480 - wandb.wandb_agent - INFO - Cleaning up finished run: kpk9il4i
2022-09-02 18:38:54,778 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:38:54,778 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.003692365770683693
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:38:54,792 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.003692365770683693 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:38:59,807 - wandb.wandb_agent - INFO - Running runs: ['2tnp2qdv']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_183859-2tnp2qdv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-1790
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2tnp2qdv
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.295547510521762 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3371438147818155 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.289545837394354 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.4804196192298145 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.139758707086121 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.50674676662011 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▇▇▇▇▇▇▇▇▇▇█▇██████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 █▇▇▆▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇███████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▆▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced northern-sweep-1790: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/2tnp2qdv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_183859-2tnp2qdv/logs
2022-09-02 18:40:27,451 - wandb.wandb_agent - INFO - Cleaning up finished run: 2tnp2qdv
2022-09-02 18:40:27,861 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:40:27,867 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.006865927065561676
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:40:27,880 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.006865927065561676 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:40:32,895 - wandb.wandb_agent - INFO - Running runs: ['md03bd88']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184034-md03bd88
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-1806
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/md03bd88
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3412486006637363 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2784265319703607 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.456460801990071 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1910661171422015 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.039408302141914 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▆▆▆▆▇▇▇█▇▆▆▇▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ██▇▇▇▆▆▆▆▆▇▆▇▆▆▆▆▇▆▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▃▁▁▁▁▁▁▁▁▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced kind-sweep-1806: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/md03bd88
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184034-md03bd88/logs
2022-09-02 18:42:00,558 - wandb.wandb_agent - INFO - Cleaning up finished run: md03bd88
2022-09-02 18:42:00,914 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:42:00,919 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0020899149310583663
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:42:00,929 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0020899149310583663 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:42:05,942 - wandb.wandb_agent - INFO - Running runs: ['yb22f6a9']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184205-yb22f6a9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-1823
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yb22f6a9
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3151022550042697 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3761263303421685 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2835868915452915 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.092915189943588 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0440247274999632 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.451257622500059 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_2 █▇▆▆▇▆▆▆▆▅▅▆▆▆▆▇▆▆▆▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▇▆▆▇▇████▇▇████▇▇▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ▇▇██████████████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▂█▁▅▁▇▁█▁▁▄█▆▁▁█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced curious-sweep-1823: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/yb22f6a9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184205-yb22f6a9/logs
2022-09-02 18:43:28,659 - wandb.wandb_agent - INFO - Cleaning up finished run: yb22f6a9
2022-09-02 18:43:28,969 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:43:28,969 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0008377157083457823
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:43:28,982 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0008377157083457823 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:43:33,994 - wandb.wandb_agent - INFO - Running runs: ['h50mjarz']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184334-h50mjarz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-1837
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h50mjarz
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0311007649692048 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.486240136522231 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.462546572834076 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.045482180044673 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.008 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_2 ▄▅▇▇▇█████▇█▇▇▇▆▅▆▆▇▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 █▇▇▇▇▇▆▆▆▆▆▆▇▇▆▆▆▆▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇████▇▇██████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▇▁▁▁▁▁▁▁█▆▁▅▇▁▁▄█▃▅▅▆▂▇▂▅▁▇▁▂▄▇█▁███
wandb: 
wandb: Run summary:
wandb:  prop_1 1.0
wandb:  prop_2 0.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 1.0
wandb: 
wandb: Synced soft-sweep-1837: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/h50mjarz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184334-h50mjarz/logs
2022-09-02 18:44:56,630 - wandb.wandb_agent - INFO - Cleaning up finished run: h50mjarz
2022-09-02 18:44:56,936 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:44:56,941 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0008284361662451162
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:44:56,954 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0008284361662451162 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:45:01,971 - wandb.wandb_agent - INFO - Running runs: ['hysbgk3r']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184503-hysbgk3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-1850
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hysbgk3r
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3917483126782004 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3547475371928184 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.063734379257072 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4427870426705187 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4779155299068556 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.006 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▆▆▆▇▇▇▇▇▆▆▆▆▆▇▇▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆▆▆▆▇▇▇████▇▇▇████▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂
wandb: prop_NA ███████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▄▁▁▁▁▁▁█▅▁▁██▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.964
wandb:  prop_3 0.021
wandb: prop_NA 0.015
wandb:  reward 0.83716
wandb: 
wandb: Synced twilight-sweep-1850: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/hysbgk3r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184503-hysbgk3r/logs
2022-09-02 18:46:34,968 - wandb.wandb_agent - INFO - Cleaning up finished run: hysbgk3r
2022-09-02 18:46:35,304 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:46:35,305 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.04555733206461042
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:46:35,313 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.04555733206461042 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:46:40,326 - wandb.wandb_agent - INFO - Running runs: ['jj15zikg']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184639-jj15zikg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-1867
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jj15zikg
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0139696995684373 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1850094708010244 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.9110805494334375 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.192352344097851 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0935391595751693 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.964942398430136 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▆▆▆▆▆▆▇▇▇▇▆▇▆▇▇▇███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▆██▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████▇███████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▄▁▅▁▁▁█▁█▁▅█▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced helpful-sweep-1867: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jj15zikg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184639-jj15zikg/logs
2022-09-02 18:48:08,042 - wandb.wandb_agent - INFO - Cleaning up finished run: jj15zikg
2022-09-02 18:48:08,401 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:48:08,401 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0204436626452775
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:48:08,440 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0204436626452775 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:48:13,457 - wandb.wandb_agent - INFO - Running runs: ['6zlm1f73']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184813-6zlm1f73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-1882
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6zlm1f73
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441011652795915 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.805443333973307 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2538793340947567 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0537781206424777 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.000193433175079 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ██▇▇▇▇▇▇▇▇██▇▇▇██▇█▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▆▇████████████████
wandb:  prop_3 ▃▆▇▇████▇▇▇█▇▆▆▇▆▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▄▁▁▇█▇▁▅▁▁▁▁▁▁▁▁▁▃▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced laced-sweep-1882: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/6zlm1f73
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184813-6zlm1f73/logs
2022-09-02 18:49:36,002 - wandb.wandb_agent - INFO - Cleaning up finished run: 6zlm1f73
2022-09-02 18:49:36,333 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:49:36,334 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.044467812141872176
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:49:36,344 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.044467812141872176 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:49:41,357 - wandb.wandb_agent - INFO - Running runs: ['llmkfdx5']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_184942-llmkfdx5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-1896
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/llmkfdx5
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2543704709688903 seconds), retrying request
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4191797886864546 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.646602497224077 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1519061213916975 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.854192771191061 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.30720054030623 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▆▆▆▆▇▇▇███▇▇▇▇▇██▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇██▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA ███████████████████▇▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁▁▁▁▁▁▁▁▁█▁▅▁▁▁██▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced lunar-sweep-1896: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/llmkfdx5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_184942-llmkfdx5/logs
2022-09-02 18:51:09,834 - wandb.wandb_agent - INFO - Cleaning up finished run: llmkfdx5
2022-09-02 18:51:10,169 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:51:10,169 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.0027686980130195815
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:51:10,179 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.0027686980130195815 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:51:15,191 - wandb.wandb_agent - INFO - Running runs: ['jifcwl03']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185114-jifcwl03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-1911
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jifcwl03
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0383319044838175 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.51610203833475 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.3242591922246403 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.930944798529165 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441313442394568 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▅▆▆▇▇▇▆▆▆▆▇▇▇▇████▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb:  prop_3 ▇█▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: prop_NA █████▇▇██████▇▇▇▇▇▇█▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▁▁█▁▁█▁▁▁▁▁▁▁█▇▁▁▁▂███▇█▂▆▄▆▄▄██▆▂█▅▃▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 1.0
wandb:  prop_3 0.0
wandb: prop_NA 0.0
wandb:  reward 0.83716
wandb: 
wandb: Synced icy-sweep-1911: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/jifcwl03
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185114-jifcwl03/logs
2022-09-02 18:52:42,863 - wandb.wandb_agent - INFO - Cleaning up finished run: jifcwl03
2022-09-02 18:52:43,212 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:52:43,213 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.0023307278502391654
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:52:43,227 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.0023307278502391654 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:52:48,241 - wandb.wandb_agent - INFO - Running runs: ['4uf06v78']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185248-4uf06v78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-1926
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4uf06v78
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4801978859957177 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.669788348062254 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.106134088585975 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.480359548263216 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.188249601274876 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▇▅▇▇▇██▇▇▆▇▇▇▇▇▇▇█▇▇▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇█▇▇▇▇▇████▇▇███▇▇▇█▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA █████████████▇█████▇▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅█▅▂▁▁█▄▁▂▁█▁▁█▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dutiful-sweep-1926: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/4uf06v78
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185248-4uf06v78/logs
2022-09-02 18:54:15,959 - wandb.wandb_agent - INFO - Cleaning up finished run: 4uf06v78
2022-09-02 18:54:16,277 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:54:16,308 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.00011512293096874009
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:54:16,316 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.00011512293096874009 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
2022-09-02 18:54:21,331 - wandb.wandb_agent - INFO - Running runs: ['za0h3r9i']
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185421-za0h3r9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1940
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/za0h3r9i
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.225057189794279 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.37861643166976 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.809084923193121 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.424436171144827 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.425762468703139 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.218092784071262 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▅█▇▆▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇█▇█▇▇▇██▇▇▇▇▇▇█▇▇▇▆▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▅▆████████████████
wandb: prop_NA █████████▇██████████▇▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ██▁▁▁▁▄▃▁▆█▁▁█▁▄█▁▁▇▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced copper-sweep-1940: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/za0h3r9i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185421-za0h3r9i/logs
2022-09-02 18:55:43,860 - wandb.wandb_agent - INFO - Cleaning up finished run: za0h3r9i
2022-09-02 18:55:44,145 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:55:44,146 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 2
	learning_rate: 0.0018219225260750812
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:55:44,151 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=2 --learning_rate=0.0018219225260750812 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:55:49,163 - wandb.wandb_agent - INFO - Running runs: ['xb49e3r4']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185549-xb49e3r4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-1954
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xb49e3r4
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1936886000976106 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0950627167954186 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.057005477177108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0088828577217144 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.604761036674009 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 █▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇█▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▇██▇██▇▇▆▆▆▆▆▆▇▇▇▇▇▇▆▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▅▇████████████████
wandb: prop_NA ████████████████████▇▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁█▅▁▁▁█▁▅▄█▁▁▁▁▁▁▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced chocolate-sweep-1954: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/xb49e3r4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185549-xb49e3r4/logs
2022-09-02 18:57:06,550 - wandb.wandb_agent - INFO - Cleaning up finished run: xb49e3r4
2022-09-02 18:57:06,852 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:57:06,856 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 3
	learning_rate: 0.014771274524745925
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:57:06,866 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=3 --learning_rate=0.014771274524745925 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:57:11,880 - wandb.wandb_agent - INFO - Running runs: ['mgeka61z']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185712-mgeka61z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-1967
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mgeka61z
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.4884115779094964 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0058236956413995 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.682639039427556 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.0581010250449108 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.598818895705445 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▆▇▆▆▇▇▇▇▇▇▇▇▇███▇▇██▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 █▇▆▆▇▇▇▆▆▅▆▇▇▇█▇▇▇▆▇▆▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇████████████████
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▁▁▅▁▁▁▁▁▁▁▁▁▄▁█▁█▁█▁▅▄▄▆█▅██████▇▆██▃▅▇▁
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.0
wandb:  prop_3 1.0
wandb: prop_NA 0.0
wandb:  reward 0.92352
wandb: 
wandb: Synced dulcet-sweep-1967: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/mgeka61z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185712-mgeka61z/logs
2022-09-02 18:58:34,443 - wandb.wandb_agent - INFO - Cleaning up finished run: mgeka61z
2022-09-02 18:58:34,826 - wandb.wandb_agent - INFO - Agent received command: run
2022-09-02 18:58:34,826 - wandb.wandb_agent - INFO - Agent starting run with config:
	batch_size: 16
	episode_length: 1
	eps_dec: 0.0002
	eps_min: 0
	epsilon: 1
	hidden_units: 4
	layers: 4
	learning_rate: 0.00016276567653815245
	mem_size: 32
	replace: 50
	sigma: 64
	sigma1: 0
	sigma2: 0
2022-09-02 18:58:34,842 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python test_IQL_wandb_sweep.py --batch_size=16 --episode_length=1 --eps_dec=0.0002 --eps_min=0 --epsilon=1 --hidden_units=4 --layers=4 --learning_rate=0.00016276567653815245 --mem_size=32 --replace=50 --sigma=64 --sigma1=0 --sigma2=0
2022-09-02 18:58:39,859 - wandb.wandb_agent - INFO - Running runs: ['ozxvk226']
wandb: Currently logged in as: jia_wan. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.2
wandb: Run data is saved locally in /data/engs-oxfair3/bras5206/noisy-ZSC/tests/wandb/run-20220902_185841-ozxvk226
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-1981
wandb: ⭐️ View project at https://wandb.ai/jia_wan/noisy-ZSC-tests
wandb: 🧹 View sweep at https://wandb.ai/jia_wan/noisy-ZSC-tests/sweeps/i2hxbgb9
wandb: 🚀 View run at https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ozxvk226
/data/engs-oxfair3/bras5206/noisy-ZSC/noisy_zsc/learner/DQNAgent.py:150: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  q_next[dones] = 0.0
/home/bras5206/.conda/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746322/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1581.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2794712929354164 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.946228033243953 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.449432236560803 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.565935089202361 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2218099663383972 seconds), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.570466995803835 seconds), retrying request
episode: 999
episode: 1999
episode: 2999
episode: 3999
episode: 4999
episode: 5999
episode: 6999
episode: 7999
episode: 8999
episode: 9999
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.007 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: - 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: \ 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb: / 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:  prop_1 ▅▇▇▇▇▇▇▆▆▆▆▆▇▇▇█████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  prop_2 ▆▇▇▇▆▇▇█████▇▇▇▇▇▇▇▇▇▅▄▂▁▁▁▁▁▁▁▁▁▂▃▄▅▆▆▇
wandb:  prop_3 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▅▇██████████▇▇▇▇▇▇
wandb: prop_NA ████████████████████▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  reward ▆▁▁▁▇▁▁▁▁▆▁█▁▁▁▁▇▁▁▄▅▄▄▆█▅██████▇▆██▃▅▇▂
wandb: 
wandb: Run summary:
wandb:  prop_1 0.0
wandb:  prop_2 0.106
wandb:  prop_3 0.863
wandb: prop_NA 0.031
wandb:  reward 0.92352
wandb: 
wandb: Synced curious-sweep-1981: https://wandb.ai/jia_wan/noisy-ZSC-tests/runs/ozxvk226
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220902_185841-ozxvk226/logs
slurmstepd: error: *** JOB 2474889 ON arc-c301 CANCELLED AT 2022-09-02T19:00:05 ***
